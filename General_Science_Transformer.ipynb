{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "General Science Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9edf5e6a10c344b3b9906c48dc59ede8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_afc7fca89d1d4b608095233fa729aa37",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_195b5150ea5d473c82c15044b39f20e6",
              "IPY_MODEL_b6c0dcf1d8a24c38ae896553a58a7d9f"
            ]
          }
        },
        "afc7fca89d1d4b608095233fa729aa37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "195b5150ea5d473c82c15044b39f20e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_af70ebe247e74160a9dcce7d5b276c59",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 200,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 200,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b326b64fc150444482500e8d8e7b43e2"
          }
        },
        "b6c0dcf1d8a24c38ae896553a58a7d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e81b6ac1d12e4c4fbcc37ed47df0880e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 200/200 [05:33&lt;00:00,  1.67s/epoch, loss=0.000297, val_loss=0.00106]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0d8251d8f714823b2246a99d2787444"
          }
        },
        "af70ebe247e74160a9dcce7d5b276c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b326b64fc150444482500e8d8e7b43e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e81b6ac1d12e4c4fbcc37ed47df0880e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0d8251d8f714823b2246a99d2787444": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "531d198d0895483192e7b9867a5ca6fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ff2ebe43fb534362893ad45d6b469692",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_130ecfb87b344d479c7fe478196a359a",
              "IPY_MODEL_9bd8d74c03454e28a5e996a9708b1313"
            ]
          }
        },
        "ff2ebe43fb534362893ad45d6b469692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "130ecfb87b344d479c7fe478196a359a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_65b9877d7b2b48f39bebe928e57bbdc2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 85,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 85,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_840e4a9b2c0448038caa919733dc2c73"
          }
        },
        "9bd8d74c03454e28a5e996a9708b1313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fc9a6365e7dd40d1817a7012ba1379c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 85.0/85.0 [00:01&lt;00:00, 54.8batch/s, loss=0.000297]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0efd48e69e954497b5dd68239b8ef33d"
          }
        },
        "65b9877d7b2b48f39bebe928e57bbdc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "840e4a9b2c0448038caa919733dc2c73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc9a6365e7dd40d1817a7012ba1379c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0efd48e69e954497b5dd68239b8ef33d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cybertraining-dsc/collab/blob/master/General_Science_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s_qNSzzyaCbD"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors and Geoffrey Fox 2020\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "jmjh290raIky",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWNb05uZ7V9I",
        "colab_type": "text"
      },
      "source": [
        "# Initial System Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4cXSlPV7hNG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "79a9d8ad-2622-4cd0-c439-b515bc2cbf4c"
      },
      "source": [
        "startbold = \"\\033[1m\"\n",
        "resetfonts = \"\\033[0m\"\n",
        "startred = '\\033[31m'\n",
        "startpurple = '\\033[35m'\n",
        "startyellowbkg = '\\033[43m'\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, \n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "# Transformer model for science data based on original for language understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AOpGoE2T-YXS"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/text/transformer\">\n",
        "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
        "    View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/transformer.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M-f8TnGpE_ex"
      },
      "source": [
        "This tutorial trains a <a href=\"https://arxiv.org/abs/1706.03762\" class=\"external\">Transformer model</a> to translate Portuguese to English. This is an advanced example that assumes knowledge of [text generation](text_generation.ipynb) and [attention](nmt_with_attention.ipynb).\n",
        "\n",
        "The core idea behind the Transformer model is *self-attention*â€”the ability to attend to different positions of the input sequence to compute a representation of that sequence. Transformer creates stacks of self-attention layers and is explained below in the sections *Scaled dot product attention* and *Multi-head attention*.\n",
        "\n",
        "A transformer model handles variable-sized input using stacks of self-attention layers instead of [RNNs](text_classification_rnn.ipynb) or [CNNs](../images/intro_to_cnns.ipynb). This general architecture has a number of advantages:\n",
        "\n",
        "* It make no assumptions about the temporal/spatial relationships across the data. This is ideal for processing a set of objects (for example, [StarCraft units](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/#block-8)).\n",
        "* Layer outputs can be calculated in parallel, instead of a series like an RNN.\n",
        "* Distant items can affect each other's output without passing through many RNN-steps, or convolution layers (see [Scene Memory Transformer](https://arxiv.org/pdf/1903.03878.pdf) for example).\n",
        "* It can learn long-range dependencies. This is a challenge in many sequence tasks.\n",
        "\n",
        "The downsides of this architecture are:\n",
        "\n",
        "* For a time-series, the output for a time-step is calculated from the *entire history* instead of only the inputs and current hidden-state. This _may_ be less efficient.   \n",
        "* If the input *does* have a  temporal/spatial relationship, like text, some positional encoding must be added or the model will effectively see a bag of words. \n",
        "\n",
        "After training the model in this notebook, you will be able to input a Portuguese sentence and return the English translation.\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/attention_map_portuguese.png\" width=\"800\" alt=\"Attention heatmap\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA3Lx2aY1xeg",
        "colab_type": "text"
      },
      "source": [
        "## Science Data Parameters and Sizes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMY9LokXwa9K",
        "colab_type": "text"
      },
      "source": [
        "-------\n",
        "Here is structure of science time series module. We will need several arrays that will need to be flattened at times. Note Python defaults to row major i.e. final index describes contiguous positions in memory\n",
        "\n",
        "\n",
        "At highest level data is labeled by Time and Location\n",
        "\n",
        "*   Ttot is total number of time steps\n",
        "*   Tseq is length of each sequence in time steps\n",
        "*   Num_Seq is number of sequences in time: Num_Seq = Ttot-Tseq + 1\n",
        "*   Nloc is Number of locations. The locations could be a 1D list or have array structure such as an image.\n",
        "*   Nsample is number of data samples Nloc * Num_Seq\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Input data is at each location\n",
        "*   Nprop time independent properties describing the location\n",
        "*   Nforcing is number of time dependent forcing features INPUT at each time value\n",
        "\n",
        "\n",
        "Output (predicted) data at each location and for each time sequence is\n",
        "*   Npred predicted time dependent values defined at every time step\n",
        "*   Recorded at Nforecast time values measured wrt final time value of sequence\n",
        "*   ForecastDay is an array of length Nforecast defining how many days into future prediction is. Typically ForecastDay[0] = 1 and Nforecast is often 1\n",
        "*   There is also a class of science problems that are more similar to classic Seq2Seq. Here Nforecast = Tseq and ForecastDay = [-Tseq+1 ... 0]\n",
        "*   We also support Nwishful predictions of events in future such probability of an earthquake of magnitude 6 in next 3 years. These are defined by araays EventType and Timestart, TimeInterval of length Nwishful. EventType is user defined and Timestart, TimeInterval is measured in time steps\n",
        "*   Any missing output values should be set to NaN and Loss function must ensure that these points are ignored in derivative calculation and value calculation\n",
        "\n",
        "We have an input module that supports either LSTM or Transformer (multi-head attention) models\n",
        "\n",
        "Example Problem AICov\n",
        "\n",
        "*   Ttot = 114\n",
        "*   Tseq = 9\n",
        "*   Num_Seq = 106\n",
        "*   Nloc = 110\n",
        "\n",
        "\n",
        "*   Nprop = 35\n",
        "*   Nforcing = 5 including infections, fatalities, plus 3 temporal position variables (last 3 not in current version)\n",
        " \n",
        " \n",
        "*   Npred = 2 (predicted infections and fatalities). Could be 5 if predicted temporal position of output)\n",
        "*   Nforecast= 15\n",
        "*   ForecastDay = [1, 2, .......14, 15]\n",
        "*   Nwishful = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UlOJMJ31SoG",
        "colab_type": "text"
      },
      "source": [
        "## Science Data Arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdszPs9on5gk",
        "colab_type": "text"
      },
      "source": [
        "Typical Arrays\n",
        "\n",
        "\n",
        "[ time, Location ] as Pandas array with label [name of time-dependent variable] as an array or just name of Pandas array\n",
        "\n",
        "time labels rows indexed by datetime or the difference datetime - start\n",
        "\n",
        "Non windowed data is stored with propert name as row index and location as column index\n",
        "[ static property, Location]\n",
        "\n",
        "Covid Input is\n",
        "[Sequence number 0..Num_Seq-1 ] [ Location 0..Nloc-1 ] [position in time sequence Tseq]  [ Input Features]\n",
        "\n",
        "Covid Output is \n",
        "[Sequence number Num_Seq ] [ Location Nloc ]  [ Output Features] \n",
        "\n",
        "Output Features are [ ipred = 0 ..Npred-1 ] [ iforecast = 0 ..Nforecast-1 ]\n",
        "\n",
        "Input Features are static fields followed by if present by dynamic system fields (cos-theta sin-theta linear) chosen followed by cases, deaths. In fact this is user chosen as they set static and dynamic system properties to use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-iizX9OKmI3",
        "colab_type": "text"
      },
      "source": [
        "We will have various numpy and pandas arrays where we designate label\n",
        "\n",
        "[Ttot] is all time values \n",
        "\n",
        "[Num_Seq]  is all sequences of window size ***Tseq***\n",
        "\n",
        "We can select time values or sequences [Ttot-reason] [Num_Seq-reason] for a given \"reason\"\n",
        "\n",
        "[Num_Seq][Tseq] is all time values in all sequences\n",
        "\n",
        "[Nloc] is all locations while [Nloc-reason] is subset of locations for given \"reason\"\n",
        "\n",
        "[Model1] is initial embedding of each data point\n",
        "\n",
        "[Model1+TrPosEnc] is initial embedding of each data point with Transformer style positional encoding\n",
        "\n",
        "[Nforcing] is time dependent input parameters and [Nprop] static properties while [ExPosEnc] are explicit positional (temporal) encoding.\n",
        "\n",
        "[Nforcing+ExPosEnc+Nprop] are all possible inputs\n",
        "\n",
        "[Npred] is predicted values with [Npred+ExPosEnc] as predictions plus encodings with actually used [Predvals] = [Npred+ExPosEnc-Selout] \n",
        "\n",
        "[Predtimes] = [Forecast time range] are times forecasted with \"time range\" separately defined\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqUzXxXfc6dx",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uO_1dNu0dhw5",
        "colab_type": "text"
      },
      "source": [
        "Indexed by city number 0..Nloc-1 [Nloc]\n",
        "Locationname"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwCAZxnf3PoN",
        "colab_type": "text"
      },
      "source": [
        "## Code for defining (import) basic modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JjJJyJTZYebt",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from tqdm.keras import TqdmCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "import os\n",
        "from csv import reader\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import io as io\n",
        "import string\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "from datetime import timedelta,date,datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fd1NWMxjfsDd"
      },
      "source": [
        "## Define input structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DefDaYecDhIM",
        "colab_type": "text"
      },
      "source": [
        "## Code to read in data and set it up for Tensorflow with training and validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kj1DvDTneDZ",
        "colab_type": "text"
      },
      "source": [
        "Set train_examples, val_examples as science training and validatioon set.\n",
        "\n",
        "The shuffling of Science Data needs some care. We have ***Tseq*** * size of {[Num_Seq][Nloc]} locations in each sample. In simplease case the last is just a decomposition over location; not over time. Let's Nloc-sel be number of locations per sample. It will be helpful if Nloc-sel is divisable by 2. \n",
        "\n",
        "Perhaps Nloc-sel = 2 6 or 10 is reasonable.\n",
        "\n",
        "Then you shuffle locations every epoch and divide them into groups of size Nloc-sel with 50% overlap so you get locations\n",
        "\n",
        "0 1 2 3 4 5; \n",
        "\n",
        "3 4 5 6 7 8; \n",
        "\n",
        "6 7 8 9 10 11 etc.\n",
        "\n",
        "Every locations appears twice in an epoch (for each time value). You need to randomly add locations at end of sequence so it is divisiuble by Nloc-sel e.g add 4 random positions to the end if Nloc=110 and Nloc-sel = 6. Note last group of 6 has members 112 113 114 0 1 2\n",
        "\n",
        "After spatial structure set up, randomly shuffle in Num_Seq where there is an argument to do all locations for a partcular time value together.\n",
        "\n",
        "For validation, it is probably best to select validation location before chopping them into groups of size Nloc-sel\n",
        "\n",
        "How one groups locations for inference is not clear. One idea is to take trained network and use it to find for each location which other locations have the most attention with it. Use those locations in  prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2KQcxrRa1QT",
        "colab_type": "text"
      },
      "source": [
        "### Major Data defining COVID problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV2GPBxY4yr7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b164414f-c871-4afe-a910-aec95c3cbc1f"
      },
      "source": [
        "def float32fromstrwithNaN(instr):\n",
        "  if instr == 'NaN':\n",
        "    return NaN\n",
        "  return np.float32(instr)\n",
        "\n",
        "def printexit(exitmessage):\n",
        "  print(exitmessage)\n",
        "  sys.exit()\n",
        "\n",
        "def strrnd(value):\n",
        "  return str(round(value,4))\n",
        "\n",
        "# read in science data for COVID\n",
        "COLABROOTDIR=\"/content/gdrive/My Drive/Colab Datasets\"\n",
        "\n",
        "os.environ[\"COLABROOTDIR\"] = COLABROOTDIR\n",
        "COVIDDIR=os.path.join(COLABROOTDIR, \"COVIDJuly2020\")\n",
        "!ls /content/gdrive/'My Drive'/'Colab Datasets'/COVIDJuly2020\n",
        "XFile = COVIDDIR + '/' + 'InputSequences14F1.csv'\n",
        "yFile = COVIDDIR + '/' + 'Predictions14F1.csv'\n",
        "PropnameFile = COVIDDIR + '/' + 'Propname14F.csv'\n",
        "PredictionnameFile = COVIDDIR + '/' + 'Predictionname14F.csv'\n",
        "LocationdataFile = COVIDDIR + '/' + 'Locationdata14F.csv'\n",
        "NaN = np.float32(\"NaN\")\n",
        "\n",
        "# Read in Information about locations\n",
        "with open(LocationdataFile, 'r') as read_obj:\n",
        "    csv_reader = reader(read_obj)\n",
        "    header = next(csv_reader)\n",
        "    Nloc = int(header[1])\n",
        "    Locationname = []\n",
        "    Locationstate = []\n",
        "    Locationcolumns = []\n",
        "    Locationfips = np.empty(Nloc, dtype=int)\n",
        "    Locationpopulation = np.empty(Nloc, dtype=int)\n",
        "    Locationindex = np.empty(Nloc, dtype=int)\n",
        "    print(startbold + '\\nLocation Data' + resetfonts)\n",
        "\n",
        "    for nextrow in csv_reader:\n",
        "      i = int(nextrow[0])\n",
        "      Locationindex[i] = i\n",
        "      Locationname.append(nextrow[3])\n",
        "      Locationstate.append(nextrow[2])\n",
        "      Locationfips[i] = int(nextrow[1])\n",
        "      Locationcolumns.append(str(Locationfips[i]))\n",
        "      Locationpopulation[i] = int(nextrow[4])\n",
        "      print(str(i) + ' FIPS '+ str(Locationfips[i]) + ' Pop ' + str(Locationpopulation[i]) + ' State ' + str(Locationstate[i]) + ' Region ' + str(Locationname[i]))\n",
        "locationdf = pd.DataFrame([], columns = Locationcolumns)\n",
        "newrow = pd.Series(Locationfips,index=Locationcolumns)\n",
        "locationdf.loc['FIPS'] = newrow\n",
        "newrow = pd.Series(Locationindex,index=Locationcolumns)\n",
        "locationdf.loc['columnnumber'] = newrow\n",
        "newrow = pd.Series(Locationname,index=Locationcolumns)\n",
        "locationdf.loc['City'] = newrow\n",
        "newrow = pd.Series(Locationstate,index=Locationcolumns)\n",
        "locationdf.loc['State'] = newrow\n",
        "newrow = pd.Series(Locationpopulation,index=Locationcolumns)\n",
        "locationdf.loc['Population'] = newrow\n",
        "\n",
        "\n",
        "# Read in property names into Propname[]\n",
        "with open(PropnameFile, 'r') as read_obj:\n",
        "    csv_reader = reader(read_obj)\n",
        "    header = next(csv_reader)\n",
        "    Npropperseq = int(header[1])\n",
        "    PopulationNorm = False\n",
        "    if header[2] == 'True':\n",
        "      PopulationNorm = True\n",
        "    CASESMAX = float(header[3])\n",
        "    DEATHMAX = float(header[4])\n",
        "    InputPropertyNames = next(csv_reader)\n",
        "    if InputPropertyNames[len(InputPropertyNames)-1] == '':\n",
        "      InputPropertyNames.pop()\n",
        "    if len(InputPropertyNames) != Npropperseq:\n",
        "      printexit('EXIT Inconsistent Property Lengths ' +str(len(InputPropertyNames)) + ' ' + str(Npropperseq))\n",
        "    PropertyValues = np.empty([Npropperseq,7], dtype=float)\n",
        "    for quantity in range(0,7): #['Min','Max','Norm','Mean','Std','Normed Mean','Normed Std']\n",
        "      nextrow = next(csv_reader)\n",
        "      for i in range (0, Npropperseq-2):\n",
        "        PropertyValues[i,quantity] = nextrow[i]\n",
        "for i in range (Npropperseq-2,Npropperseq): # Cases and Deaths\n",
        "  for quantity in range(0,7):\n",
        "    PropertyValues[i,quantity] = 0\n",
        "PropertyValues[Npropperseq-2, 1] = float(CASESMAX)\n",
        "PropertyValues[Npropperseq-1, 1] = float(DEATHMAX)\n",
        "\n",
        "line = startbold + 'Name   Min , Max , Norm , Mean , Std , Normed Mean , Normed Std' + resetfonts\n",
        "print(\"\\n\" + line)\n",
        "for i in range(0,Npropperseq):\n",
        "  line = str(i) + ' ' + InputPropertyNames[i] + ' : '\n",
        "  for quantity in range(0,7):\n",
        "    line += strrnd(PropertyValues[i,quantity]) + ', '\n",
        "  print(line)\n",
        "\n",
        "# Read in prediction names into Predictionname[] etc.\n",
        "with open(PredictionnameFile, 'r') as read_obj:\n",
        "    csv_reader = reader(read_obj)\n",
        "    header = next(csv_reader)\n",
        "    Npredperseq = int(header[1])\n",
        "    Predictionname = []\n",
        "    Predictiontype = np.empty(Npredperseq, dtype=int)\n",
        "    Predictionday = np.empty(Npredperseq, dtype=int)\n",
        "    Predictionwgt = np.empty(Npredperseq, dtype=float)\n",
        "    i = 0\n",
        "    Predictionnamelookup = {}\n",
        "    for nextrow in csv_reader:\n",
        "      stredit = nextrow[3].replace('Next ','Next')\n",
        "      finalname = stredit.replace(' ','')\n",
        "      Predictionname.append(finalname)\n",
        "      Predictionnamelookup[finalname] = i\n",
        "      Predictiontype[i] = int(nextrow[0])\n",
        "      Predictionday[i] = int(nextrow[1])\n",
        "      Predictionwgt[i] = float(nextrow[2])\n",
        "      i += 1\n",
        "\n",
        "print('\\nPredicted Quantities')\n",
        "for i in range(0,Npredperseq):\n",
        "  line = ' Cases'\n",
        "  if Predictiontype[i] == 1:\n",
        "    line = 'Deaths'\n",
        "  line += ' Day= ' + str(Predictionday[i])\n",
        "  line += ' Weight ' + str(Predictionwgt[i])\n",
        "  line += ' Name ' + Predictionname[i]\n",
        "  print(line)\n",
        "\n",
        "# Read in  sequence Data into RawInputSequences\n",
        "with open(XFile, 'r') as read_obj:\n",
        "    csv_reader = reader(read_obj)\n",
        "    header = next(csv_reader)\n",
        "    Ftype = header[0]\n",
        "    if Ftype != 'X':\n",
        "      printexit('EXIT: Wrong file type ' + Ftype)\n",
        "\n",
        "    numdims = int(header[1])\n",
        "    if numdims != 4:\n",
        "      printexit('EXIT: Wrong number of dimensions ' + str(numdims))\n",
        "    \n",
        "    Num_Seq = int(header[3])\n",
        "    Nloc1 = int(header[2])\n",
        "    if Nloc != Nloc:\n",
        "      printexit('EXIT Inconsistent Location Numbers ' + str(Nloc) + ' ' + str(Nloc1))\n",
        "    Tseq = int(header[4])\n",
        "    Npropperseq1 = int(header[5])\n",
        "    if Npropperseq != Npropperseq1:\n",
        "      printexit('EXIT Inconsistent Property Lists ' + str(Npropperseq) + ' ' + str(Npropperseq1))\n",
        "    RawInputSequences = np.zeros([Num_Seq, Nloc, Tseq, Npropperseq], dtype =np.float32)\n",
        "    print(\"Input Sequences, Locations, members sequence, input variables \",np.shape(RawInputSequences))\n",
        "    \n",
        "    totinput = 0\n",
        "    totnan = 0\n",
        "    for nextrow in csv_reader:\n",
        "      i = int(nextrow[1]) \n",
        "      j = int(nextrow[0])\n",
        "      k = int(nextrow[2])\n",
        "      for l in range(0,Npropperseq):\n",
        "        val = float32fromstrwithNaN(nextrow[3+l])\n",
        "        if np.isnan(val):\n",
        "          totnan +=1\n",
        "        RawInputSequences[i,j,k,l] = val\n",
        "      totinput += Npropperseq\n",
        "    print(\"Number of Sequences \",totinput,\" Number of input NaN\", totnan)\n",
        "    if totnan != 0:\n",
        "      printexit('EXIT: NaN in sequence input ' + str(totnan))\n",
        "    totinputexpected = Num_Seq * Nloc * Tseq * Npropperseq\n",
        "    if totinput != totinputexpected:\n",
        "      printexit('EXIT: missing sequence input ' + str(totinputexpected) + ' ' + str(totinput))\n",
        " \n",
        " # Read in prediction Data into RawInputPredictions\n",
        "with open(yFile, 'r') as read_obj:\n",
        "    csv_reader = reader(read_obj)\n",
        "    header = next(csv_reader)\n",
        "    Ftype = header[0]\n",
        "    if Ftype != 'y':\n",
        "      printexit('EXIT: Wrong file type ' + Ftype)\n",
        "    numdims = int(header[1])\n",
        "    if numdims != 3:\n",
        "      printexit('EXIT: Wrong number of dimensions ' + str(numdims))     \n",
        "    Num_Seq1 = int(header[3])\n",
        "    if Num_Seq1 != Num_Seq:\n",
        "      printexit('EXIT: Wrong number of Sequences ' + str(Num_Seq) + ' ' + str(Num_Seq1))\n",
        "    Nloc1 = int(header[2])\n",
        "    if Nloc1 != Nloc:\n",
        "      printexit('EXIT: Wrong number of locations ' + str(Nloc) + ' ' + str(Nloc1))\n",
        "\n",
        "    Npredperseq1 = int(header[4])\n",
        "    if Npredperseq1 != Npredperseq:\n",
        "      printexit('EXIT Inconsistent Numbers of Predictions ' + str(Npredperseq) + ' ' + str(Npredperseq1))\n",
        "    RawInputPredictions = np.zeros([Num_Seq, Nloc, Npredperseq], dtype =np.float32)\n",
        "    print(\"Input Sequences, Locations, Predictions per sequence\", np.shape(RawInputPredictions))\n",
        "    \n",
        "    totinput = 0\n",
        "    totnan = 0\n",
        "    for nextrow in csv_reader:\n",
        "      i = int(nextrow[1]) \n",
        "      j = int(nextrow[0])\n",
        "      for k in range(0, Npredperseq):\n",
        "        val = float32fromstrwithNaN(nextrow[2+k])\n",
        "        if np.isnan(val):\n",
        "          totnan +=1\n",
        "        RawInputPredictions[i,j,k] = val\n",
        "      totinput +=  Npredperseq\n",
        "    print(\"Number of Predictions \",totinput,\" including number of NaN (missing prediction)\", totnan)\n",
        "    totinputexpected = Num_Seq * Nloc * Npredperseq\n",
        "    if totinput != totinputexpected:\n",
        "      printexit('EXIT: missing sequence input ' + str(totinputexpected) + ' ' + str(totinput))\n",
        "   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "InputSequences14F1.csv\tPredictionname14F.csv  Propname14F.csv\n",
            "InputSequences14F.csv\tPredictions14F1.csv\n",
            "Locationdata14F.csv\tPredictions14F.csv\n",
            "\u001b[1m\n",
            "Location Data\u001b[0m\n",
            "0 FIPS 17031 Pop 5150233 State Illinois Region Cook, Illinois, US\n",
            "1 FIPS 17197 Pop 690743 State Illinois Region Will, Illinois, US\n",
            "2 FIPS 17043 Pop 922921 State Illinois Region DuPage, Illinois, US\n",
            "3 FIPS 1073 Pop 658573 State Alabama Region Jefferson, Alabama, US\n",
            "4 FIPS 26161 Pop 367601 State Michigan Region Washtenaw, Michigan, US\n",
            "5 FIPS 26163 Pop 1749343 State Michigan Region Wayne, Michigan, US\n",
            "6 FIPS 36029 Pop 918702 State New York Region Erie, New York, US\n",
            "7 FIPS 25027 Pop 830622 State Massachusetts Region Worcester, Massachusetts, US\n",
            "8 FIPS 1097 Pop 413210 State Alabama Region Mobile, Alabama, US\n",
            "9 FIPS 25013 Pop 466372 State Massachusetts Region Hampden, Massachusetts, US\n",
            "10 FIPS 25009 Pop 789034 State Massachusetts Region Essex, Massachusetts, US\n",
            "11 FIPS 36119 Pop 967506 State New York Region Westchester, New York, US\n",
            "12 FIPS 25005 Pop 565217 State Massachusetts Region Bristol, Massachusetts, US\n",
            "13 FIPS 25021 Pop 706775 State Massachusetts Region Norfolk, Massachusetts, US\n",
            "14 FIPS 4013 Pop 4485414 State Arizona Region Maricopa, Arizona, US\n",
            "15 FIPS 18097 Pop 964582 State Indiana Region Marion, Indiana, US\n",
            "16 FIPS 18057 Pop 338011 State Indiana Region Hamilton, Indiana, US\n",
            "17 FIPS 18089 Pop 485493 State Indiana Region Lake, Indiana, US\n",
            "18 FIPS 17097 Pop 696535 State Illinois Region Lake, Illinois, US\n",
            "19 FIPS 34017 Pop 672391 State New Jersey Region Hudson, New Jersey, US\n",
            "20 FIPS 32031 Pop 471519 State Nevada Region Washoe, Nevada, US\n",
            "21 FIPS 36001 Pop 305506 State New York Region Albany, New York, US\n",
            "22 FIPS 32003 Pop 2266715 State Nevada Region Clark, Nevada, US\n",
            "23 FIPS 34031 Pop 501826 State New Jersey Region Passaic, New Jersey, US\n",
            "24 FIPS 34039 Pop 556341 State New Jersey Region Union, New Jersey, US\n",
            "25 FIPS 34013 Pop 798975 State New Jersey Region Essex, New Jersey, US\n",
            "26 FIPS 25017 Pop 1611699 State Massachusetts Region Middlesex, Massachusetts, US\n",
            "27 FIPS 34021 Pop 367430 State New Jersey Region Mercer, New Jersey, US\n",
            "28 FIPS 6001 Pop 1671329 State California Region Alameda, California, US\n",
            "29 FIPS 6059 Pop 3175692 State California Region Orange, California, US\n",
            "30 FIPS 6013 Pop 1153526 State California Region Contra Costa, California, US\n",
            "31 FIPS 22071 Pop 390144 State Louisiana Region Orleans, Louisiana, US\n",
            "32 FIPS 21111 Pop 766757 State Kentucky Region Jefferson, Kentucky, US\n",
            "33 FIPS 22051 Pop 432493 State Louisiana Region Jefferson, Louisiana, US\n",
            "34 FIPS 22033 Pop 440059 State Louisiana Region East Baton Rouge, Louisiana, US\n",
            "35 FIPS 6029 Pop 900202 State California Region Kern, California, US\n",
            "36 FIPS 6037 Pop 10039107 State California Region Los Angeles, California, US\n",
            "37 FIPS 6073 Pop 3338330 State California Region San Diego, California, US\n",
            "38 FIPS 36061 Pop 5803210 State New York Region New York City, New York, US\n",
            "39 FIPS 6071 Pop 2180085 State California Region San Bernardino, California, US\n",
            "40 FIPS 6067 Pop 1552058 State California Region Sacramento, California, US\n",
            "41 FIPS 25025 Pop 803907 State Massachusetts Region Suffolk, Massachusetts, US\n",
            "42 FIPS 22017 Pop 240204 State Louisiana Region Caddo, Louisiana, US\n",
            "43 FIPS 24510 Pop 593490 State Maryland Region Baltimore City, Maryland, US\n",
            "44 FIPS 25023 Pop 521202 State Massachusetts Region Plymouth, Massachusetts, US\n",
            "45 FIPS 34007 Pop 506471 State New Jersey Region Camden, New Jersey, US\n",
            "46 FIPS 6065 Pop 2470546 State California Region Riverside, California, US\n",
            "47 FIPS 26049 Pop 405813 State Michigan Region Genesee, Michigan, US\n",
            "48 FIPS 26125 Pop 1257584 State Michigan Region Oakland, Michigan, US\n",
            "49 FIPS 27053 Pop 1265843 State Minnesota Region Hennepin, Minnesota, US\n",
            "50 FIPS 26099 Pop 873972 State Michigan Region Macomb, Michigan, US\n",
            "51 FIPS 29510 Pop 300576 State Missouri Region St. Louis City, Missouri, US\n",
            "52 FIPS 6085 Pop 1927852 State California Region Santa Clara, California, US\n",
            "53 FIPS 6081 Pop 766573 State California Region San Mateo, California, US\n",
            "54 FIPS 42003 Pop 1216045 State Pennsylvania Region Allegheny, Pennsylvania, US\n",
            "55 FIPS 42101 Pop 1584064 State Pennsylvania Region Philadelphia, Pennsylvania, US\n",
            "56 FIPS 42095 Pop 305285 State Pennsylvania Region Northampton, Pennsylvania, US\n",
            "57 FIPS 39049 Pop 1316756 State Ohio Region Franklin, Ohio, US\n",
            "58 FIPS 39095 Pop 428348 State Ohio Region Lucas, Ohio, US\n",
            "59 FIPS 8059 Pop 582881 State Colorado Region Jefferson, Colorado, US\n",
            "60 FIPS 8005 Pop 656590 State Colorado Region Arapahoe, Colorado, US\n",
            "61 FIPS 8031 Pop 727211 State Colorado Region Denver, Colorado, US\n",
            "62 FIPS 8123 Pop 324492 State Colorado Region Weld, Colorado, US\n",
            "63 FIPS 37119 Pop 1110356 State North Carolina Region Mecklenburg, North Carolina, US\n",
            "64 FIPS 36067 Pop 460528 State New York Region Onondaga, New York, US\n",
            "65 FIPS 37183 Pop 1111761 State North Carolina Region Wake, North Carolina, US\n",
            "66 FIPS 42077 Pop 369318 State Pennsylvania Region Lehigh, Pennsylvania, US\n",
            "67 FIPS 9001 Pop 943332 State Connecticut Region Fairfield, Connecticut, US\n",
            "68 FIPS 9003 Pop 891720 State Connecticut Region Hartford, Connecticut, US\n",
            "69 FIPS 10003 Pop 558753 State Delaware Region New Castle, Delaware, US\n",
            "70 FIPS 11001 Pop 705749 State District of Columbia Region District of Columbia,District of Columbia,US\n",
            "71 FIPS 12099 Pop 1496770 State Florida Region Palm Beach, Florida, US\n",
            "72 FIPS 12103 Pop 974996 State Florida Region Pinellas, Florida, US\n",
            "73 FIPS 12011 Pop 1952778 State Florida Region Broward, Florida, US\n",
            "74 FIPS 12086 Pop 2716940 State Florida Region Miami-Dade, Florida, US\n",
            "75 FIPS 12031 Pop 957755 State Florida Region Duval, Florida, US\n",
            "76 FIPS 39035 Pop 1235072 State Ohio Region Cuyahoga, Ohio, US\n",
            "77 FIPS 39061 Pop 817473 State Ohio Region Hamilton, Ohio, US\n",
            "78 FIPS 12095 Pop 1393452 State Florida Region Orange, Florida, US\n",
            "79 FIPS 48029 Pop 2003554 State Texas Region Bexar, Texas, US\n",
            "80 FIPS 13121 Pop 1063937 State Georgia Region Fulton, Georgia, US\n",
            "81 FIPS 16001 Pop 481587 State Idaho Region Ada, Idaho, US\n",
            "82 FIPS 47037 Pop 694144 State Tennessee Region Davidson, Tennessee, US\n",
            "83 FIPS 48113 Pop 2635516 State Texas Region Dallas, Texas, US\n",
            "84 FIPS 48439 Pop 2102515 State Texas Region Tarrant, Texas, US\n",
            "85 FIPS 48121 Pop 887207 State Texas Region Denton, Texas, US\n",
            "86 FIPS 48157 Pop 811688 State Texas Region Fort Bend, Texas, US\n",
            "87 FIPS 55079 Pop 945726 State Wisconsin Region Milwaukee, Wisconsin, US\n",
            "88 FIPS 53053 Pop 904980 State Washington Region Pierce, Washington, US\n",
            "89 FIPS 48201 Pop 4713325 State Texas Region Harris, Texas, US\n",
            "90 FIPS 53077 Pop 250873 State Washington Region Yakima, Washington, US\n",
            "91 FIPS 48453 Pop 1273954 State Texas Region Travis, Texas, US\n",
            "92 FIPS 49035 Pop 1160437 State Utah Region Salt Lake, Utah, US\n",
            "93 FIPS 53033 Pop 2252782 State Washington Region King, Washington, US\n",
            "94 FIPS 53061 Pop 822083 State Washington Region Snohomish, Washington, US\n",
            "95 FIPS 42069 Pop 209674 State Pennsylvania Region Lackawanna, Pennsylvania, US\n",
            "96 FIPS 45079 Pop 415759 State South Carolina Region Richland, South Carolina, US\n",
            "97 FIPS 4019 Pop 1047279 State Arizona Region Pima, Arizona, US\n",
            "98 FIPS 6075 Pop 881549 State California Region San Francisco, California, US\n",
            "99 FIPS 8041 Pop 720403 State Colorado Region El Paso, Colorado, US\n",
            "100 FIPS 8001 Pop 517421 State Colorado Region Adams, Colorado, US\n",
            "101 FIPS 12071 Pop 770577 State Florida Region Lee, Florida, US\n",
            "102 FIPS 9009 Pop 854757 State Connecticut Region New Haven, Connecticut, US\n",
            "103 FIPS 12057 Pop 1471968 State Florida Region Hillsborough, Florida, US\n",
            "104 FIPS 13089 Pop 759297 State Georgia Region DeKalb, Georgia, US\n",
            "105 FIPS 13095 Pop 87956 State Georgia Region Dougherty, Georgia, US\n",
            "106 FIPS 47157 Pop 937166 State Tennessee Region Shelby, Tennessee, US\n",
            "107 FIPS 44007 Pop 638931 State Rhode Island Region Providence, Rhode Island, US\n",
            "108 FIPS 42011 Pop 421164 State Pennsylvania Region Berks, Pennsylvania, US\n",
            "109 FIPS 46099 Pop 193134 State South Dakota Region Minnehaha, South Dakota, US\n",
            "\n",
            "\u001b[1mName   Min , Max , Norm , Mean , Std , Normed Mean , Normed Std\u001b[0m\n",
            "0 Insurance : 4.8, 47.9, 0.0232, 16.6918, 8.3646, 0.2759, 0.1941, \n",
            "1 Nbeds : 0.026, 0.1168, 11.0117, 0.0563, 0.0159, 0.3332, 0.1746, \n",
            "2 Nbeds_per1000 : 0.6764, 13.6471, 0.0771, 3.4149, 2.063, 0.2111, 0.159, \n",
            "3 Nhosp : 0.0018, 0.0061, 229.0618, 0.0034, 0.0008, 0.3827, 0.1752, \n",
            "4 Estbeds : 0.026, 0.1168, 11.0117, 0.0563, 0.0159, 0.3332, 0.1746, \n",
            "5 senior_percent : 9.9, 28.6, 0.0535, 14.8818, 2.9192, 0.2664, 0.1561, \n",
            "6 black_percent : 1.3, 70.9, 0.0144, 18.5727, 15.2632, 0.2482, 0.2193, \n",
            "7 Percenthispanics : 2.2, 69.1, 0.0149, 19.2364, 14.3492, 0.2547, 0.2145, \n",
            "8 pop_density_2010 : 22.83, 20056.94, 0.0, 1387.6508, 2564.7891, 0.0681, 0.128, \n",
            "9 poverty_percent : 4.2, 29.5, 0.0395, 13.1364, 4.5446, 0.3532, 0.1796, \n",
            "10 svi_minority : 0.4897, 0.9968, 1.972, 0.8672, 0.1104, 0.7445, 0.2177, \n",
            "11 svi_overall : 0.0255, 0.9659, 1.0634, 0.5454, 0.2192, 0.5529, 0.2331, \n",
            "12 CASTHMA : 5.9, 15.3, 0.1064, 10.0245, 1.7855, 0.4388, 0.1899, \n",
            "13 HIGHCHOL : 12.1, 39.5, 0.0365, 30.3582, 4.8034, 0.6664, 0.1753, \n",
            "14 DIABETES : 1.7, 30.0, 0.0353, 10.8609, 4.5098, 0.3237, 0.1594, \n",
            "15 OBESITY : 13.9, 49.2, 0.0283, 30.1836, 7.8449, 0.4613, 0.2222, \n",
            "16 CANCER : 1.3, 16.5, 0.0658, 5.9773, 2.1558, 0.3077, 0.1418, \n",
            "17 STROKE : 0.9, 8.7, 0.1282, 3.1191, 1.4652, 0.2845, 0.1878, \n",
            "18 MHLTH : 8.1, 24.1, 0.0625, 14.3468, 3.5426, 0.3904, 0.2214, \n",
            "19 CSMOKING : 4.8, 34.7, 0.0334, 18.3695, 6.4419, 0.4538, 0.2154, \n",
            "20 CHOLSCREEN : 50.7, 91.8, 0.0243, 77.6373, 6.3075, 0.6554, 0.1535, \n",
            "21 INSURANCE : 4.8, 47.9, 0.0232, 16.6918, 8.3646, 0.2759, 0.1941, \n",
            "22 CHD : 1.2, 18.6, 0.0575, 5.4391, 2.3036, 0.2436, 0.1324, \n",
            "23 CHECKUP : 51.0, 83.4, 0.0309, 70.2336, 6.4123, 0.5936, 0.1979, \n",
            "24 KIDNEY : 0.9, 5.9, 0.2, 2.9909, 0.8805, 0.4182, 0.1761, \n",
            "25 BINGE : 7.8, 34.1, 0.038, 17.6355, 3.8989, 0.374, 0.1482, \n",
            "26 LPA : 12.4, 47.5, 0.0285, 27.7945, 8.2875, 0.4386, 0.2361, \n",
            "27 ARTHRITIS : 4.4, 39.4, 0.0286, 22.5591, 6.6873, 0.5188, 0.1911, \n",
            "28 BPMED : 23.7, 86.0, 0.0161, 70.5682, 9.3418, 0.7523, 0.1499, \n",
            "29 PHLTH : 6.0, 23.7, 0.0565, 13.1945, 4.3777, 0.4065, 0.2473, \n",
            "30 BPHIGH : 14.1, 58.4, 0.0226, 31.1682, 8.4626, 0.3853, 0.191, \n",
            "31 COPD : 2.3, 13.0, 0.0935, 6.4682, 2.2163, 0.3895, 0.2071, \n",
            "32 norm_pop : 11.3846, 16.122, 0.2111, 13.6637, 0.7657, 0.4811, 0.1616, \n",
            "33 Cases : 0.0, 88.5268, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
            "34 Death : 0.0, 30.5941, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
            "\n",
            "Predicted Quantities\n",
            " Cases Day= 1 Weight 1.0 Name CasesNextday\n",
            "Deaths Day= 1 Weight 1.0 Name DeathsNextday\n",
            " Cases Day= 2 Weight 0.0714 Name Casesday2\n",
            "Deaths Day= 2 Weight 0.0714 Name Deathsday2\n",
            " Cases Day= 3 Weight 0.0714 Name Casesday3\n",
            "Deaths Day= 3 Weight 0.0714 Name Deathsday3\n",
            " Cases Day= 4 Weight 0.0714 Name Casesday4\n",
            "Deaths Day= 4 Weight 0.0714 Name Deathsday4\n",
            " Cases Day= 5 Weight 0.0714 Name Casesday5\n",
            "Deaths Day= 5 Weight 0.0714 Name Deathsday5\n",
            " Cases Day= 6 Weight 0.0714 Name Casesday6\n",
            "Deaths Day= 6 Weight 0.0714 Name Deathsday6\n",
            " Cases Day= 7 Weight 0.0714 Name Casesday7\n",
            "Deaths Day= 7 Weight 0.0714 Name Deathsday7\n",
            " Cases Day= 8 Weight 0.0714 Name Casesday8\n",
            "Deaths Day= 8 Weight 0.0714 Name Deathsday8\n",
            " Cases Day= 9 Weight 0.0714 Name Casesday9\n",
            "Deaths Day= 9 Weight 0.0714 Name Deathsday9\n",
            " Cases Day= 10 Weight 0.0714 Name Casesday10\n",
            "Deaths Day= 10 Weight 0.0714 Name Deathsday10\n",
            " Cases Day= 11 Weight 0.0714 Name Casesday11\n",
            "Deaths Day= 11 Weight 0.0714 Name Deathsday11\n",
            " Cases Day= 12 Weight 0.0714 Name Casesday12\n",
            "Deaths Day= 12 Weight 0.0714 Name Deathsday12\n",
            " Cases Day= 13 Weight 0.0714 Name Casesday13\n",
            "Deaths Day= 13 Weight 0.0714 Name Deathsday13\n",
            " Cases Day= 14 Weight 0.0714 Name Casesday14\n",
            "Deaths Day= 14 Weight 0.0714 Name Deathsday14\n",
            " Cases Day= 15 Weight 0.0714 Name Casesday15\n",
            "Deaths Day= 15 Weight 0.0714 Name Deathsday15\n",
            "Input Sequences, Locations, members sequence, input variables  (106, 110, 9, 35)\n",
            "Number of Sequences  3672900  Number of input NaN 0\n",
            "Input Sequences, Locations, Predictions per sequence (106, 110, 30)\n",
            "Number of Predictions  349800  including number of NaN (missing prediction) 52360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lprQwdZFby5Y",
        "colab_type": "text"
      },
      "source": [
        "### Other COVID setup data including dates and Associated Temporal Positional Encodings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu9Oy46Nb4LO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5ecd4ffe-86f4-4c56-d474-6a5b985b7a72"
      },
      "source": [
        "def LinearLocationEncoding(TotalLoc):\n",
        "  linear = np.empty(TotalLoc, dtype=float)\n",
        "  for i in range(0,TotalLoc):\n",
        "    linear[i] = float(i)/float(TotalLoc)\n",
        "  return linear\n",
        "\n",
        "def LinearTimeEncoding(Dateslisted):\n",
        "  Firstdate = Dateslisted[0]\n",
        "  numtofind = len(Dateslisted)\n",
        "  dayrange = (Dateslisted[numtofind-1]-Firstdate).days + 1\n",
        "  linear = np.empty(numtofind, dtype=float)\n",
        "  for i in range(0,numtofind):\n",
        "    linear[i] = float((Dateslisted[i]-Firstdate).days)/float(dayrange)\n",
        "  return linear\n",
        "\n",
        "def WeeklyTimeEncoding(Dateslisted):\n",
        "  numtofind = len(Dateslisted)\n",
        "  costheta = np.empty(numtofind, dtype=float)\n",
        "  sintheta = np.empty(numtofind, dtype=float)\n",
        "  for i in range(0,numtofind):\n",
        "    j = Dateslisted[i].date().weekday()\n",
        "    theta = float(j)*2.0*math.pi/7.0\n",
        "    costheta[i] = math.cos(theta)\n",
        "    sintheta[i] = math.sin(theta)\n",
        "  return costheta, sintheta\n",
        "\n",
        "def AnnualTimeEncoding(Dateslisted): \n",
        "  numtofind = len(Dateslisted)\n",
        "  costheta = np.empty(numtofind, dtype=float)\n",
        "  sintheta = np.empty(numtofind, dtype=float)\n",
        "  for i in range(0,numtofind):\n",
        "    runningdate = Dateslisted[i]\n",
        "    year = runningdate.year\n",
        "    datebeginyear = datetime(year, 1, 1)\n",
        "    displacement = (runningdate-datebeginyear).days\n",
        "    daysinyear = (datetime(year,12,31)-datebeginyear).days+1\n",
        "    if displacement >= daysinyear:\n",
        "      printexit(\"EXIT Bad Date \", runningdate)\n",
        "    theta = float(displacement)*2.0*math.pi/float(daysinyear)\n",
        "    costheta[i] = math.cos(theta)\n",
        "    sintheta[i] = math.sin(theta)\n",
        "  return costheta, sintheta\n",
        "\n",
        "# Dates set up in Python datetime format as Python LISTS\n",
        "# All encodings are Numpy arrays\n",
        "InitialDate = datetime(2020,2,1)\n",
        "FinalDate = datetime(2020,5,25)\n",
        "Numberofdays = (FinalDate-InitialDate).days + 1\n",
        "print(\"Total number of Days \" + str(Numberofdays))\n",
        "if Numberofdays != (Num_Seq + Tseq):\n",
        "  printexit(\"EXIT Wrong Number of days \" + str(Num_Seq + Tseq))\n",
        "\n",
        "Dateslist = []\n",
        "# add one to include predicted data of last sequence\n",
        "for i in range(0,Numberofdays+1):\n",
        "  Dateslist.append(InitialDate+timedelta(days=i))\n",
        "\n",
        "LinearoverLocationEncoding = LinearLocationEncoding(Nloc)\n",
        "LinearovertimeEncoding = LinearTimeEncoding(Dateslist)\n",
        "CosWeeklytimeEncoding, SinWeeklytimeEncoding = WeeklyTimeEncoding(Dateslist)\n",
        "CosAnnualtimeEncoding, SinAnnualtimeEncoding = AnnualTimeEncoding(Dateslist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of Days 115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANMrg0vjoPxS",
        "colab_type": "text"
      },
      "source": [
        "Add in Temporal Position Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I977Ffv_obEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "addweeklyposition = True\n",
        "addlineartimeposition = True\n",
        "addlinearlocationposition = True\n",
        "NpropperseqTOT = Npropperseq\n",
        "Numberpropaddons = 0\n",
        "if addweeklyposition:\n",
        "  NpropperseqTOT +=2\n",
        "  Numberpropaddons +=2\n",
        "if addlineartimeposition:\n",
        "  NpropperseqTOT +=1\n",
        "  Numberpropaddons +=1\n",
        "  actuallineartimeposition = NpropperseqTOT-1\n",
        "if addlinearlocationposition:\n",
        "  NpropperseqTOT +=1\n",
        "  Numberpropaddons +=1\n",
        "RawInputSequencesTOT = np.empty([Num_Seq, Nloc, Tseq, NpropperseqTOT], dtype =np.float32)\n",
        "\n",
        "for i in range(0,Num_Seq):\n",
        "  for j in range(0,Nloc):\n",
        "    for k in range(0,Tseq):\n",
        "      for l in range(0,Npropperseq):\n",
        "        RawInputSequencesTOT[i,j,k,l] = RawInputSequences[i,j,k,l]\n",
        "      if addweeklyposition:\n",
        "        RawInputSequencesTOT[i,j,k,Npropperseq] = CosWeeklytimeEncoding[i+k]\n",
        "        RawInputSequencesTOT[i,j,k,Npropperseq+1] = SinWeeklytimeEncoding[i+k]\n",
        "      if addlineartimeposition:\n",
        "        RawInputSequencesTOT[i,j,k,actuallineartimeposition] = LinearovertimeEncoding[i+k]\n",
        "      if addlinearlocationposition:\n",
        "        RawInputSequencesTOT[i,j,k,NpropperseqTOT-1] = LinearoverLocationEncoding[j]\n",
        "\n",
        "Numberpredaddons = 0\n",
        "LocationPredictions = True\n",
        "if LocationPredictions:\n",
        "  Numberpredaddons = Numberpropaddons\n",
        "NpredperseqTOT = Npredperseq + Numberpredaddons\n",
        "RawInputPredictionsTOT = np.empty([Num_Seq, Nloc, NpredperseqTOT], dtype =np.float32)\n",
        "\n",
        "if LocationPredictions:\n",
        "  if addweeklyposition:\n",
        "    Predictionname.append('weeklycostheta')\n",
        "    Predictionnamelookup['weeklycostheta'] = Npredperseq\n",
        "    Predictionname.append('weeklysintheta')\n",
        "    Predictionnamelookup['weeklysintheta'] = Npredperseq+1\n",
        "  if addlineartimeposition:\n",
        "    actualposition = Npredperseq\n",
        "    if addweeklyposition:\n",
        "      actualposition +=2\n",
        "    Predictionname.append('lineartime')\n",
        "    Predictionnamelookup['lineartime'] = actualposition\n",
        "  if addlinearlocationposition:\n",
        "    Predictionname.append('linearlocationtime')\n",
        "    Predictionnamelookup['linearlocationtime'] = NpredperseqTOT-1                      \n",
        "\n",
        "for i in range(0,Num_Seq):\n",
        "  for j in range(0,Nloc):\n",
        "    for l in range(0,Npredperseq):\n",
        "      RawInputPredictionsTOT[i,j,l] = RawInputPredictions[i,j,l]\n",
        "    if LocationPredictions:\n",
        "      if addweeklyposition:\n",
        "        RawInputPredictionsTOT[i,j,Npredperseq] = CosWeeklytimeEncoding[i+Tseq]\n",
        "        RawInputPredictionsTOT[i,j,Npredperseq+1] = SinWeeklytimeEncoding[i+Tseq]\n",
        "      if addlineartimeposition:\n",
        "        RawInputPredictionsTOT[i,j,actualposition] = LinearovertimeEncoding[i+Tseq]\n",
        "      if addlinearlocationposition:\n",
        "        RawInputPredictionsTOT[i,j,NpredperseqTOT-1] = LinearoverLocationEncoding[j]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CdCNdQ_yGWV",
        "colab_type": "text"
      },
      "source": [
        "## General Control Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bcRp7VcQ5m6g",
        "colab": {}
      },
      "source": [
        "Num_Seq_TimeandLoc = Num_Seq * Nloc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V88mmqms1pq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "9db6adcb-1305-4f3e-8e4f-fc234e119288"
      },
      "source": [
        "print(\"Size of sequence window Tseq \", str(Tseq))\n",
        "print(\"Number of Sequences in time Num_Seq \", str(Num_Seq))\n",
        "print(\"Number of locations Nloc \", str(Nloc))\n",
        "print(\"Number of Sequences in Location and Time\", str(Num_Seq_TimeandLoc))\n",
        "print(\"Length of each sequence Tseq \", str(Tseq))\n",
        "print(\"Number of internal properties per sequence including static or dynamic Npropperseq \", str(Npropperseq))\n",
        "print(\"Is there explicit temporal weekly encoding \" + str(addweeklyposition))\n",
        "print(\"Is there explicit temporal linear encoding \" + str(addlinearposition))\n",
        "print(\"Number of internal properties per sequence adding in explicit temporal position encoding \", str(NpropperseqTOT))\n",
        "print(\"Total number of predictions per sequence NpredperseqTOT \", str(NpredperseqTOT))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of sequence window Tseq  9\n",
            "Number of Sequences in time Num_Seq  106\n",
            "Number of locations Nloc  110\n",
            "Number of Sequences in Location and Time 11660\n",
            "Length of each sequence Tseq  9\n",
            "Number of internal properties per sequence including static or dynamicNpropperseq  35\n",
            "Is there explicit temporal weekly encoding True\n",
            "Is there explicit temporal linear encoding True\n",
            "Number of internal properties per sequence adding in explicit temporal position encoding  38\n",
            "Total number of predictions per sequence Npredtotperseq  30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blSLh5R9ftlZ",
        "colab_type": "text"
      },
      "source": [
        "##Plot and Analyze DL Time Series Fits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikdmffIpA6AC",
        "colab_type": "text"
      },
      "source": [
        "## Useful Time series utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WsspqAef_yR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DLprediction(Xin, yin, DLmodel):\n",
        "  # Input is [Num_Seq] [Nloc] [Tseq] [NpropperseqTOT]\n",
        "  # Input Predictions are [Num_Seq] [NLoc] [NpredperseqTOT]\n",
        "    FitPredictions = np.zeros([Num_Seq, Nloc, NpredperseqTOT], dtype =np.float32)\n",
        "    # Compare to RawInputPredictionsTOT\n",
        "\n",
        "    RMSEbyclass = np.zeros([NpredperseqTOT], dtype=np.float64)\n",
        "    RMSVbyclass = np.zeros([NpredperseqTOT], dtype=np.float64)\n",
        "    AbsEbyclass = np.zeros([NpredperseqTOT], dtype=np.float64)\n",
        "    AbsVbyclass = np.zeros([NpredperseqTOT], dtype=np.float64)\n",
        "    ObsVbytimeandclass = np.zeros([Num_Seq, NpredperseqTOT], dtype=np.float64)\n",
        "    Predbytimeandclass = np.zeros([Num_Seq, NpredperseqTOT], dtype=np.float64)\n",
        "    count = np.zeros([NpredperseqTOT], dtype=np.float64)\n",
        "\n",
        "    for iseq in range(0, Num_Seq):\n",
        "      for iloc in range(0,Nloc):\n",
        "        xx = Xin[iseq,iloc]\n",
        "        yy = yin[iseq,iloc]\n",
        "        xx = xx.reshape(1, Tseq, NpropperseqTOT)\n",
        "        yyhat = DLmodel.predict(xx, verbose=LSTMverbose)\n",
        "        yyhat = yyhat.reshape(NpredperseqTOT)\n",
        "        FitPredictions[iseq,iloc,:] = yyhat\n",
        "        for i in range(0,NpredperseqTOT):\n",
        "          if(math.isnan(yy[i])):\n",
        "            continue\n",
        "          RMSEbyclass[i] += (yy[i]-yyhat[i])**2\n",
        "          AbsEbyclass[i] += abs(yy[i] - yyhat[i])\n",
        "          RMSVbyclass[i] += yy[i]**2\n",
        "          AbsVbyclass[i] += abs(yy[i])\n",
        "          count[i] += 1.0\n",
        "          ObsVbytimeandclass [iseq,i] += yy[i]\n",
        "          Predbytimeandclass [iseq,i] += yyhat[i]\n",
        "\n",
        "    ObsvPred = np.sum( np.abs(ObsVbytimeandclass-Predbytimeandclass) , axis=0)\n",
        "    TotalObs = np.sum( ObsVbytimeandclass , axis=0)\n",
        "    SummedEbyclass = np.divide(ObsvPred,TotalObs)\n",
        "    RMSEbyclass1 = np.sqrt(np.divide(RMSEbyclass,count))\n",
        "    RMSEbyclass2 = np.sqrt(np.divide(RMSEbyclass,RMSVbyclass))\n",
        "    RelEbyclass = np.divide(AbsEbyclass, AbsVbyclass)\n",
        "    extra = [' ',' ']\n",
        "    for i in range(0,NpredperseqTOT):\n",
        "      print('RMSE % ' +str(i) + ' ' + Predictionname[i] + ' ' + str(round(count[i],0)) + ' ' + str(round(100.0*RMSEbyclass1[i],4))  + ' ' + str(round(100.0*RMSEbyclass2[i],4))\n",
        "      + ' ' + str(round(100.0*RelEbyclass[i],4)) + ' ' + str(round(100.0*SummedEbyclass[i],4)) )\n",
        "      if i <= 1:\n",
        "        extra[i] = 'Unnormed RMSE% ' + str(round(100.0*RMSEbyclass1[i],4)) + ' Normed RMSE% ' + str(round(100.0*SummedEbyclass[i],4))\n",
        "    Location_summed_plot(yin, FitPredictions, ex_cases=extra[0], ex_deaths = extra[1])\n",
        "\n",
        "    return FitPredictions   \n",
        "\n",
        "def Location_summed_plot(Observations, FitPredictions, fill=True, ex_cases = '',ex_deaths = ''):\n",
        "    # Only deal with futures as days; plot sum over locations\n",
        "    basiclength = Num_Seq\n",
        "    predictlength = LengthFutures\n",
        "    if not UseFutures:\n",
        "        predictlength = 0\n",
        "    totallength = basiclength + predictlength\n",
        "    real = np.zeros([2,basiclength])\n",
        "    predictsmall = np.zeros([2,basiclength])\n",
        "    predict = np.zeros([2,totallength])   \n",
        "\n",
        "    \n",
        "    for casesdeaths in range(0,2):\n",
        "      for iloc in range(0,Nloc):\n",
        "        for itime in range (0,Num_Seq):\n",
        "          real[casesdeaths,itime] += Observations[itime, iloc, casesdeaths]\n",
        "          predict[casesdeaths,itime] += FitPredictions[itime, iloc, casesdeaths]\n",
        "        for ifuture in range(0,LengthFutures):\n",
        "          predict[casesdeaths,Num_Seq+ifuture] += FitPredictions[itime, iloc, casesdeaths + 2 + 2*ifuture]\n",
        "      for itime in range(0,basiclength):\n",
        "          predictsmall[casesdeaths,itime] = predict[casesdeaths,itime]\n",
        "        \n",
        "    error = np.absolute(real - predictsmall)\n",
        "    xsmall = np.arange(0,Num_Seq)\n",
        "\n",
        "    plottype = ['Cases','Fatalities']\n",
        "    plt.rcParams[\"figure.figsize\"] = [18,5]\n",
        "    figure, (ax1,ax2) = plt.subplots(nrows=1, ncols=2)\n",
        "  #  eachplt = plt\n",
        "    for iplot in range (0,2):\n",
        "      eachplt = ax1\n",
        "      if iplot == 1:\n",
        "        eachplt = ax2\n",
        "      sumreal = 0.0\n",
        "      sumerror = 0.0\n",
        "      for itime in range(0,Num_Seq):\n",
        "        sumreal += abs(real[iplot,itime])\n",
        "        sumerror += error[iplot,itime]\n",
        "      c_error = round(100.0*sumerror/sumreal,2)\n",
        "\n",
        "      eachplt.plot(predict[iplot,:], label='prediction')\n",
        "      eachplt.plot(real[iplot,:], label=f'real')\n",
        "      eachplt.plot(error[iplot,:], label=f'error', color=\"red\")\n",
        "\n",
        "      if fill:\n",
        "          eachplt.fill_between(xsmall, predictsmall[iplot,:], real[iplot,:], alpha=0.1, color=\"grey\")\n",
        "          eachplt.fill_between(xsmall, error[iplot,:], alpha=0.05, color=\"red\")\n",
        "\n",
        "      extrastring = ex_cases\n",
        "      if iplot == 1:\n",
        "        extrastring = ex_deaths\n",
        "    #  extrastring = f\"Length={Num_Seq}, Cumulative Results {plottype[iplot]},  error={c_error}% \" + extrastring\n",
        "      extrastring = f\"Length={Num_Seq}, Cumulative Results {plottype[iplot]}, \" + extrastring\n",
        "      eachplt.set_title(extrastring)\n",
        "      eachplt.set_xlabel(\"Days\")\n",
        "      eachplt.set_ylabel(plottype[iplot])\n",
        "      eachplt.grid(True)\n",
        "      eachplt.legend()\n",
        "    figure.tight_layout()\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJylkkL9AvsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_lossGCF1(y_actual,y_pred):\n",
        "    flagGCF = tf.math.is_nan(y_actual)\n",
        "    y_actual = y_actual[tf.math.logical_not(flagGCF)]\n",
        "    y_pred = y_pred[tf.math.logical_not(flagGCF)]\n",
        "    tensordiff = tf.math.square(y_actual-y_pred)\n",
        "    return tf.math.reduce_mean(tensordiff)\n",
        "    \n",
        "def custom_lossGCF4(y_actual,y_pred):\n",
        "    tensordiff = y_actual-y_pred\n",
        "    newtensordiff = tf.where(tf.math.is_nan(tensordiff), tf.zeros_like(tensordiff), tensordiff)\n",
        "    return tf.math.reduce_mean(tf.math.square(newtensordiff))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIB3yMlo7kFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffleDLinput(Xin,yin):\n",
        "  np.random.seed(int.from_bytes(os.urandom(4), byteorder='little'))\n",
        "\n",
        "  trainingorder = list(range(0, len(Xin)))\n",
        "  random.shuffle(trainingorder)\n",
        "  Xinternal = list()\n",
        "  yinternal = list()\n",
        "  for i in trainingorder:\n",
        "    Xinternal.append(Xin[i])\n",
        "    yinternal.append(yin[i])\n",
        "  X = np.array(Xinternal)\n",
        "  y = np.array(yinternal)\n",
        "  return X, y\n",
        "\n",
        "def finalizeDL(ActualModel, ActualmodelResult, usedvalidationfrac, X_in, y_in):\n",
        "\n",
        "  histlen = len(ActualmodelResult.history['loss'])\n",
        "\n",
        "  trainloss = ActualmodelResult.history['loss'][histlen-1]\n",
        "  plt.rcParams[\"figure.figsize\"] = [8,4]\n",
        "  plt.plot(ActualmodelResult.history['loss'])\n",
        "  if usedvalidationfrac > 0.001:\n",
        "    valloss = ActualmodelResult.history['val_loss'][histlen-1]\n",
        "    plt.plot(ActualmodelResult.history['val_loss'])\n",
        "  else:\n",
        "    valloss = 0.0\n",
        "  plt.title('model loss ' + str(round(trainloss,6)) + ' Val ' + str(round(valloss,6)))\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  FitPredictions = DLprediction(X_in, y_in,ActualModel)\n",
        "  return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMIeYApPybFA",
        "colab_type": "text"
      },
      "source": [
        "# Standalone LSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33FLmGmcilz5",
        "colab_type": "text"
      },
      "source": [
        "## LSTM Control Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds28euHRi5vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UseFutures = True\n",
        "CustomLoss = 1         # Can be 0 1 4\n",
        "UseClassweights = True\n",
        "LengthFutures = int(round((Npredperseq-2)/2))\n",
        "\n",
        "\n",
        "if(Npredperseq <=2):\n",
        "  useFutures = False\n",
        "  CustomLoss = 0\n",
        "  UseClassweights = False\n",
        "\n",
        "number_of_LSTMworkers = 1\n",
        "LSTMepochs = 200\n",
        "LSTMbatch_size = 110\n",
        "\n",
        "LSTMactivationvalue = \"selu\"\n",
        "LSTMrecurrent_activation = \"sigmoid\"\n",
        "LSTMoptimizer = 'adam'\n",
        "LSTMdropout1=0.2\n",
        "LSTMrecurrent_dropout1 = 0.2\n",
        "LSTMdropout2=0.2\n",
        "LSTMrecurrent_dropout2 = 0.2\n",
        "number_LSTMnodes= 16\n",
        "LSTMFinalMLP = 64\n",
        "LSTMInitialMLP = 32\n",
        "LSTMThirdLayer = False\n",
        "\n",
        "LSTMverbose = 0\n",
        "LSTMvalidationfrac = 0.2\n",
        "bestmethod = 2\n",
        "if LSTMvalidationfrac < 0.001:\n",
        "    bestmethod = 1\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToZJjmB2DWc2",
        "colab_type": "text"
      },
      "source": [
        "## LSTM Utilities and code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRlpZa-8cl4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def checkNaN(y):\n",
        "  countNaN = 0\n",
        "  countnotNaN = 0\n",
        "  for i in range(0,y.shape[0]):\n",
        "      for j in range(0,y.shape[1]):\n",
        "          if(np.math.isnan(y[i,j])):\n",
        "              countNaN += 1\n",
        "          else:\n",
        "              countnotNaN += 1\n",
        "  percent = (100.0*countNaN)/(countNaN + countnotNaN)\n",
        "  print(' is NaN ',str(countNaN),' percent ',str(round(percent,2)),' not NaN ', str(countnotNaN))\n",
        "    \n",
        "def get_model_summary(model):  \n",
        "  stream = io.StringIO()\n",
        "  model.summary(print_fn=lambda x: stream.write(x + '\\n'))\n",
        "  summary_string = stream.getvalue()\n",
        "  stream.close()\n",
        "  return summary_string\n",
        "\n",
        "def setLSTMinput():\n",
        "  # Initial data is Flatten([Num_Seq][Nloc]) [Tseq] with values [Nprop-Sel + Nforcing + Add(ExPosEnc-Selin)] starting with   RawInputSequencesTOT\n",
        "  # Predictions are Flatten([Num_Seq] [Nloc]) [Predvals=Npred+ExPosEnc-Selout] [Predtimes = Forecast-time range] starting with RawInputPredictionsTOT\n",
        "  X_predict = RawInputSequencesTOT.reshape(Num_Seq_TimeandLoc,Tseq,NpropperseqTOT)\n",
        "  y_predict = RawInputPredictionsTOT.reshape(Num_Seq_TimeandLoc,NpredperseqTOT)\n",
        "  return X_predict, y_predict\n",
        "\n",
        "def InitializeLSTM(message,processindex,y_predict):\n",
        "  if( processindex == 0 ):\n",
        "      print(message + \" Window Size \", Tseq, \" Number of samples over time that sequence starts at and location:\", Num_Seq_TimeandLoc, \n",
        "            \"Number input features per sequence:\", NpropperseqTOT, \n",
        "            \"Number of predicted outputs per sequence:\", NpredperseqTOT, \n",
        "            \"batch_size:\", LSTMbatch_size, \n",
        "            \"n_nodes:\", number_LSTMnodes, \n",
        "            \"epochs:\", LSTMepochs)\n",
        "      checkNaN(y_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh1D1xxEszcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyLSTMmodel(tf.keras.Model):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(MyLSTMmodel, self).__init__(**kwargs)\n",
        "    self.fullLSTM = MyLSTMlayer()\n",
        "\n",
        "  def call(self, inputs):  \n",
        "    outputs = self.fullLSTM(inputs)\n",
        "    return outputs\n",
        "\n",
        "class MyLSTMlayer(tf.keras.layers.Layer):\n",
        "# Class for a simple multiple layer LSTM with FCN at start and end\n",
        "# All parameters defined externally\n",
        "# structured so MyLSTMlayer can be used standalone or in part of a transformer\n",
        "\n",
        "  def __init__(self, **kwargs):\n",
        "    super(MyLSTMlayer, self).__init__(**kwargs)\n",
        "    self.dense_1 = tf.keras.layers.Dense(LSTMInitialMLP, activation=LSTMactivationvalue)\n",
        "    self.LSTM_1 =tf.keras.layers.LSTM(number_LSTMnodes, recurrent_dropout= LSTMrecurrent_dropout1, dropout = LSTMdropout1,\n",
        "                  activation= LSTMactivationvalue , return_sequences=True, recurrent_activation= LSTMrecurrent_activation)\n",
        "    self.LSTM_2 =tf.keras.layers.LSTM(number_LSTMnodes, recurrent_dropout= LSTMrecurrent_dropout1, dropout = LSTMdropout1,\n",
        "        activation= LSTMactivationvalue , return_sequences=LSTMThirdLayer, recurrent_activation= LSTMrecurrent_activation)\n",
        "    if(LSTMThirdLayer):\n",
        "      self.LSTM_3 =tf.keras.layers.LSTM(number_LSTMnodes, recurrent_dropout= LSTMrecurrent_dropout1, dropout = LSTMdropout1,\n",
        "                    activation= LSTMactivationvalue , return_sequences=False, recurrent_activation= LSTMrecurrent_activation)\n",
        "    self.dense_2 = tf.keras.layers.Dense(LSTMFinalMLP, activation=LSTMactivationvalue)\n",
        "    self.dense_f = tf.keras.layers.Dense(NpredperseqTOT)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    if(LSTMInitialMLP > 0):\n",
        "      Runningdata = self.dense_1(inputs)\n",
        "      Runningdata = self.LSTM_1(Runningdata)\n",
        "    else:\n",
        "      Runningdata = self.LSTM_1(inputs)\n",
        "    Runningdata = self.LSTM_2(Runningdata)\n",
        "    if(LSTMThirdLayer):\n",
        "      Runningdata = self.LSTM_3(Runningdata)\n",
        "    if(LSTMFinalMLP > 0):\n",
        "      Runningdata = self.dense_2(Runningdata)\n",
        "    Outputdata = self.dense_f(Runningdata)\n",
        "    return Outputdata\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3Tp0VAn-orp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RunLSTMClassVersion():\n",
        "  # Run the LSTM model defined by Model and Layer class\n",
        "\n",
        "\n",
        "  X_predict, y_predict = setLSTMinput()\n",
        "  InitializeLSTM('Class Version ',processindex,y_predict)\n",
        "\n",
        "  X_train, y_train = shuffleDLinput(X_predict, y_predict)\n",
        "\n",
        "  myLSTMmodel = MyLSTMmodel(name ='myLSTMmodel')\n",
        "  if CustomLoss == 0:\n",
        "      myLSTMmodel.compile(loss='mse', optimizer= LSTMoptimizer)\n",
        "  if CustomLoss == 1:\n",
        "      myLSTMmodel.compile(loss= custom_lossGCF1, optimizer= LSTMoptimizer)\n",
        "  if CustomLoss == 4:    \n",
        "      myLSTMmodel.compile(loss= custom_lossGCF4, optimizer= LSTMoptimizer)\n",
        "\n",
        "  the_callbacks = [TqdmCallback(),]\n",
        "\n",
        "  if UseClassweights:   \n",
        "      cw = {}\n",
        "      for i in range(0,NpredperseqTOT):\n",
        "        cw[i] = Predictionwgt[i]     \n",
        "      modelresult = myLSTMmodel.fit(X_train, y_train,\n",
        "            epochs=LSTMepochs,\n",
        "            batch_size=LSTMbatch_size,\n",
        "            class_weight = cw,\n",
        "            verbose=LSTMverbose,\n",
        "            validation_split=LSTMvalidationfrac,\n",
        "            callbacks=the_callbacks\n",
        "            )\n",
        "  else:\n",
        "      modelresult = myLSTMmodel.fit(X_train, y_train,\n",
        "            epochs=LSTMepochs,\n",
        "            batch_size=LSTMbatch_size,\n",
        "            verbose=LSTMverbose,\n",
        "            validation_split=LSTMvalidationfrac,\n",
        "            callbacks=the_callbacks\n",
        "            ) \n",
        "  myLSTMmodel.summary()\n",
        "  finalizeDL(myLSTMmodel,modelresult,LSTMvalidationfrac,RawInputSequencesTOT, RawInputPredictionsTOT)\n",
        "  return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-KKpE09yyow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9edf5e6a10c344b3b9906c48dc59ede8",
            "afc7fca89d1d4b608095233fa729aa37",
            "195b5150ea5d473c82c15044b39f20e6",
            "b6c0dcf1d8a24c38ae896553a58a7d9f",
            "af70ebe247e74160a9dcce7d5b276c59",
            "b326b64fc150444482500e8d8e7b43e2",
            "e81b6ac1d12e4c4fbcc37ed47df0880e",
            "b0d8251d8f714823b2246a99d2787444",
            "531d198d0895483192e7b9867a5ca6fe",
            "ff2ebe43fb534362893ad45d6b469692",
            "130ecfb87b344d479c7fe478196a359a",
            "9bd8d74c03454e28a5e996a9708b1313",
            "65b9877d7b2b48f39bebe928e57bbdc2",
            "840e4a9b2c0448038caa919733dc2c73",
            "fc9a6365e7dd40d1817a7012ba1379c5",
            "0efd48e69e954497b5dd68239b8ef33d"
          ]
        },
        "outputId": "65e1ce93-c470-4ed4-ac6e-53e56d6cac6b"
      },
      "source": [
        "def StandaloneLSTM():\n",
        "# run pure LSTM with no attention (transformer) with simple Keras sequential model\n",
        "\n",
        "  X_predict, y_predict = setLSTMinput()\n",
        "  X_train, y_train = shuffleDLinput(X_predict, y_predict)\n",
        "\n",
        "  # n_timesteps=n_steps_in=Tseq, \n",
        "  # n_features= NpropperseqTOT,  \n",
        "  # n_outputs = NpredperseqTOT       \n",
        "  InitializeLSTM('Keras Sequential Version ',processindex,y_predict)\n",
        "\n",
        "  # define model\n",
        "  StandaloneLSTMmodel = Sequential()\n",
        "  \n",
        "  if(LSTMInitialMLP > 0):\n",
        "      StandaloneLSTMmodel.add(Dense(LSTMInitialMLP, activation=LSTMactivationvalue, input_shape=(Tseq,NpropperseqTOT)))\n",
        "      nextround = LSTMInitialMLP\n",
        "  else:\n",
        "      nextround = NpropperseqTOT\n",
        "\n",
        "  StandaloneLSTMmodel.add(LSTM(number_LSTMnodes, recurrent_dropout= LSTMrecurrent_dropout1, dropout = LSTMdropout1,\n",
        "                  activation= LSTMactivationvalue , return_sequences=True, recurrent_activation= LSTMrecurrent_activation,\n",
        "                  input_shape=(Tseq, nextround)))\n",
        "\n",
        "  if(LSTMThirdLayer):\n",
        "      StandaloneLSTMmodel.add(LSTM(number_LSTMnodes, recurrent_dropout= LSTMrecurrent_dropout2, dropout = LSTMdropout2,\n",
        "                  activation= LSTMactivationvalue , return_sequences=True, recurrent_activation= LSTMrecurrent_activation,\n",
        "                  input_shape=(Tseq, number_LSTMnodes)))\n",
        "      StandaloneLSTMmodel.add(LSTM(number_LSTMnodes, recurrent_dropout= LSTMrecurrent_dropout2, dropout = LSTMdropout2,\n",
        "                      activation= LSTMactivationvalue , recurrent_activation=LSTMrecurrent_activation,\n",
        "                      input_shape=(Tseq, number_LSTMnodes)))\n",
        "  else:\n",
        "      StandaloneLSTMmodel.add(LSTM(number_LSTMnodes, recurrent_dropout= LSTMrecurrent_dropout2, dropout = LSTMdropout2,\n",
        "              activation= LSTMactivationvalue, recurrent_activation=LSTMrecurrent_activation,\n",
        "              input_shape=(Tseq, number_LSTMnodes)))\n",
        "      \n",
        "  if(LSTMFinalMLP > 0):\n",
        "      StandaloneLSTMmodel.add(Dense(LSTMFinalMLP, activation=LSTMactivationvalue))\n",
        "  StandaloneLSTMmodel.add(Dense(NpredperseqTOT))\n",
        "  \n",
        "  if CustomLoss == 0:\n",
        "      StandaloneLSTMmodel.compile(loss='mse', optimizer= LSTMoptimizer)\n",
        "  if CustomLoss == 1:\n",
        "      StandaloneLSTMmodel.compile(loss= custom_lossGCF1, optimizer= LSTMoptimizer)\n",
        "  if CustomLoss == 4:    \n",
        "      StandaloneLSTMmodel.compile(loss= custom_lossGCF4, optimizer= LSTMoptimizer)\n",
        "\n",
        "  modelsummarystring = get_model_summary(StandaloneLSTMmodel)\n",
        "  if( processindex == 0 ):\n",
        "      print(modelsummarystring)\n",
        "\n",
        "  the_callbacks = [TqdmCallback(),]\n",
        "  if UseClassweights:   \n",
        "      cw = {}\n",
        "      for i in range(0,NpredperseqTOT):\n",
        "        cw[i] = Predictionwgt[i]     \n",
        "      modelresult = StandaloneLSTMmodel.fit(X_train, y_train,\n",
        "            epochs=LSTMepochs,\n",
        "            batch_size=LSTMbatch_size,\n",
        "            class_weight = cw,\n",
        "            verbose=LSTMverbose,\n",
        "            validation_split=LSTMvalidationfrac,\n",
        "            callbacks=the_callbacks\n",
        "            )\n",
        "  else:\n",
        "      modelresult = StandaloneLSTMmodel.fit(X_train, y_train,\n",
        "            epochs=LSTMepochs,\n",
        "            batch_size=LSTMbatch_size,\n",
        "            verbose=LSTMverbose,\n",
        "            validation_split=LSTMvalidationfrac,\n",
        "            callbacks=the_callbacks\n",
        "            )  \n",
        "  finalizeDL(StandaloneLSTMmodel, modelresult, LSTMvalidationfrac,RawInputSequencesTOT, RawInputPredictionsTOT)\n",
        "  return\n",
        "\n",
        "# RUN PURE LSTM\n",
        "processindex = 0\n",
        "standaloneLSTMrun = False\n",
        "ClassLSTMrun = True\n",
        "if standaloneLSTMrun:\n",
        "  StandaloneLSTM()\n",
        "if ClassLSTMrun:\n",
        "  RunLSTMClassVersion()\n",
        "if standaloneLSTMrun or ClassLSTMrun:\n",
        "  sys.exit(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class Version  Window Size  9  Number of samples over time that sequence starts at and locatin: 11660 Number input features per sequence: 38 Number of predicted outputs per sequence: 30 batch_size: 110 n_nodes: 16 epochs: 200\n",
            " is NaN  52360  percent  14.97  not NaN  297440\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9edf5e6a10c344b3b9906c48dc59ede8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "531d198d0895483192e7b9867a5ca6fe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model: \"myLSTMmodel\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "my_lst_mlayer (MyLSTMlayer)  multiple                  9534      \n",
            "=================================================================\n",
            "Total params: 9,534\n",
            "Trainable params: 9,534\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "RMSE % 0 CasesNextday 11660.0 2.775 27.2302 24.9874 5.9164\n",
            "RMSE % 1 DeathsNextday 11660.0 3.0649 40.0507 48.3444 13.2418\n",
            "RMSE % 2 Casesday2 11220.0 2.8211 27.1557 24.8287 6.1597\n",
            "RMSE % 3 Deathsday2 11220.0 3.103 39.7761 52.6015 16.64\n",
            "RMSE % 4 Casesday3 11000.0 2.8427 27.0937 24.6903 5.6836\n",
            "RMSE % 5 Deathsday3 11000.0 3.1161 39.5508 48.6563 12.4822\n",
            "RMSE % 6 Casesday4 10780.0 2.8708 27.0868 24.8039 5.532\n",
            "RMSE % 7 Deathsday4 10780.0 3.1606 39.7119 48.1993 12.8719\n",
            "RMSE % 8 Casesday5 10560.0 2.9046 27.125 25.1315 6.5207\n",
            "RMSE % 9 Deathsday5 10560.0 3.181 39.5587 47.9454 10.8307\n",
            "RMSE % 10 Casesday6 10340.0 2.9499 27.2592 25.9392 8.4192\n",
            "RMSE % 11 Deathsday6 10340.0 3.2072 39.4661 47.3169 10.7375\n",
            "RMSE % 12 Casesday7 10120.0 2.9474 26.945 24.9913 6.0464\n",
            "RMSE % 13 Deathsday7 10120.0 3.2443 39.4966 47.7883 11.8382\n",
            "RMSE % 14 Casesday8 9900.0 2.9888 27.0241 24.8475 5.4751\n",
            "RMSE % 15 Deathsday8 9900.0 3.2779 39.469 47.4861 11.1851\n",
            "RMSE % 16 Casesday9 9680.0 3.0245 27.0423 24.708 5.1971\n",
            "RMSE % 17 Deathsday9 9680.0 3.3374 39.7362 47.2068 11.4629\n",
            "RMSE % 18 Casesday10 9460.0 3.0772 27.1983 25.5281 6.7136\n",
            "RMSE % 19 Deathsday10 9460.0 3.3454 39.3774 47.2052 10.4033\n",
            "RMSE % 20 Casesday11 9240.0 3.1622 27.6236 25.3422 7.0205\n",
            "RMSE % 21 Deathsday11 9240.0 3.4191 39.7746 49.4697 13.4922\n",
            "RMSE % 22 Casesday12 9020.0 3.1504 27.1917 24.6783 4.8892\n",
            "RMSE % 23 Deathsday12 9020.0 3.4672 39.8525 47.4149 10.4714\n",
            "RMSE % 24 Casesday13 8800.0 3.216 27.4184 24.9247 5.9647\n",
            "RMSE % 25 Deathsday13 8800.0 3.4715 39.4131 46.9039 9.9903\n",
            "RMSE % 26 Casesday14 8580.0 3.2851 27.658 25.2226 6.952\n",
            "RMSE % 27 Deathsday14 8580.0 3.5349 39.63 48.3609 11.336\n",
            "RMSE % 28 Casesday15 8360.0 3.3188 27.5829 24.9872 6.2884\n",
            "RMSE % 29 Deathsday15 8360.0 3.5854 39.6795 48.0092 10.4862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABNsAAAFgCAYAAACCIH/AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeZhUxbXAf6d79oWBGfZ12JEdQQEVRVE07kafRpMoMcYkJsbEJMbsZjebiXlqEl9iNHHXiFvEBZHghrKIgIDs+z4wK7N2n/dH3R56enp6ema6GRjO7/vmm75Vt9Zbt+rcU6eqRFUxDMMwDMMwDMMwDMMwDKPt+No7A4ZhGIZhGIZhGIZhGIbRUTBlm2EYhmEYhmEYhmEYhmEkCFO2GYZhGIZhGIZhGIZhGEaCMGWbYRiGYRiGYRiGYRiGYSQIU7YZhmEYhmEYhmEYhmEYRoIwZZthGIZhGIZhGIZhGIZhJAhTtjWBiBSKiIpISnvnpSMgIvNF5IZWhu0vIuUi4k90vo40IjJdRLa3dz6M5OL1HUPaOx/G0U1b+kXDMGJjclxiMTnOcazJcSJyh4g87P1u9jl4/oOOXA47NiYPGm3lWOtzjIYclco2EdksImd3hDRFZLSIvCIi+0VEo/jni8hsEakQkS0ick2EfzcReVRESkTkoIg80oK007xBdp0X/2YReUBECttesuQR+SxUdauq5qhqIMHpzBKRgCdYlIrIhyJyYSLTiCMPbWp3InKNiCz2yrBLROaIyGmJzGMi8Or6rSjuR/xdb2+8D5Yq75ntF5FnRKRXmP8dnnB2S0S4Wzz3O8Lcvicim7y4tovIE02kE/p7wfPrJyILReSAiPw+Ip05IjIpRv67i8hjIrLT65feFpHJMe6fE5GHGhFZ4fn1j/Ar98r4Tc9/uogEI/yvi5GWisgKEfGFuf1cRB5sKszRitcOar0yF4vIOyIyNcx/ulfe2RHhxnnu88PcLhGRZV4/t19E5onIwCjphP6KPb8UEXncS/9lEekUFuf3ROTWZsrwoPe8w+OO+pEnIuki8gevXR0UkftEJDXM/6teX1cd7XmKSJYXZr/XLhdEuSdNRFaLCa1Jpz369mSlKSbHtZjIZ2FyXMywlRF9ZO9mwrRa6Rn5HKLF5flvbE388SAmD9Yjx7g86N3zhojsC3v/Lolxr4jIr0WkyPv7tYhImL9fnMy2U0TKROQDEekcJZ7XJWIiRUROEZH3vXDLJca3UFi9XhnmluK5FcYq79GIl+8K77nuEJG7JEzW8p6/isi4iHCzPffp3nVnb3zZ7dXjWhG5vYl0Qn+3eX4zvPa3W0Q+FRams4gsFZHcGPlPE5GnvT6gPj9h/t8QkY1eG9spTlaMOokmIlNE5DWvPe8TkafC36mINBvJgyJyv4h8LO7bY1aEn3jtc4e48Xy+iIxqqlwhjkplWwejFngS+HwT/vcCNUAP4NPAnyMe3DPAbqA/0B34XQvSfhq4GLgGyAPGAUuAGS2Io6PzrqrmAJ2B+4DHo3XsRyPiPnT/CPwS137648rQ5EBnuAG1vfMAfNVrd0OAHBq/12uBayPcrvPcARCndPoscLYX1yTg9WjphP1d5Ll/F3gIGAhcGhKmROQqYJOqLo6R9xxgETARyPfi+Y+I5ES7WVU/EZ4H4B3gKc9va4TfGCAI/Dssip0RZXgoRt4AegOfauaeZjlK2skTXr10Bd7Aq7cw9gFTRaQgzC2ynQwB/gl8EzcODMSNO+EfvU9E1HGoD/wkoF76JcCNXpwDcWPLn+Iow28i4m7qY/t2XBseDQwDTgR+EOa/E/g58EAT4e/HtccTvP/fiHLPt3F1ZhgtweS4o5tjVo7zuCiij9zZ3hk6XjhKxvljWR4EuAXopaqdcDLCw9GUGx43Apfi+rGxwEXAF8P8fwKcAkwFOnllqgqPQEQ+DaRGuOUDLwC/xfUDvwFeEJEuMfJ9APiJJMDa9ihpR+O8Z38GcBVwfYR/g3bkyY1TaSgT/QHXBk/AjTcXA+ujpRP29xvP/Y+453kucF9Yvf4KuFNVy5rJ/1vAZ3BjZSTPAyd6bWw0rv18rYl4uuDkwUJgAFAG/CPKfU3Jgx8CNwFLo/j9D65ep+HkzHeBfzWRj8Oo6lH3B2zGdRiR7j6cQL4BKMIJP/meXyHuo+A6YCuwH/h+WNhMXGdyEFgN3AZs9/z+hfvAqwTKPb+Y8bWiTENcdTdwy8YJaMPC3P6Fa5QAM7268LcivbO98vSLt56BO4CHI+rzc8A2r96+BJwELAeKgXuihY0In+Jdzwdu8H4PBuZ5z3A/8AjQOY5nkYLrQBZHlOMbwPPe73TcQLUV2AP8BchsovyzgLfCrrO8dE5qLi7cx+eLXj0cAN4EfJ6fAkPC4n0Q+Ln3e3oz7S4DeNirm2KcUqNHlLzneWH+J8bzPRnXERQDu4B7gDTPT3Cd6l6gFFgBjG5LuZtpjw3qOlob9OrpXuA/uM7xPWBw2L2Ka4PrvPTvBSSsb/gBsMUr0z+BvIi2+HmvTAu8/Lzt1UExsBE3wM/Ctfe9wHVhacdsV7hOexdOIXB9ZBuIKPN8vHfBu74J+CjyXcL1U6M8t1HAKs/9Ds/tHuCPMeq8QToRfnOA4d7vx4ErcYLNB3jvYgv7m1JgYhz3FeKUPIVN+P8YeCPsejre+xJnPhT4jtdGQn3Pz4EHw+65GPjIe+7zgRMi2uN3cH1cNV6/TZz9oBfH9d6zOwi8AgwI8zsHWINTXN0D/DfGM7qDhn3qSC8v3cLrxmuLX/Hc/MAO4EfAfM/tCmBZjDprkE6E33eAL3q/vwTc5/1+ATg1jufxIF7fF8e9iwnrz3DKhW1R7mvwPD23EV4b7BQj/oHec/lES9qU/bXuD5PjTI4zOS6mHNfUe4L7WHwR9yF40Pvd1/P7BW4MrfLSu8dzv9t7xqU4Zey0ZtpESoy46sve2vprpl03eGbR6gKTBxs8O44ReRD33VEFnNyE/zvAjWHXnwcWhrX78vDnHCV8Hk5pNIWGfdOF4fXmua0FPt9EPHfg+qwPQ88W904onnzqpfVP3Hu4xWtTof4hvM0U4cklOGX/HK8cbwM9cUqogzjZb0JYHnrjJpb3AZuAr4X5ZXrxHfSe9beJIbdEtjHcuHpvxPP/EU5m9HtuXwX+7LlN99xWApfGm06E38aw37txE0snAy+3sA3V56cJ/wJgLp48Gkd8JwJlEW7NyoM45d+sCLfvAE+GXY8CqprLw7Fm2XYzTiN+Bq6RHsR1sOGcBgzHzfr9SERO8Nx/jOtkB+E+eD4TCqCqn8V1mqHZpd80F5+45XvFMf76x1GeYUCdqq4Nc/sQ9/DAdSYfAw955raLROSMOOIFJ6S9r6rb4ry/KSYDQ3HC0R+B73txjwKubEF+whGcprs3TnveD9fxNfcswH3kDReRoWFu1wCPer/vxNXreJxg3AfXwcTOkNPAfw43g70ljri+iesQuuFms7+H64TipomyXofr4PvhOpQv4YS4SKbiBLrZUfxCBHACbFfv/hm4gRzcB8DpXvnycINrkeeX1HI3w6dwM1tdcLMpv4jwvxD3oTDWy/O5nvss7+9M3DuegxM+wjkD195CYSbjPjgKcO3ncS/uIbj+4Z4wa60m60REzgO+hetXhuLej7jwZpY+SeOZI3BCfGgW6joaz54sBK4VkW+LyKQWzs6tBM7xZv8n4pRPP8MJa8UtiAcRGQ+kNVGGSK4F3lTVzVHiEc8/0nKtu4js8czT/yAi2c2k8Qzug2NWlDSGAY8BX8e14Zdws59pYbddDVyAmx2t89zi6gfFLZ/4Hu6ZdsN9fDzm+XX18vYD3Du5ATi1mbKE8p2Gq5si3LgXzj853E7OxT3bcMuIpcAIr+7ObMoCsQlWAmeJSDru3fpIRC4D9qvq23HGcZNnzr9ERC5v5l6J+N1XRPLiSONkXL/9E3FLcVZESet/cc8mWn9qHDlMjjM5zuS42PhwlhgDcNaQlXjyjKp+HzeuhKyUvuqFWeSVMR9Xj0+JSEYzeW8qrnBMHjR5MJ68vygiVTil6Hzc5Fk0RuH6xxDhfeUYnMx1hbiliGtF5CsR4X+JUxBFs36SKNejY2RbgR8CP5awLSvC+F/cezwI116uxfUvISbjFLM9ONw2r+SwjFeNM3hY6l0/DdwFIG6rkxdw5e+DG5u+LiKh9vhj3ITGYFwbvS5GORogIiNwlleR7WgnTnE307u+Fic/hrMQ+IWIfC6if46HveK2MRmHm4A4iJsEaMoCrUV443UpbnJnHPDXOIOejmvT4bRWHnwcGCwiw7w2cx3wcrOhWqJtPFJ/ND0juhqYEXbdCzeopnB4tqJvmP/7wKdCGlfg3DC/GwjTZkam2Vx8rShTtBnRacDuCLcvcNgi4X4Oz8Ck4gaeYqBrHOn9H/B4S+qZ6LNffcL8i4Crwq7/DXw9MmxE+EYzolHycSnwQRzPIhTXw8CPvN9DcbNeWbiOtYKGs19TcWbQ0dKdhevYi712VAlc6fnFjAv4KfAcUTT8xDkj2kRZr8fN/Ixt5tl9OrLtxNEmvg7M9n6fxeHZIV/YPa0udzNpzyK+mcy/hfmdD6yJqNfTwq6fBG73fr8O3BTmN5zGfcOgiPysC7se493TI8ytCCdMNVcnD+BZMXjXwyLbQESZ5wOHcNZNCiwD+ke+hzgheyvu3d+KE9zrZzLD2sFcL39FwHeipFMc9vczzy8feAI30H8DmIBbphgS1BfgBPDmnmsnnFXkd+NsB+uJmCkK85uGmw3MCXPribPo8uFmohYAf40Rv+L62vNxH1tphFlC4QSr8FkpH84SbHpYe7w+zD/UduLtB+cQNpPqxX8I99F0Ld4Mbti7tp3Ylm013nMLeOlOD/OfzmHrinW4Nv+41yZuwBtHPP8puPdlH27W+cFQPUekE/p7IyyPd+I+Qu7HfYgsw31c/cJ7HvfhWcxGKcOJXpgU75mU0YRFnPec3vbi7okT2hW3PCXyvgcj3EIfeXd4z/wMry2d4PlfBsyJrDf7S94fJsfN936bHBc9ruNejgsLW87hvvfZKPeMBw6GXTf5HMLuOYhb7tVUm2jymXJ4HDV5sOF7Y/Jg7OeairMUujXGPQFgRNj1UK/cglO4K/B3nGXXWJzMco537ySvfsKfY6gdF3hlutrLx3U4hU9UeZGG78R7wJcJs2zDrRKoAUaGhfkih/v1WcDWiDgfBP4v7PpmYHVEuyr2fk+OEv67wD+83xuB88L8bqR5y7ZS79krbpI3PbLPwCmOH8OtBljr+YVbtmXi5KkluHdmPfCJKOmEt6Nzw/qp+V59zsAp2X7mPcdXvDZ1RhztqDnLtqFevD3jiGsszuo23NI3LnmQ6JZtaTgFouLGnU3AwObycaxZtg0AZodmHXFCWwCnVQ4Rru0+hJvRADf7Fj47GO9MYVPxJYJy3MdqOJ1wQgc4oWGzqv5dVWtV9XFcvuOxhijCCbFtZU/Y78oo1y2uDxHpIW7T7R2elvphnNY/Xh7FdajgOudnVfUQ7iMtC1gS1kZe9tybYqG6/Ym64NaET/Pcm4vrt7hO6FVxmzbeTmL4F65TelzcJpC/aWLGpQjoGmufAE/z/qI3Q1SKmxHqCqCq83AzfffiZiPuF7f5ebLKXUfEHgseqbgOPURz71us93tLmN8W3MAZ3jdEvvORbRlVjda+m6uTyL4lPB9N8TVVzcMNBF2AvpE3qOpWXF3/EicINuqzVPURVT0bZ4X1JeBnYTNjoXQ6h/390At3QFWvUtVxuIHjf3GCwe24Wc6zgS+FWZQ0QkQycTNzC1X1V80VWNxmtT1xs3vRuA74t6qWh5Vvt6quUtWgqm7CLdFpzjoKVX0JN2B/McKrQTtR1SDu2fUJuyfa2BBvPzgAuDusnRzACZF9iGgn6kbu5sahJ73+qQfuuUxs4r5/4ZYEnEkUa1dVXaiqV6pqN1wfdzrOuqVBOmF/Z4byqKq3q+pYVb0R1z7+gpvxn4RTaqXReG+QULpLVbVIVeu8Z/IIbuY+Gr/ALVtZhvtQfRbXN+xp4v5wKr17f66qNar6X5xgN9OzhPwNCZpdNdqMyXEmx4HJceFcGtb3XirusJe/ijtsoxSn7Ogcy1pJRL4lbrPvEq+cebTseUTD5MGGbiYPxsDr3+bgxt2Lm7gtsr/sBJR78lDIyuinqlqpqstxE4jne5Zg9wG3qGodEahqEW6/6ltxz/I8nOIxnsOQfoCTh8ItQbvi2mNkO0qkrNg73JIap+QKtdHWtKMTvfivwinzoq0CeQZnbPFVouw15tX7L1V1Ik6B+STOSjY/PJ2IdvSKF3aZqk5X1ck4C7rrce31bzgL1c8B/xI5fCBGa1DVdThLtfti3Sduv+I5uDbzpufWVnnwRzj5tx+uvfwEmCciWbECHWvKtm04DWv4Q85Q1R1xhN1Fww6sX4S/tiQjIvJpaXyKXvhfPMsP1gIpEaaa4zhs7rg8Sr7izedc4GQRadRph1GBGzRC9Iwz7rbG9UtcOcao2+zwMzQ0/22ujK8B3cQtX7uaw0sP9uM6s1Fh7SNP3YaRMfE+8L8MfFZEJjQXl6qWqeo3VXUQbg+oW0UktGHxIeKviwZl9Qarn6jqSNyeERfSeGNUcKbJ1bjZ5Kb4M26PgKFePX+PsHpW1T95HepI3Ozbt9tY7lhsBfqHd7Je59Sd+AaR5tiJG7xC9McJdOEDXYve8TCaa1e7aNifxPPuuwyprsBZ6tzbxAAU2tg+0tQ7Mp5aVX0K12fEMpuPxo24j5WVuJm3xapag7NYGxMtgLhlhc8SXaHVFNcBz4Qr08Liy8RtPNrc4QdK/OPW93FtPvxdbNBOvDrvh7NuC0+jtWzD7XEWPkZlquo7RLSTsLSbRVX3457THRJ94+F/4ZaIv+R9sMaKaxFO4GpROxGRMbg+6X5cu1jiCciLcB8J8RCawY6Wr0pV/aqq9vH6lyIvjWAc8S5vIi1ws6CFwJsishtX9l7eJERhnPk2EofJcSbHgclxsfgmzhprsle3p3vuofptkJ6ITMNNRF0JdPEUjyU00dfGynsEJg82xuTB5knBLX+Mxke4/jFEZF8JDZ9N6Hcn3ATfE944vshz3+61f1T1v6p6kqrm4w5WGIGzZI6Jqr6GU2TeFOa8H6f4jWxHiZQVN0WMg7mqer7n36p2pI4ncd+IjZbee/LhHFw/GXNjf1UNGWlk41aWtIQ/AD9Q1UoOt6PNOAVmrImTeInVxhCRAbjx82eqGl7OtsqD43EHim1XN4n8IE5BPjJWoKNZ2ZYqIhlhfym4GfVfeJUYOk493pMXnwS+KyJdRKQPTqsbzh7cuuy4UDeDkBPjb6uXRxG3b0Kad53hfaiiqhW4B/1TEckWkVNxmvlQw5gNdBGR68Qdh3wFTtB824vrDhGZ30T+5uKEmdkiMlHckca5IvIlEQlZISwDPiUiqeJOn7ki3vJHYRlwuoj0F7fHzndj3JuLm90o8Z7FtyP8Yz4LVa3Fncr3W5yZ82ueexC37OIPItIdQET6RMzsNImqHsBp4H/UXFwicqGIDPEGxBLczHzoo3AZcI33zM7DWX80RYOyittTaYy4GcxSXGff6GNTVUtwHem9IhKaCU0VkU+ISGh/lFwvjnJxa/i/HJbOSSIyWdxsawVuaVmwLeUWkQdF5MEmyvmel8bt3juQjVuetpjECFePAd8QkYHi9tX4Ja5DbDQD1lLiaFdPArNEZKQnMP64hUk8hJvNijYT+ARuf4UnIz1EZJaIXOC91z4R+QRu74v34k3YK89X8PbawZlEn+nV4SScKXtkmFScdVolbmPZZpUhnjLtSpyZfTQuwy17eSMi3JkiMsDrR/vh2sxzzZcMVHU+blb2ujDnJ4ELxB1RnooTXKtxllSJ4C+4cWaUl/88Efkfz+8/wCgR+aQ3nn2NFnwYq+rHOGuJ26L4bcL1M9+P9BOR00TkC2FtdwSurS2MN23vfb8HNzMexLWT08TtJXcGUdqJF+4KEcnx2udM3Af5803c20dEenvPegreXiph/ineWOoH/GFyATjLj624uk/xxtIzcfW1Eie0jvf+bsD1u+OJ3zLKaB0mx5kcFxWT42KSixtfi8VZlETKFJF1m4tTJu3DKX5/RGNry7jyHo7Jg40xebBRmBHivjsyvT7oMzjl8H+bSOafOKVsHxHpjZPBHgRQ1Q24PQS/LyLp4izpPoU7hKMEZ+0VGsdDSqmJoTKKyAQvD51wB1hsU8/qKg6+T5hspe7U9CdxY1WuN17dirPgTQTvA2Ui8h2v7vwiMlpETvL8w8e6vjhLw5ZwJ/AFEYkmY34Pt5xzc6SHiPxQ3Pdhmjfm3YJbKvpxvAmLyDlAhqq+6Dltwu39Owp3uEhRE+HS5fA+k2le3yCe3w1h79tI3NgUedpuKJ4+uMN77lHVv0R4NysPhpVdOCzDhPRli4D/EWfZ7RORz+IUiDH3rD6alW0v4Qab0N8dOPPW53Emy2W4j4XJccb3U5wVxiactvNp3EdWiF8BPxBnzvmtRBTAYwAu/yHNfSUNG+1NuDXSe3EDxJdV9SOoFxouxm22WYIz6b3Es3IA12BibVJ9Ba4en/DCr8R1mHM9/x/iNMMHcaaQj0aJIy68mYEncDMTS3CdY1P8BGfuWoL7AH0mwj+eZ/EozrT5qYgB9Du4Rr9QnPn9XNwMYbz8EWeyPLaZuIZ61+W4GYT7VDWkKLgFd/xxMW4PhWdjpBdZ1tAyu1Lc8pr/0sTsg6r+Htf5/wAnZG3DfXyE0vsWbnlGGU44eCIseCfP7SBOuCnCCb20odxNtkdVrcZtOj8d9x5uxA2cV3rWMW3lAVw9LcC941W0fHCKRZN1os5s/o+4zn299z9uvFnDu3HvY6RfparO9WaHIinFDZpbcW3tN7j+462we+6RhpYaSyLi+B3OZD9kbfYrnIn5NuAFjX7ke2imfibuYyAU9zRws+wiEmm9dqmXxzeIznXAv6K0hQk4RViF938FLTP//gHuQw6oV1h9BrdMYj/uPb3IewZtRlVnA7/GLR8qxfW5n/D89uOs9+7EvW9Did1/R+O3wI0hoSMi7bdUdWeUMMW4cWSF91xexikAwjctv0oaW/WEp/E5YKWqhtrPMzjrgX24pQb3N5HfW3AzwcVe3r/gKUHxPujDrYcGc/hZP4Tbf+fVsLh+gBs/b8c9w0rPLfThfglOAC/B9W3Xquoab/Zxd+gPt7Q36F0Hmsi3kRhMjjM5zuS4GHJcjPxn4saohTTegPtu3CbyB0XkT7hJhZdxVpZbcPJPvBMJkXFFYvJgY0wePIzg+vW9OHngFtyekEshqjz4V9z2Iytwfdl/aLjR/dW4/rbI8/uhqr7uWWyFj+P7vPv3hMlvt+HemW245feXRclvVNQd+BRpBXczTh7ZiNu/61Fc22oznuxxIU7JswmX77/hln+D61+3eH6v0rL+I2QluYDGkyCo6s6IdtHAG3c4y36cjHcOcIE2XJHyYUQ7+mPIQ9wk1G9x7SDEzbhJtrm4vRSbkrs+xo2tfXB9WiWHLQtPxcmwFbjx8CVcew+l+5GIfNq7vAE3gXBHeD69sscjD77qpR1ayVHJYeviX+P2NlyGe8++AVyuzRwkEjom+bhDRL6M2yQ31mzVUY2ILMNtNBxVS2wYRwpxFi4f4jYErm3ufsMwDMNoCybHGcbRh8mDhmEYhzlulG3i9rkZhJt9GYrTmN+jqn+MGdAwDMMwDMNoV0yOMwzDMAzjWKLJkww7IGk4U9WBONO/x2nmJAvDMAzDMAzjqMDkOMMwDMMwjhmOG8s2wzAMwzAMwzAMwzAMw0g2R/MBCYZhGIZhGIZhGIZhGIZxTHFMLCPt2rWrFhYWJi3+iooKsrOzkxb/8YDVYduxOmw7VoeJweqx7Vgdtp1E1+GSJUv2q2q3hEVoHFFMFjz6sTpsO1aHbcfqsO1YHbYdq8O20xHkwGNC2VZYWMjixdFOHE4M8+fPZ/r06UmL/3jA6rDtWB22HavDxGD12HasDttOoutQRLYkLDLjiGOy4NGP1WHbsTpsO1aHbcfqsO1YHbadjiAH2jJSwzAMwzAMwzAMwzAMw0gQpmwzDMMwDMMwDMMwDMMwjARhyjbDMAzDMAzDMAzDMAzDSBDHxJ5thmEYhtERqa2tZfv27VRVVbV3Vo468vLyWL16dYvDZWRk0LdvX1JTU5OQK8MwDMMwjMRgcmDTdAQ50JRthmEYhtFObN++ndzcXAoLCxGR9s7OUUVZWRm5ubktCqOqFBUVsX37dgYOHJiknBmGYRiGYbQdkwObpiPIgbaM1DAMwzDaiaqqKgoKCkzAShAiQkFBgc0QG4ZhGIZx1GNyYGI52uTApCnbROQBEdkrIiuj+H1TRFREuiYrfcMwDMM4FjABK7FYfR49RJMFRSRfRF4TkXXe/y7tmUfDMAzDaE9MbkksR1N9JtOy7UHgvEhHEekHzAS2JjFtwzAMwzAMo315kMay4O3A66o6FHjduzYMwzAMw+hQJE3ZpqoLgANRvP4A3AZostI2DMMwDOPIM3/+fC688EIAnn/+ee68884m7y0uLua+++6rv965cydXXHFF0vNoHDmakAUvAR7yfj8EXHpEM2UYhmEYRlIwObAhopo8nZeIFAIvqupo7/oS4CxVvUVENgOTVHV/E2FvBG4E6NGjx8THH388afksLy8nJycnafEfD1gdth2rw7ZjdZgYrB7bTrx1mJeXx5AhQ45AjtpGIBDA7/c3e9+bb77Jn/70J5566qlm792yZQtXXnkl7733XpvSjMb69espKSlp4HbmmWcuUdVJrYrQaDVRZMFiVe3s/RbgYOg6SliTBY8hrA7bjtVh27E6bDtWh23H5ECTAwF3YkOy/oBCYKX3Owt4D8jzrjcDXeOJZ+LEiZpM3njjjaTGfzxgddh2rA7bToevw9oq1ZrKpCfT4evxCBBvHa5atSq5GYmDTZs26fDhw/Waa67RESNG6OWXX64VFRU6YMAAve2223TChAn62GOP6SuvvKJTpkzRCRMm6BVXXKFlZWWqqjpnzhwdPny4TpgwQW+++Wa94IILVFX1H//4h3w9TEcAACAASURBVH7lK19RVdXdu3frpZdeqmPHjtWxY8fq22+/rVdddZVmZGTouHHj9Fvf+pZu2rRJR40apaqqlZWV+ulPf1pHjx6t48eP13nz5tXHedlll+m5556rQ4YM0W9/+9tRyxStXoHFmkSZx/6alwW96+II/4PxxGOy4NGP1WHbsTpsO1aHLSRQ5/7CsDpsOyYHmhyoqqQcQb3eYGAg8KG3aV1fYKmInKyqu49gPgzDMI4Ndn0I798PBzajBzdD6Q7I6wdfX35Ubf5pJIafvPARq3aWJjTOkb078eOLRjV738cff8zf//53Tj31VK6//vp6s/6CggKWLl3K/v37+eQnP8ncuXPJzs7m17/+NXfddRe33XYbX/jCF5g3bx5Dhgzhqquuihr/1772Nc444wxmz55NIBCgvLycO++8k5UrV7Js2TIANm/eXH//vffei4iwYsUK1qxZw8yZM1m7di0Ay5Yt44MPPiA9PZ3hw4dz8803069fvzbWlHEE2SMivVR1l4j0Ava2d4YMwzCOW+Z8B927Gvncf9o7J8c9Jgdurr+/o8iByTwgoQGqukJVu6tqoaoWAtuBE03RZhiG0QQL/4x++AS1NVVU95pEXZ/JSMlWgtUV7Z0zo4PRr18/Tj31VAA+85nP8NZbbwHUC00LFy5k1apVnHrqqYwfP56HHnqILVu2sGbNGgYOHMjQoUMRET7zmc9EjX/evHl8+ctfBsDv95OXlxczP2+99VZ92iNGjGDAgAH1QtaMGTPIy8sjIyODkSNHsmXLlrZXgHEkeR64zvt9HfBcO+bFMAyjafaugZe/B8Fge+ckaejHc2DXMoIduIxG85gcmBySZtkmIo8B04GuIrId+LGq/j1Z6RmGYXQ4ynYR6D6aQ596Bp/PB8sfIXXHQrSiCDJsL42ORjwzj8ki0lIydJ2dnQ24LSfOOeccHnvssQb3hWYjjyTp6en1v/1+P3V1dUc8D0Z8RJMFgTuBJ0Xk88AW4Mr2y6FhGEYMVj8PC+8lMOUm/J37tnduEk/xVqR0OwCBQ8X4cvLbOUPHNyYHxsexJAcm8zTSq1W1l6qmqmrfSEWbZ+EW9XAEwzAMA7RsN4Hs7k7RBmimE4L0kHWdRmLZunUr7777LgCPPvoop512WgP/KVOm8Pbbb7N+/XoAKioqWLt2LSNGjGDz5s1s2LABoJEQFmLGjBn8+c9/BtyGtyUlJeTm5lJWVhb1/mnTpvHkk08CsHbtWrZu3crw4cPbXlDjiBJNFlTVIlWdoapDVfVsVY12cr1hGEb7U7EPgGBZB13tvnVh/U8t3dGOGTHaG5MDk8MRW0ZqGIZhtJCyXWhW9/rLemVbhSnbjMQyfPhw7r33Xk444QQOHjxYb+ofolu3bjz44INcffXVjB07lqlTp7JmzRoyMjK4//77ueCCCzjxxBPp3r171Pjvvvtu3njjDcaMGcPEiRNZtWoVBQUFnHrqqYwePZpvf/vbDe6/6aabCAaDjBkzhquuuooHH3ywwUymYRiGYSSdcqdk0/IOqmzb8s7h3yXb2y8fRrtjcmByOJIHJBiGYRjxUluJVJUQyA5XthW4H6ZsMxJMSkoKDz/8cAO38I1qAc466ywWLVrUKOx5553HmjVrGrnPmjWLWbNmAdCjRw+ee67x1lyPPvpog+uVK1cCkJGRwZ///Gdyc3ObjBPgxRdfbLJMhmEYhtEmQvJWR1W2bX2XuvyhpBxYhxabsu14xuTA5GCWbYZhGEcjZe7smGC2WbYZhmEYhmEcadRbRhr636E4dAD2raF6yAUoYpZthpEETNlmGIZxNOIp2zS7R72TZuSh4oNDRe2VK6MDUlhYWD+TaBiGYRiGR4Vn0dYRlW3efm21faeg2d3B9mw7bjE5MHmYss0wDONopLyxZRs+P5rR2ZRthmEYhmEYySRQi1QeBEA64oqCre+g/jSCPccTzO2NlO1s7xwZRofDlG2GYRhHIyHLtpyeDZw1Mx85ZIf3GYZhGIZhJI1wBVtHPAV+60IC3cfiT89Cc3vhK9uFqrZ3rgyjQ2HKNsMwjNby1OfQDx9PTtxlu1B/GmR2aeCsmflIpSnbDMMwDMMwkkbY0lHpaMq2mkPozg+o7T0Jn8+H5vbGV74LDQbbO2eG0aEwZZthGEZrKNsDHz1D4KPnkxa/ZnVHfA276ZCyzWYfDcMwDMMwkoSnbAt06o+vsqhjyV07FiPBOmp6TQJwy0jrKgnaygnDSCimbDMMw2gN2993/w9sSk78ZbsIZHfHF0XZ5qsyZZtx9FBYWMj+/R1s1t8wDMM4vgkp2wqG4ztU1LGsvrYuRBGCfU4CQHN7u//JOJG0dCc89xV3+qnRITE5sGlM2WYYxrFPyQ5Y/iT9tzwNgbojk+Y2p2zzlWwhGAgkPHot200wuzsi0tA9qwCpPNixhD7jqEFVCVrbMgzDMI53Qsq2rsOQQDXBqtJ2zlAC2fIOwa4jkMzOAARzezn3kiScSLrlHfjgYQJzbk983EbCMTkwsZiyzTCMY5PKg/D8zejd4+API+GZLzBo078IrH/jyKS/fREAvtoKguVJOBK+fHfDk0g9NDMf0QBaWZz4NI3jks2bNzN8+HCuvfZaRo8ezc9+9jNOOukkxo4dy49//OP6+y699FImTpzIqFGjuP/++9sxx4ZhGIaRZMr3ov50gp0LAdCKJMh67UGgDt2+iJpek/D7/QCop2xLimVbdRkA/hVPEFw3N/HxG23G5MDkkdLeGTAMw2gV792PLv0XtYNnUjPqM9R2H0PeM1cT2PwW/uHnJDy5QFD57jPLGVCQzeen9iF95wcE8wbgL9kCBzdBXs/mI4mXmkNIVQnBrGjKNndggh7aD7ldE5em0f7MuR12r0hsnD3HwCfubPa2devW8dBDD1FaWsrTTz/N+++/j6py8cUXs2DBAk4//XQeeOAB8vPzqays5KSTTuLyyy+noKAgsfk1DMMwjKOBiv1oVgGa1c1dl++D7sPaN0+JYM8KpKac2l4TCa2d0OweqPiTo2yrqQAgkNsHeeHr8JWFkJ6T+HQ6AiYHdjjMss0wjGOSqtUvsz5lKOft/hKnvzOOkx4P8lFwAFUb301Kei8u38mTi7fz21c+5qt3PYTUVVE17BIAgkUbEptY+W4Xb1TLNm9QqyhKbJrGcc2AAQOYMmUKr776Kq+++ioTJkzgxBNPZM2aNaxbtw6AP/3pT4wbN44pU6awbdu2enfDMAzD6HBU7COYWQA53eqvOwRbnJwc6HPyYTefH83pgZQmYRlpTTkAh2b+Hl/pNurm/jTxaRhtxuTA5GCWbYZhHBk+mg3F2+DUr7U9rkMHSNuzjFf1Mgb2zqRzZip5WaksWTyc4XvfIFhbjS81ve3peNQFgtw9dx1Du2Vx65kD2PDyPABuWz+Ke5DEH5JQtgfACT4RXpqZ7350tGPojbhmHpNFdnY24Pbq+O53v8sXv/jFBv7z589n7ty5vPvuu2RlZTF9+nSqqqraI6uGYRiGkXwq9jplW7ZTtgXL97ZzhhLEtvcIduqH5PVp4BzM7Y2U7kx8ejXlaEomgX5TqR77WdIW3U9wzBX4+p/cfNjjDZMDOxxm2WYYRvJRhXk/Rxf8LiEb++/+4CV8BMkecTZ/+9wUfn/1JH50yTgquowkTaspWvdeAjJ9mOeW7WTj/gpuPKUPpw3txo0D91Ge1o35RZ054CuAAxsTmh5lu4CmLNucsk0rjpCyrfKge37GccG5557LAw88QHm5m4nesWMHe/fupaSkhC5dupCVlcWaNWtYuHBhO+fUMAzDMJKHVuwnmFkQtqKgg1i2le0i0Klf49Puc3vjK9+V+NPuq8vRNKfIqTn9ewRzeqLP3wx1NYlNx0gIJgcmFlO2GYaRGJY85P6ise9jKFqPVJcQKGn7rNm2RS9QrDnMOHNmg9M6exeOAuDDd15pcxohagNB/jRvHSN6ZDNjuNsjLWXXUlL7T+Kayf1ZV9eNQFGiLdvcMlLNabwPnGaFhL4joGzbvhj97RCCa/6T/LSMo4KZM2dyzTXXMHXqVMaMGcMVV1xBWVkZ5513HnV1dZxwwgncfvvtTJkypb2zahiGYRjJQdUtI80qgJR0NK3TkZG7jgBaWUwwI6/xafc5vfCV7078afc1FWhqtksvPZeaGT/Hv38NdcseS2w6RkIwOTCx2DJSwzASgr7/V7dMdMz/IGlZDT3XvHD4vr1roEvfVqez82AFhQffZUvnkxnTPb+BX5f8ruxJ6Y1v+3tU1tSRmdb2Lm720h1sKTrE7y8dSmpqKlKxF1/pNoLjr+PykX358N0ejD24HFVtJLi0mrJdqD8dMjrXO9UGghRV1JDm85PjT0eTvWebKsz5DhKso/bjV0k74cLkpme0G4WFhaxcubL++pZbbuGWW25pdN+cOXOiht+8eXOysmYYhmEYR56qEiRQg2a5SdZgVgHSQZRtVB5Ee3Ru5Bzs1AsJVBMoT7AFX005mppVLyPXDZ5JXdcRyML7YOK1kCjZ2Wg1JgcmD7NsMwwjMZTvQ6pLCax6obHf6hcJ5A0AQPetblMy/3ntVbpJCV3HntvIBB5A+k9hnK7h6UVb2pQOQE2ds2ob1TOHM4c5gcu/cwkAvn6TGdGzE5U5/ciqPUCwqrTN6dVTvodgdjfmrT/I5f+3hNPveocT73yLc/73fS65fwnBzHyoPJC49KKx4inYsZhgaja+HYuTm5ZhGIZhGMbRgqdYC2Y62U+zuiIdYa9cVagqRtM7NfbK7e3+J/pE0prDy0gBEKF24hfw719DYP28xKZlGEcZpmwzDKPtBAOHN+xf9khDv+KtsGsZVaOuIpieB3vXtDqZ4kM1VKx8GYCCcedHvafbqOkUSBmvvfUOwWDb9p14esl2th+s5Aun9CY1NRVwyjb1peLrOwGAfkNGA7B5bQKP6i7bRW1md3760nqqagOcNbyAL5/Wn8+f0o/iyjpKpRNyKHmWbb5AFfrajwl0H031hOvx71+dWGWiYRiGYRjG0UqFOwwhtHWHZhUglfsTv5/Zkab2EBKoIZgRxbLNU7YReSJpZTHsboOMW12OpmQ1WP1RN+IStx/ewvtaH69hHAOYss0wjLZzqAjRIIGs7vi3vEmwOGxWzNvvq3rQTIIFw5D9a+OLc+tCeOGWBhuo/vPdLUxlGeWdR5DapU/UYDLgFAB6ln7IvNW7W1ce3LLNe+atY2zvXE4fUlDv7tu1lLpuo/Cnu1m6CeOc0u2DD5e1Oq1ItGw3G6pyKa2q464rRvH7T03iOxeO4bsXjKYgO42dtdlIEi3b+m+djZTtpOy0H6D9JiMaJLhtUdLSMwzDMAzDOGrwDkMIt2zzHSo69pVtlQcBCMaybCuOsGx77Yfogxe0uuxaU46m5TR0TMmgdty1pGyYS3BfnN8FhnEMYso2wzDaTvkeAKrGz3JKtw8ePey3+kUCBcPwdR1KsGAo/gPr4xuw37wLljxI4NUfAlBZE+Dptz9ikm8t/iFn4ff7o4crGIJmFjAtbR3/92brTwmdt2YvO0uquPaknvVWbQRq8O/+kECvE+uXsOb3HQ7Azi1rCAQSs6mslu5myYEMzh/VlRMHHj6RNMXv4/wxvdh4KBMqDyRH6CvZTr9tz1A99AJkwCkEek5AEYJb7NQhwzAMwzCOA8o9y7bskLKtAKk6iAbq2jNXbaeyGABNb2zZplldUV9qw2WkwQC65iWkqoRgdUXr0vT2bIukdvy1qC+N4Dv3ti5ewzgGMGWbYRhtxxNKantOpK7PyfiWP+ad5LQf3foO1QPPwe/3EywYhq/qAMGyvbHjO3QA3fA6wcx8/O//heCal3hu2Q5GVn2AnyAy9Jymw4rAgClMS1vHe5uLWbWzuFVFemrxNrrlpHH60DCrtn2rkUA19D3p8I2ZnalJzaOgeicLNyZgP4+aCnw1peylC7eeM6zRvnQXj+/N/mAOWpH4GVZVZd/s74Eqh0653aWdkecsEre/n9C0DMMwDMMwjkpChyHULyPtimgQPZTk/XKTjWfZphl5jf3Eh+b0RMKXke5YUr9XnXphW0x1OZqa3chZs7tRe8Kl+Fc8cezXq2E0gSnbDMNoO56yjZzu1I66Ev/BjdRtWQgfz0E0SM3gcwEIFgx1//esih3fqueQYB2lF9xPXdeR8OxNLFq+kgsyVxBMy8VfODVmcOk/lc7VO+gpB3l2acs3et1bWsUbH+/jgpEFZKSl1rvXH44Qkb6/6yAG+vfyzJJtLU4rknUb1gMwuHAgg6KcFjWxfxdq0ruQFqhA66rbnF4477w9n26bn+MvtRfwjXkVvLZmHzV1QQJ9JuHftRQNBhKanmEYhmEYxlFHxT6CGV0Qv5MBQ6eSakWCT+o80tQr2xrLlwDB3F5I2c7DDh+/VP9TD7VC2aYKNRVRLdsAak+8AamrJPD+31set2EcA5iyzTCMtuMtIw1mdaVu+IVoSib6wSOw5kWCnfqiPcY4f0/ZpvuaOSRh5b8JdBmM9p5I1UV/hrpqPrXtp0yTD6ntdyopaRmxw/d3yrAru29jzso9zgKstsrtHxeHwujppdsJBJWLx3RvsKGrf9cSAtk98Hfu1+B+f8EghqXu4+VV+6isadsSgyfecCd/njZ+ZIO0Q/h8Qt8+Lv3ifbvalFY4qkrlW/dRSTrrel3Cyp1l3Prv1Zx190K2Z4/GV11KYE/bTpI1DMMwDMM46qnY66zZPDksdFAC5e2gbFv4F9j3cWLiqvJWe2RGV7Zpbm985WH7HX8857CirDV7BddVIRpovGebR7D7SGr7nYJv8d/QsD2aDaOjYMo2wzDaTsU+NCUTScuBtBxqh56Pf/VsdMMbVA88G39KCgCa08sNuLFOJC3dhW5+i+qhF5CSmormD2b5mO9xkqymc91+goNmRFVCNaDnWDQlk5k5G9lWXMXqj5bDA+fC49cQWPHvmEFVlacWb2dC304M6hYmHGgQ/84l1PWcgC9yv7j8QeQH9lFdU80rK1uvAHtz3T52b98EQF6PAU3eN2rIQADeWZEg4Qv4YO0mTqt8g009P8Glo/JZ+L2zeeC6E6kLKo/u7AmAbnk3YekZxw6BQCDmdTRUlWAwMXsYGoZhGMYRpWI/wcyCMGVbyLKtmW1QWsOGeW5COBrF2+Dl71D3XoIsv+oPSIiyjBR3IqmvfDdoEIo2wL41VA/+BEDrlnrWuH3emrJsA2fd5ivfTWD9vJbHbxwxTBZsHaZsMwyj7ZTvIZjVtV4JVTf6Snw15UigmupBMw8rx0QI5A+NfSLpR7MRlOphF9c7PV5zGs8GT0fFjww9u/n8pKRBn4kMqf6Is/wfMnD2BeiBjag/ncDmd2IGXbT5IJv2V3DJ6K4NDmFIXfp3fKXbCQw5t7Gyr8tAfBpgbHYJzy2LODK9Bfz1vxsZklkGgHTq3eR9A/o5y7ZlH7f+AIhI1r/yFzKklh5nfhFwhzGcdUIvZo7qyZNbMglm5MM227etI/Lwww9z8sknM378eL74xS8SCATIycnhm9/8JuPGjePdd99tdH3XXXcxevRoRo8ezR//+EcANm/ezPDhw7n22msZPXo027a1fVm1YRiGYRxptGJfQ2Vb6FTS8gQr20p3wb8uI/BuE4cEbH7TpVsSYzwt3wvV5fGlV1mM+lLc5HgUNLc3EqwlraYEPp4DQPUJn6wP22KqnUxLE+kBBPqeDEBw18qWx28kDJMFk0NKe2fAMIwOQPleglnd6oWSQL+pBHL7ILWVBPucTLgdmBYMw79pHqoa3UJt5dMEuo9GunpLTlVZsL6I3X2/xQUX3Ul6t4FxZUkGnEL6gt/yt9RVbAj2J/+Kv5O34Ef4ti+KGe6JRdvITvNzzoiu9W6+vR+R/uavqBl4NmmTPts4UL7L0/m9K/jdpoNU1dSRkday7nVfWTXvbNjPTf2q0KJ0pAkTfwDJ7gbAnr272VtaSfdOmS1KK5L1e0qZvH822zqNpfeQybDrzXq/i8b1YvYHO9jTYwzddyxq+rkZbefrX4dlyxIb5/jx4AlA0Vi9ejVPPPEEb7/9Nqmpqdx000088sgjVFRUMHnyZH7/+98DNLhesmQJ//jHP3jvvfdQVSZPnswZZ5xBly5dWLduHQ899BBTpkxJbDkMwzAM40hRvpdgn1PqLzWzMyq+wwcnJApvDzhd+xqc/s3G/hv/C4CU7mzsF8rbgxegg87Cd/6vm0+v8iCa0RnxRbe30dxeAKRV7YOdcwh0HYH2HOf8WnNAgmfZFkzNpknJMaMzwezusL+ZLWbawoLfQcFgGHVZ8tJIBO0gB4LJgsnELNsMw2gzWt5wbwvER9W5d1E249ekpKU3uDdQMBTfoX0EK4oaR3RgI+xYQtWQC+qtyjYVVbKzpJrThvUgtdeo+BU9g89CUDb0PJ+LKu/go5oeBHpPxL9/NcGqsqhByqpqeWnFLmaOKCA3y8t3bSUZ//kqwfQ8ghfdTUpqauOAXZyybXLeQapqg7y5ruUzn3NW7iKoMCyzjGB298ZLVcPx9g7pQikvfth6S7oQb770GAN8e0k7+foG1nwApw3pRl5mCgtrB+Mv3kSwPfYrMZLG66+/zpIlSzjppJMYP348r7/+Ohs3bsTv93P55ZfX3xd+/dZbb3HZZZeRnZ1NTk4On/zkJ3nzTaegHTBggAlXhmEYxrFLXTVSXUow8/Bp9IgPzSyoV44lDG8PNf/ORQQrSxr6qaKbFrjky3dHP4G+rgb2ryNQHKcsWHkQTe/UpCwdzHWrKnIqNqNb36W68Cz8mXmo+OuXoLaIGmdxF2sZKUCwYBi+WKte2oIq+uZd6HNfRWMoLY9nTBZMHkmzbBORB4ALgb2qOtpz+y1wEVADbAA+p6qtsEk1DOOoomIvwR4TGjgFB5waVZtff0jC3jWQc1pDz5VuP7XqoRcSUmktWO+UcmeN6NmyPA2YSvDWj+kqeQTufIOXV+1j0tCJiAYIbF+Cb8j0RkFe+HAXlbUBLhlz2Eov/b8/w39gHRWXP0JWlz7R08rtiaZkMtC3l6xUH699tJtzRjW9DDQazy/bydBuWeQFDhDM7k5KLKViZj4Ag7IqeXH5Lq6fNqRFaYWzt6yKgZseozS1C11O+p9G/mkpPs4b3YtnlvXjMj8Et76Hf9RFrU7PiEEzM4/JQFW57rrr+NWvftXA/Xe/+10DxWtGRkYjRWw0srOzE55HwzAMwzhieAq1YFbXBs6aVYAkWtnmLc2UYB11G/6Lb/ThLVQo2oCU7SSQ1R3fob0E62rwpzacwKZsJ4JCbUV86VUVE0zv3KSyTT1lW+9dryAaoGbg2fhF3OmlbVC2xVpGCu7bIGXlkwQDgdiTza2hbDfi1U/g5e/jv/IfiY0/kbSDHAgmCyaTZFq2PQicF+H2GjBaVccCa4HvJjF9wzCOBIFa5FARwcyuzd+Lm70CCEY72XLFv6nrNQl//uHDARasP8CQrpkM6Jbb4qz5OvWkS24mpw/txutrD1DbczwA2sTeY08u3sbgrlmM7dMJAP/6V0n78J9Ujv88maPOb9qqTgTyC0kt28bUQV2Yv7aoRRuC7iiuZPGWg5wzPN9Z/WX3iG3B509BMzozpnMNS7aVsrv4UNxpRfLsvLc5XZZxaNTVpGZEHxwvGtub92sHEhQ/unVhq9OKxtxVe3j8/a2UHKpNaLxGfMyYMYOnn36avXudNeaBAwfYsmVLzDDTpk3j2Wef5dChQ1RUVDB79mymTZt2JLJrGIZhGMkltLQz3LINd0iCHIqyKqMteAosRWD93IZ+m9wS0poRlyIaREujHMBV7O2HVVsZV3LajGWbZuaj/nQ6la0nmN0D7eXJzRl5SGuUbdUtsGyrrSBYvL3laTTHgQ0A1PaahH/VMwQ2zE98Gsc4Jgsmj6Qp21R1AXAgwu1VVa3zLhcCfZOVvmEYRwhv/4qgt49Yc2inPmhKJuyL2JthzyrYt5qqoRfi8/aSKKuq44NtpUwbkh/XTEpTXDiuF3vKali6z0egy6CoG/2/uHwny7YVc8mYrqSmpkJdNRmvfpu6riNJOfen9Xlqki4D8ZdsZfrQAvaW17B8e/xGu/9Z7szaZ44owFe+B83p3nygrAIKM5xw1doTUCuq60j74B+oCHmn3tCk8DVlUD452TlsTh2CbE/cIQnFh2q4+bEPuP2ZFUz6xWt8+eElzF21h9rA8X1y0ZFk5MiR/PznP2fmzJmMHTuWc845h127YrenE088kVmzZnHyySczefJkbrjhBiZMmBAzjGEYhmEcE3hyrUaxbPNV7m+8nLOpk0TjwVtGWtd3Cr6N89DwidpNCwjm9KKu31SXfnGUjeZDByfUxjnpWllMMKPpPYERIejt21ZTeBb+FLfORDM6I1WtWIwWsmxLjz1hHsx3KzR0X5SJ+LZS5JRtFWf9kkCnfvCfb0HAJnjDMVkwebTnnm3XA3PaMX3DMBJB+R6AhntbxEJ8BPKHIEURezMs/ScqPmqGnl/v9M6mg9QFlbNGxKF8isHZJ/QgLcXHy6v2Eeh1Iv5dSxsINOv2lHHb08sZ1yeXq050QoZvzwp8lUXUnvJ1UjNjm78DSP4g/KVbOW1QZwSY+9HuuPP3/Ic7Gd0rh8JOgtSUQU6v5gNld6WTltI7L525q/fEnVY4L3+wkUt1Hvt7z4h58ESK38f5Y3qxoGoQ/t0fEqytblV6kTzy3lYG1a3n7umpXDGuBws37ueGfy7mlsc+SEj8RnxcddVVLFu2jOXLl7NkyRKmTJlCeXnDk80ir2+99VZWrlzJypUr+frXvw5AYWEhK1faaWKGYRjGMYx34qhGTCI7y7YDDZVt619H7+yPHtzcurQqi1HxUzvkfPyl2wjuX+/cg0F085vU9J2K5DnbFC2JYvXlKeCk9lD0Pd0apXcQTc+LeYt6Mmj1wBmHJ2EzOkNVSXxp4+lgFAAAIABJREFUhOMdkBCPZRuA7v24ZfHHw4ENqD8NzR9M9Vlua5jA2/+b+HSOcUwWTA7tchqpiHwfqAMeiXHPjcCNAD169GD+/PlJy095eXlS4z8esDpsO8dqHeYXLWEs8PGOYsoqYp/0GeIECuiyeyVve+XNPLSTkxb9H7u7n8nqtdsRcRu9zl5ZQ1YKVO9Yw/zdzW+cGqsOxxQIL3+0h1nDCjihsoiFrzxBVWYvKuuUn75bSQrKZwfV8NGK5QD03zabIcCSfWnUxfFceu+vZVhdFduXzWdwXjYvLN3MpMzmD0rYXRFk5Y5KrhzqZ/WiN5gKbNx3iL3NpDn6kJJetZOReXXM33SQl+e+QUZKy04JXfPOPC6XCpbkn8rqBQvq3aPVYz8N8H7dUGb55rD4pYcozxvWorQiqQsqL/93E0+n/5SqVYPJHf8LzjwlhUdWK698tJuXXnuDrNRj99TTeN/nvLw8ysqiH9hxvBMIBFpdN1VVVcdkf2oYhmG0M6E92zILCF9ToVnd8NWWE6g5BBneJOyKp5FANTUb3yJtYmHL06oqRjM6UzdwOsyH4LrX8HcfBntXIYeKqOs7Fe3k9gvWkiiHIJRsBUDqqpo/LT4YQKpLm1e25fUnsHMpgf6H917WjM74ita1vHzV3hjezJ5tmlVAMDO/8aqXRFC0gWCnfvhSUgkMPpvaQWeT8uZv0XFX1isyDSNZHHFlm4jMwh2cMENjqMdV9X7gfoBJkybp9OnTk5an+fPnk8z4jwesDtvOMVuHH2yHFTB0wqn4uw6OK0hacArpb81n2snj8Gd1gUc/haZmkH7+Lzg53w18QVW+9dZCpg3pzIyzJsd1CmmsOiztspOvPfYBz1SdyPeBid0DpJx4Bl95dCl7Kyu594oRnDLk8MEIGTv+QiBvAFPPvji+Jazr62DdXxnXL5cL/P24+43NDB17En3yY28S+qfX1yGs5XMzxjGgciUsgsHjT2PkCdHLUU/JUwTXbuFTp53A3EdXUlswhPMm9Gs+nx47iispef3XVKR3ZuxFXyY1PaPeL1o9nh5ULlm1H2phbH41adOayV8zPLNoMz/Vb5Ep1WSUr2XimBH4MnLJ7FPCfx/6kKr8wZw/sX+b0mhP4n2fV69eTW5uy/cjPB4oKytrdd1kZGTYcgbDMAyj5VTsQ1MykfSGCiL1ToLXiv1O2RYMoOteQQB2LW9dWp6lmXYeQKBzodu37dSvgHcKaW3fKaSkd0LTcqA0irItzLKtWarcaafBjNjKtupTbmVNyjiGZRwuf2gZabMKvUhqKlBfCvjTmr01mD8UScKJpHpgI4HOA+vzXX3WT0n5x5kEXv8FKZ/8c8LTM4xwjugyUhE5D7gNuFhVW7+jt2EYRw+euX3kqU37y2vYURx9H4tAvbn4Wlj/Oqydw6FJN5Eadtrnql3lHDhUyxnDurZsYG+CT4zuyaxTBvDI5lzKNJM333iZn/9nNS+t2M1XTuvL1MFh6aji37mYut6Tmt+rLUQXtwxTDm5m+lAnkL22KvZ+B6rK8x/uZEK/TvTukoV4S3KlUxzLSLO6IlUHGd8nl7yMFF5dFf+yVYAXl27hTN8HVBXOICUtvdn7fT7h5LGj2ad51Gxb2qK0IlFVKl7/NRN866kafTUSrMO39R0AxvTuREF2Kq+2YBnusU6Ll2UYMbH6NAzDMFpNxT6CWQWN5L+QnKue3Mv2xcihIlR8yO7WKtuK6w8sCBROJ2Xbu2htFWxaQKBzIdLZTToGc3ohUZRtoaWlUlfZ/NgXOowho0vM27RTH0rzTmgge2tGZ3w1ZWhL9zqrKUdTs5E4ZOlg12H4D6xruG9dWwkG4cBG6vIG1JdH8/pTN/QT+Na/mti02oDJLYnlaKrPpCnbROQx4F1guIhsF5HPA/cAucBrIrJMRP6SrPQNwzhClO9F03Lwhc0ABoLKFx5dzkV/WcTf39lKINiw0wsWDAVA96yAV75HMG8A1eOvbzCwv7BiDz6Bs07omZBspvp93HHxaBZ8ZwZFeaPoVb6Cv7+1ibOG5TNrSt8GQpUc3ISvsgjte3L8ir7O/VHx4y/dwuCuWfTtnM7rq2MvI12zu4z1e8uZOTwfn8/XQmVbARKowV9XwbQh+SxYd4DaukBcWVVVNi9+mU5SSeboC+Mu48Xj+7AyWEjNjlYKlR7L33udqysfZ32P80i96PdoSgYpW98EwO8Tpg8t4M31B6iqrXP7fVSVtim9o5mMjAyKioqOKsHgWEZVKSoqIiMjo/mbDcMwjP9n77wD6zirtP97Z25Xl64kS7JkWcXdjuOabidOSCGQ0BbC0lnYLLB8sLt8S99KdtkPFli2ERaWhFBDgEAgPXbsJMRxTey4q/d2paty+8z7/TGjZl3p3ivLieO8v38kTzszY9n36HnPOY/ibMb6kN6iGbnReGUbo1abKaceRmoOYnW3oPcenZ9wExnCtMW2RPV2RCLMrkcewGx+hnjF5RO5qcwpRxs5awHXNGF8jls8DCnFNsvgQLpzM75NaVfDyXCGJgmxMXBlpZVnmoX1aNEgRjLX1fky0olIRDALps8lTiy5Gi3Uj9H96s8WU3ngwnKh5YHnrY1USnlHks3fO1/xFArFq8RYL6ZvevXZb470cKYvxOqybL65s5ldpwa467YVVBZ4AWtVSeou9Ge+BiNdjN78n9NMCFoDYX5+sIs3ry2hJG/uoaqZ4s/x4F9/LXLP1/nazeVcvnyx5T46Bb3Tmj0nllye/oV1JxTW4Og+hCEE2+qLuP9gF6ORGNme5OXzvz7cgS4E1y+3EjhtrAfp8CBSlPgDYCd9IjTAdcuLeOhoL3sb+7lqWWnKU491DbNqeA9xlxfnsuvTfsR1i/P4nqOOa8Z+hRkdQ3PP3SKblOgopU/8OX2ikIK3fA3dnYWsuhxn27OMW1Vft6yIBw538+zpPnYc+iRmLIT2wd9lHus1wOLFi2lvb6evr+/VvpULjkgkMq9kyePxsHixmsOiUCgUisyRo70Y3tIkYptd2TZmL6SefIRE+WaMqitxn36IxEAjjuK6zGKFhzCLrREgRuXlmJoT375/Q9NGCPg3k2Pfg5lThqPvZUzTnFwcHutDGFGM7DL00S5kPAyOOUYvTFS2WUZe4/ziUBf7W4b44s31ZLuTSwPSdjCVoQDkps4zJ4iOIJ3p5YqTJgknIL8ixdFpYjuRGnnV0yqMjKqrrFhnnoLydQsTa56oPHB2LoY88FUxSFAoFBcRo9PFtmjC5D93t7CqNItff+wKfvNSN3/7m5d523cP8IWb6rht3SLQdMzCOvS+Y8QXX4657JZpQ2i/ubMJpy74ixuWpd/GmQmLtyCkyRvyOxFZMxMjvWMfpjsPvXRlRpcV6/4I186vEAk0sb2+iB/t62TPqT5uXjczadjfHOD7dmVdca4lQoqRbsysErR0ZsRlWUmfCAe4sqYaly549OXutMS2Xx9s48P6AaJVV5PlTX8mlhACUb4eveMBoh0v4a7JQIy0GXrws5TEu/jpym9zR6n1QShqtuN44m8wg51oeeVsXVqA16mx9/BLXHf6ccguzXxOyGsEp9PJ0qWzO8G+ntm1a5eau6ZQKBSKV5axfmTRqhmbx8U2RvtgsBn6jhO96guIRWut/V0vQoZi2zR3UFcWg0WXsrXvBQD+6mAh31hn4HPpVmVbqB8jHgG3vQgdtOa1GQV16KNdEA/BXDndFLFtKr95qYdD7cOc6Rvjv+9Yhz975gLxxDnzqGyTTl96lW3jXS+9x2HZjszizEbAEtvkWZVtMrcCo6AGmp6Gaz61MLHmicoDZ+diyANf0ZltCoXi4kOO9mJ6J8W2nx7opHs4yqd31OB0Onnbxkoe/fQ1rK3I5csPneKFZuvD3iyqRwqN0au+iO6Y1P0PtgV5/EQ/799STqU/81L3tFi8CQC960DS3XrnfhJlG9AdzqT7Z2X9HyOFhuOlH7OxKo9sl849zzUTjk1v7+wKhrnzvgOU5br5/BuWTgiK2sBJjILa9ESlKZVtPpfO1up8njrRh5mijcEwJacP7WGRGERbcUvGAtai5VsB6D7xh4zOAyARJev4z/iF3M626988Gbv2WgC0FquV1O3QuKq2kLzTv0IgEaF+TCMx21UVCoVCoVAoZvLYF5H3vT39403Tntnmn7nP6UM6vMixPjj1KACx6usw/SuQQkd2Hs7s3kwTIsFpbZ2nc6wca8BXw/P9Lv7ql8dImBIzpxwAObXFcshyIjUKLXMyGUsxDj1it5Ge1T3RPBBiZWkWrYMR3vODQ7QEwjNOnRTbBtN/PoDYKKYzvTZSmVWC6c6FvpOZxZiLgQakw43MmTmexVhyNY7255GJ6MLFUyjOQoltCoXi3BjtQfqKARiJJPjus61sXZLLdasnq7nK8318/4NbqSr08dkHTzAwGiV22acZueW/0crWThwnpeRrTzRSnO3kzmuXnb9KJl8hsqgeZ/ehmfvCg+iBM5gVmzOPn1cBddfjPv4ADgw+ub2avc1DvO2/nqVjyEpeInGDP/3hAUIxg/93Wz3+XHuF0oijBRow/CvSFNsKAdAiVuJz7TI/HcEoxzuDc572XEM/m6PPYQodx8o3ZvZ8wIZ1axmU2Yw0Z26SEGnei1PGGFm8nfKiKUJq6VqkrwhX6zMTm66tL+QmYxcAwkwgxwYyjqdQKBQKheJ1TMsfkJ2HUi5EThAZQkgD6bUWNA+1BfnQfS9ytHMEsKrbRKgfTj6MUVCL5q8DhwezaBmi68XM7i06jEBOqzR7XrOqeHx1V/O3b1rFnoZBvvLwKUxbLJJ2NRswMa/NLLQqwkjlSDoulE2JNxSKMxhO8MY1Jfz4I5cRipu85weHaApOf1/jpgoyFMjoEWVsFNJsI0UI25F0AcW2QCNmXjWaPrOZz6i6GhEPYbTsXbh4CsVZKLFNoVDMn0QUERnCsKusfvB8O8Fwgr+6oR79rFbIbLeD//jjDQTDCT7/mxMkCmsRK26Z1ib6yLE+jnSO8Ilt1eRlnd/BlqJyK47uwzMG2uqd+639mcxrm3rdjR9AD/UiTj/GHZsr+Ld3rKJlIMSb/m0PexsH+Nwvj/BSe5C/v7mGleWTCY822Igw44iSma0LSfGNt5FaydP2ekt8S+Xi+atDHdykHyBWvgVHTpKV2xSU5ftodNSSNXg843Nb9j+KKQV1G3dMFxQ1DZZuw9n+7MTfx/U5rdRqXROrvNI2jzhn4mHIdPVZoVAoFArFaw452IQIB5DpVsePWXOzDK+dU53oZ19LkPfcc5jvP9eK6StCDDYjm58hWn3tRK5rlq7N3CRhoq1zstLs+dFSvuv5EFz2Md53xVL+9Jql/OJwD4+2WWLRuPsoAME2pDsXmW2PD4mNpYwnnVkIx2SbaHPAEuhqS3K4tKqAX9x5OVluB98+HMWY+izjM9vCmYltREcxXdPFNiklDX1jSQ0BJhxJF8gsQA40THMinUqi8nKk0JANOxcklkKRDCW2KRSK9Og4OOl6NI6dlJi+YvpHY9z7Qjs3LC9kY01J0kusLs/jS7eu4rmmIP/7XOu0fdGEyTd3NlFf7ONdW5ee//lclZvRIgGkPTx1HL1zP1JzotmtphlTfyMyuxT30Z8CsH2Znx9/YD3Zbp133f08vzrUwZ1XLuaGVdOH72r9JwAQi1anF8edY91n2Kr4Ks5xs7Y8hydOzO6AGoolOHH0ILWiA7P+pnnPwwsVraUi1kQolCKxO5vmPZwS1WxZvWzGLlF7LdpYL7LPeg/5Db8iipvvxWwDh4US2w7dB3dvw3zxZwtzPYVCoVAoFBcekWFEaAAhzfQrskatHGp8PltD3xhLi7zsWO7nGzubeXHQhbP7IMKME6uenCtmlKxGCw9gBDsyuD+rrdN0T4ptTQNhDle8C2/5CgD++qaVrFyUw30nbfFpah4+1IaRUw4uu0MiZWXbkGWOMCX3bOq3ui7qS61Zb7UlOXzmxhUMReFI+2SnhPTY3QihTNtIx2YYJOxvDXL73Qf47rOtMw43C+vRwgHM0QUwCzANGGzCyK9O/juFJw+j9BJE09PnHkuhmAUltikUirSQP3035u//evrGKUnJ3c+2Ejckf/mGuU0N3nPZEm5eU8q3d7fy2PFeHjraw1cfa+C99xymMxjlMzfU4nZlOCttPlRZlWvOY/dP26x37CdRvBrdk53srNToDlj/HpytTyPtpKumOIuffGgDO5YXctvaYj5yZeWMd6T1n0RqDrSSFenFEQKy/IjIZOLzxjoX/p5nefhIZ9JTvvnEaa42rMG72qo3zePhLPJqN+ESBscPpz+3bXh0hOrwMQb8m/G4k7iz1lhz2/Tm3ZCI4DzxG5qLt/GHYatqUi6QFfxIh1WRJx/8c+JtmbfCKhQKhUKheA0w1DLxrRzrT+8cexF5UmwLsWpRFt9532a+cvtqmsKWsGW68zArJhdlzRLbJKEzg1ZS22zAdFlC1lg0Qc9IjFr/pDilaYK3bKjgYI9JwpULU8Q8GWzFzKlAjItZqWa2hQcx3bnTxbZACKcuqCycjLltWTECePr0FIFScyBdORMCYdrERuGsyrbTvdZC7befbuHx49MXiMdNEsyezLsnZhBsQxgxjLzqWQ8xllyN3n0YM1PjB4UiTZTYplAoUhMZRox0Qdve6SXyttg25izkVy92c8sqP8vKCua8lBCCr779Espy3fzlL0/wuQdPcv+hLlw6/MW11exYvUB236koXo657g68B76D6LCNEowYevdhjPJN5+SCKja8ByFN9CM/mdiW63Hwjbev4R/etAKXc6aYqPWfwMhfiu7yph/IV4g2PoMjOsKHm/6Se1xf5a6f7eRA8/RV3B8828Tduxu5I/dF4sVrcBZVz+fRAFi67goAuk+kP+fi0LOP4RZxClZuT77CmF+JLKzF1f4sjobHEdEg2Zv/mD5pt9qOLExl25mTR2kzi+k2sun73jv44o92sfuUsltXKF5phBCfFkK8LIQ4KoT4iRDi/M4OUCgUr30yaS8MNE1+P5bm5/wUsW04kqB3NEZdcTZCCP74smouW2stiDblX4bDNflfllGyColAdiaZBTwb48KV18pzmgesKrPakumLvW+6pBwBBDQ/jExZTB1qw8ipADtvlKnaSCNDM5xIm/rDVOZ7cDomR78UZLmoy9d4pmm6ACU9+ROjS9LCSCASEUynb9rmtsEIXqfGuopcPv+bUxzrGpnYZxZZnQ/jXQ7nhN25YhbM7vRpLLkKIQ2Mht3nHk+hSIIS2xQKRWps62wt1Icx0Di5fcwS257uchCJm9yxeXFaIlWux8l9f3IZd922kgfv3MKLX9rBrz5+NZ+8cfWMWW/nE+2Wr0LOIjyPfAriYbSeIwgjCpVbz+3ChTXIpdvwHLsfaU53Ip2tPVbvP4FRtDyz9llfESISgHgY768/gLPvKAAbvD18+J59NPRaCcwjR7v4u4eOcXuNZEn4OIm6G8/pPeeU1jMmfIieI2mfE3j5KQw0qjfMbucuaq/F2bEX55EfY2QtonT9zSwtLyGMZ0Fmtu0+1Ycv1EG0aAVN1/4XfjHMbac/x4e+/xwvtWXYGqFQKOaNEKIC+CSwSUq5BtCBd726d6VQKC547n0z8uHPpXfsYPPEt3J09hEb0xjrRyLAW0hjvyVeLbNbLAHKKyoBeCxx6fR8zZWNWbAU0Z1+XjQ5s80SwBoHrMq0+tLcaYeV5XnZsrSQhlg+YtgW2yJBRHQYM7scaYtZqcQ2GR7EdOdNu+/mgRBLi7wzcs9LSnRO9IzRNTRZLSc9+RCZ24RrGrFR6+tZbaQtgTBVBR6++75NFPicfPL+l+kfjVkxcsqtttPeBRDbAtbvK2b+HGJb2UakwwONam6b4vygxDaFQpGaKXPNZMuU1kFbAPn5SYOaIi+ba4rTvmS1P4t3X17DJdXFeNyuc6okmzeePMTt/4VjqAnnrn+YMEfQqudnjjAVsfH96CMdiKZdqQ+OjaEFW5HFaTqRjsfw+dHGevH89k709hcIX/MlAD6zPoEA3v/9F3jkaBf/56eHWVeew9+s7EEgEctvmt9DjaNpBHJWUBY+zeBYasv0gdEoFUP76fYtw507x89IzXZEPISjZQ+xFW9Bd7rYsaKEHjOPeHBu44dUGKbkrt8do0rro6yyjqu234jz9m+zmWN82XkfDx5qT30RhUKxkDgArxDCAfiA5P3vCoVCATDUCk27MVrSHGEx2ITUbBfKdCvbwgGkJw+hOzjTZwlNy8smxS+t+ioasi7lf3qXEY5NN10wS9ag9R5Jf7j/eOuiLbY1DYTQBSwpmuneedv6Cppi+TDcZTmrjjuR5lbAeOVYGm2kcsp8uLhh0j4UobrIN1NsK7be2+4zk10S0pM/bXRJSmyxTbqmV+q1DoapLPBQmuflfz6wmeFIgk/8/AjRhAlCYBTWIfpPpR9nNgYaLCFy3EAiGQ43RsVWtCZV2aY4P8z0wVUoFIqzGWiwyuOdPmTbXtj0Xmv7aC8JZw4Hu2P85XXVOJO0R17w1GxDbr0Tz97/xshbgpFbhZ5Xfu7XXXEr0luI8+VfEK+dvZoLQBuwbc7TdSIdx1eEPtyGPtzG2HVfwXvlnyGf/wZF0Tb+451/zIfue4k77ztIdaGXr99Wj+/oo0jNgZ6uCcMcOBdfysrgvTx5spM3bph91RDgsRebeJs4TX/V++auqKu+Gik0hDQRl74bIQTblpfQ+0w+3kAX85yiB8AvD7bT19OB1xMlYrfQikvehdl5mPft/S/+9Mg2zFtXvzqir0LxOkNK2SGE+BrQCoSBx6SUj519nBDio8BHAUpLS9m1a9d5u6fR0dHzev3XA+odnjvqHc5ORfvvqAfMgYY539H4O1zXcBCHr4qc0SY6Th2mJTH7OeOsaj5BtvBy4MABnj0Zx6VB6/FDtJ+YFKOOLv0SA/sj/PDxfVxaMvmrdFUsn7qRTp554rcknLnJLj+NmoYjVAgnB186htA0Dp6O4vcK9u2dKSbmxiSnKMIZG2T3zscpGHyJtcDxrlHCw8fZBrQ2nKBjtmeUkmvGAnQPR2nctw+ArjGThCkRIz0z3mc+IYo8Gg8dbKZGWjNzV4dNskd7eTbNn0/fWBtbgKaOXvoSVkzDlLQPRlidG5uI+aHVTv7j8Bj/+dBerqpwsJJCCnpeTDvObKw9/QIuVwkHDx2acyG7UqumfvBpnnv0AWLuonOKORX1b/ncuRjeoRLbFApFagINyJxyjIIatI59k9tHexkU+Tg0wds3Vb1693eOiOv/FvPMk+gDp4mueAuuhRBcHG6ovRZn07PETBMxxzX1fkts08rWZBbDXq0LXfHXeK/6GJqmIf3L0AcbWFuRy9fftpL/fa6VL95YQ2lBNtrAqcznws2Cf9kWHMe+x8mjB1OKbWcOPIVLGOSt2Db3Rb35UHU5iVgUZ5klCK6vzOcprQA52oGUcl4uteGYwdceO8m24lEYAVFQPbFP2/Elogd/wtsjD3C49Q42VC9coqVQKJIjhCgAbgOWAkPA/UKI90gp75t6nJTybuBugE2bNsnt27eft3vatWsX5/P6rwfUOzx31Ducg3u/AYArPszVWy9F9+YlPWz8HcoXg8TKViPbg5TnuViazntt/QYJfRGbN2/mu2eOUFscZ/u2a6YtxF2RMPnO0cdpSeTz0c0rJ7brJVFoupetVV6cy9OINfwA5kA+GzdtQtd1hg7uZ0W5m23bLk+a6/zPqWehHy5bVYWrrRWOQv2mHThyS+E5qCrzUz/bM8ZC8HSc4sp6ijZvBuCpk/3AMd5w2SVsqZte/bVr1y5uvqSIBw62s3b9BjxOHffQUhynT3DNNdektzDZfgD2wZL61VQvt2K2DYYxntjHZWtq2X6VZYawTUp+0fAkzTEfn968Fpe8HPeenVy9eR16VmHqOLMgX/oLYmUr2bJly5zHaUt80HQPW/whHBvfNu94Z6P+LZ87F8M7VEv4CoUiNQMNGPnVGBWb0ftPTrj2mCM9tMSyuba+gNL8mWXvrxmcXrS33o3U3Zg1185L0EmGqLwMfawbc6htzuO0/hNIpw+tcG7RagabPkj8HT/CveOvJxIf4V+GPtiIlJJr6or4/nvXU1tqJaR6/wmMwvoFeT5HxaUAhNsOzdky0R2MUNC7FxMdZ20KsQ0Q7/ox/PHPJyrgdE3gyi/DFw+QSBgpzk7O955ppGc4ygeWWy0forB6cqcrC3PLR7lBP8hzf9gzr+srFIqMuR5oklL2SSnjwC+BK17le1IoFBcq4SFk8zMYudbCrhlonvt4IwHBNozcSqSvCBFKz4106lyzhr4QtX7fDGHJ5dC4bnkJuxsGSRiTpmFGibVIKDsPp/9MHitWwpS0BMLU+Ge2dI6zcrkl7B0/eQKGWpG6G7L8oOnW93O1kdpmDOaUNtIm25ChbspMuqnsWFlKOG6yt8lqJbXaSIemG6XNhd1GOtUgoSVgxVzqn+xVEEJw7YoSnm8OEksYGLZJAk/8DTz6Bfjtp+DBj8PgpLtsSowEDLXM6UQ6jlm8EtNbhGxQc9sUC48S2xQKRUpkoIFE3hLM8k0IJEbrCwCEBrvoNvJ4x8b0jBEuaCo2wGdO4974noW7ZqW1mjY+C242tP4TJArr0fQMi42z/DhX3zq9NdNfjz7ahRmxzBEmkrZ4GBFsQ/ozNGGYjaI64pqH8vAp2gZmH8r7uyNdXKYdI1S0GkdW/qzHTeDNx5E9vbqsaFEVuYxxpCXzuW39o1H+++lGrq0vpN5lzRoRBUumh7zyz4gKN0tP/a81C0WhUJxvWoHLhBA+Yf2HtAM4/irfk0KhuFA58wTCTBC+5H3Wn6c6jSZjuB1hJjDyqpA+PyI0kF6cUADTk08wHKdvNEZdSfKF5DesXsRQOMHB1imOnd4CzJzF0PVierEiQxPCXsdQhIT+mgYvAAAgAElEQVQpqS2efWDGhrVW98Pxkycg2IaZUz6RN0qnF+JziG1nmTGAZY5QlOUkz+dOesrltUV4nBp7GibPFdJARofTe75xg4QpM9tabbGt5qznvH5lKSFb2DMXrUM6feiH7kXu+x7msQfh0H3Ej/0uvbgAQy3233916mOFhlGxBa1jf/rz9hSKNHmN/3asUCjOO6EAIjyIkVeNUXYpUmjQ8jwA2lgvIWcB21csepVvcmEQnjy0hXRDLV2DdGbhSCm2ncQsWr4wgqXfKssXgYZpm7XAaQQSSlYmOytzNJ148WpWa838/kjyueaGKfndgTOs1xrQq6+Y9/MtqbIq/vYfzfx38e8/00Q4ZvDxqxejj7RhegvRPGfNUvEV0lr9dt5g7uGloxk4iaXJqZ4RAmOxBb+uQvFaRUq5F/gFcBA4gpWP3v2q3pRCobhwOfl7TJ+fxIrbAZCpxDbbidS0xTYt3J+ekBIeRHoKaOy3zRFmqfratrwYpy7sVsxJjNI16GmaJMjwENIW25rseHUlyeMBeAstJ9S+rmbMwVbMnPLJxVNHmmKbezL/aRoIU13omTU38zh1rqj180zDIKZpTgh1MjyU9PgZjLujuiYFy9bBMD6nRkmuZ9qhV9b5cTs0nj4dQGaVMPKxowz+eQPBT5xg+MPWDLvxReS0sJ1IjfzqtA43F61DD7ZghpQzvWJhUWKbQqGYmwnr7Gpw52D6V0D7C7T3DuCTIUrLKnE61fjHpOgOqNiIs/vgrIeIUD9aqB+5UCKY3yq/1wbOTNus2c5OWmmGJgxz4K3awFq9hW88cYrDrTMTlH955ARZPftxYCCWXjPvODn+CgBON6ZIrs/CMCUPHGznipp86ktz0eyWkmSVfaU3/hUAod3fnvd9JqOhb5Sbv7WHrXc9wUfv3c9jL3cTN1T1nEIhpfwbKeUKKeUaKeV7pZSprY0VCsXrj0QMefpxYtXXomWXIF3ZyFQthbbYJvOq7DbSgdQCWCKGiI1ievImnEiXlSWfC5ftdnBlnZ9dZwanVcSbJWvQh5onxq3MSXgQ0xa/mgZssW0WcQ8Al4+YK5/CRB+xQCtG9qTYJp0+xJxim3U/0ltgfZWSpoEQ1YWzt60CXLeihI5glDO9oxOuqYQCsx4/jagljslplW0RKgs8M8yyvC6dK+uKeKZxCNM0EQ4XDpcbXdfRXT5roT8+exfFDAasBWeZ5ngWo3QtAGbHofRjTEXK1G6witclSmxTKBRzY4s2Rr71gWWUb0LvOsQjz1szKZYtXbJgM84uRkTVVvT+E7OuyGm2OYIoPXeHUAAKa5BCQx86q7Jt4CRSc6L56xYmDiDK1+OVEdb7+vnoD/fTEwxP7Pv5/ja+s7uRD5a1WA6oS89hHFN2CQDDA50ERiNpn/bMmX56hqPcutqPpmlowVbMvKqkq7i5i2rYl30t6/t/izGaZrtJGvz7U2dwaoK3rSthf/MAH/3hAbbe9QS7T/UuWAyFQqFQKC5aWp5FRIeJLb0eoWmYeVWIoRRiW6AJqTmROeVWZVtsBJlIoedPtFoW0NA/hsepUVngm/Xwm1YvoiMY5WTPZH5nlK23vnnp/tTPFbEq28AS24p8Tgqykrd0juMoqGSp3osn0oeZWzG5w+mDeHj2E+1nGxfMBkNxhiMJaornnrd83Qor/9p9JoD02mLbOVa2VRV4k+ZhO1aW0hGMcrpndPoOIcCZNdmWmg6BBkvk8xWndbhZss76pnOeYtuz30J+cw0y2DG/8xUXLUpsUygUczPQgBQaMt8aSmuUb0SLjxI48jgABSWVr+bdXfhUXoaQBqIzeXWb1m+1Ri6Y2OZwQ0E1+mDjtM36wCnLTdY5dyKXEXZS+Q8bwgyHE/zpD/cTTRi80BTgC786wtbqPK52HCdResmsrmFpkWO1KfsJ8vTJ9EWqXxxoJ8/rYFtdIZgGYqQTmTe7a254y5/jI0LbI9+Y/71OobFvlAcPd/BHlxTx+ZvqefzPt/LNt67ArQv+9bGTCxJDoVAoFIqLmpMPIx0eElVXA1ZrqBZsnbtSbbAZM3cxmsOJ9FlzYOVo39xxwlbFlunJ50xfiJoiLw7H7KNFdqwsRQh46uTkAp2x5BrilVehPfElZO8coy9MAxEdwbTFr6aBMEvmaOkcR8tbzHphL4Jnl09sl04PIjGH2HaWQUKzPTttrhlxAOX5XlYsymFPw+CEMCjDaVa2jYtjtkFCwpR0DEWoLPQmPXzHCssRddfpmQue0umbFO/SYaABI39p2qNhpK8QM2dx+uYWZzPYhAgNYD74CavKTaGwUWKbQqGYm0CDlbA4rfkKRoVl370l8hwAWm7Zq3ZrrwkWbwJmN0nQ+k5gegrRckqT7p8X/nr0wbMq2/pPYRQtW1gji+LlSG8BS/qf5h/ftIzD7cN88scHufO+A1TkefjaNjeOnhdJLEnTJn42fH4kgkpnkJ1pim3BcJxHX+7mphVF+DwuxGgXwkzAWeYIU9my9Up2mpfiP34vMpOkbhbue+xZ/sH5A/72+BtxHvguLofOjpUlvHNjBYfbh2noTXPIsEKhUCgUr0ekRJ78HfHKq3B4rRZLmbcEfbhtblfMwSaMvCqEEEiv3zpvLJXYNqWyrW8sqRPpVIpz3GyoKmDXmSnik9CI3vItpDML+fMPzl5tFglasdy5SClp7A+xtGjulk4AcsvxYV3TyJkU26zKtrlntkmhI9zWOxyfEVe/KHf2c2yuWVbMS52jxJz2sem2kcbGrPZWzRK8uoKWCcTSouTVdIvyPKwuz2VP48yxJNKVhcggL5OBBoy8JRnlnsaideg9L83PJCFi5XN641MY++/J/HzFRYsS2xQKxdwMNGDkVU98YMncSkKuIq7Qjlr77RY/xSx485HFK3B2HUi6Wx84SaJoGbpj4ebeCf8ya2ZIIm5tiI2hDVtOpAuK7oRL34ur8THeUBHnI1dU8uixXhKGyddvr6f0zP0gNMTG959jHAdk+VmVHebZMwGMNGaePfRSJ7GEya2rixFCoAVbARAF1bOek+NxcqT8HWQbQeINe+Z/vwMNVB39Np87dQfv1J9CZvlx7/03pJ1c37qmBAE8cKB9/jEUCoVCobjY6T6CCLYTXXr9hBBl5lUijCjmcNesp8nBZkx7RutkZVuKxTpbRBoROfSPxakrmbvqC+DG1aWc6AnROTgpdMnsUiI3fQOt/zjGI59PfuIUd9CA3dJZm6KlE4C8ydbRqG/SnMya2RaeXSgKDyI9eQg7l28OhHHpgsVztMmOU1eSTcKUtIVdVqxwmiYC0RGkc/KZWuxquqVzPOeOlaUc6RxlYPSsll9nVvqVbVJCsAMjZ/JdtQbCBMPxOU8zS22ThLE0xcSpRIdJlKwlvvhytMe/kHqmoOJ1gxLbFArF7EhprQ7lV0+utgnBccdKXMIAQMtRYlsqRNVlOLoPIU1j+g5pWk6k/hULO/euqB5hRCFoiTnagGWOQPECmTBMQWz+MEgTx+F7+cT2aj5+dRXffMsy6otcOI/+lFjtjbiKZq8mS5vsEqo9IwyE4hzpSD0v5BcH2qkr9rGmwlqJFcE262th9Zzn1W3YDkDbsefnd59jA8jvbGNx/9P8RF5P57t3Id75I7RoEMf+/wGgNNfN1up8fn24E9NU7QYKhUKhUCTl5MNIBPGl101sMu2xJrM5kjriI4hIkESudZxpi22k2UbaErE6OZbNZVZgs3GJZThwrHv6XF6j5jqiGz6CfuD7mMd+mySWbVjgzp0wR6hPIx65iwEwpaDDKJrc7vAi4qE5xLYhpDt/Itds6g9RVeDBOUeb7DjjImDjkInU3RnMbBtFurInYk6Ibf7ZRczrV5ZgSnj61HSX15QGEFMJDyLMODJr8veTj/z4Jf7sp0cw56haM0qtuW3zMkmIjmC6coje9K9IKTF//TGQygxLocQ2hUIxF2P9iOgIRt6kWGKYkp2hGgBMdz7CsYAzwC5WKrdaw3n7ps/pEsE2K3lYKCfScWxHUjFwGpgU2xbSiXSCgmqofwOel3+KSES585pqNtf4cZ18EBENYm76k4VpXc1eRDFWZdjO4z1zHnqmd5RDrUPcusqPw64Y1IKtSKGh5c8+sw3gqnXLaJd+Qq3znNvRvAcRG+G9sc9yYu1fU1m3Bm3xBuSym/Ec+h+knaS+eV0pncEozzekSP4VCoVCoXi9cuphjLIN6LmTVVymnZPOVj3kDXfbx1kzhaUvzTZSu7Lt5IiV1y5Po8WyrtgSyBr7ZwpBsWs+R6JkLTz4ceRI9/SdkcnKtqZ+S4Sa04l0HLuyrYcCWkcmF3Cl0zf3zLbxyjZb+GoOhFlSmNyo4GzGxbGWQBjpyUdE0jdIkM7J1ti2wTA+p0ZJrmfWU9aU51GS42ZPw1nVc64siI+l1+JpVzCa9t/7SCRBZzDKkc5Rfn149mrIcUdSujIX22RkGOnOQeZVEt32ZfSWZyjvfDjj6yguPpTYplAoZmfCibR6YtOJ7lGejdYC1geZciJNg8qtAGjtL0zbPOFEumjNwsazxTbNntum959C6i40f+3CxrERWz+KFh5AO/mQtUFKnId+QKJoOc7aaxYmRnYprkg/Kxdl8fjxnjkTrgcOtqMLwc2r/BPbtGArZvYihMM1Z5xcj5Nu33Lyh09gzjUPZjaanyEqPLxEPXdur5v49yGu/RxabATH/rsB2LHcj9ep8cCBtsxjKBQKhUJxsSMlsu8U8dJ100QhOe7COdjEaDRBNDG9a8ATsRbkxkU5XDlI3QVpzGyTmpNTgxKvU0urxTLP56Q4203zQBKhS3cRveGf0KJB4qeeOCvWeGVbHk0DIdwOjYr81PGwn71D+mkfnOLObotts+VGMjKE6c5FCEHcMGkfDFPjTyMeUJjlIt/rpGUwgvTkTzqbpiI6OqONtLLAgz6HaYGmCa5bUcIfmoPEElPFxKz0K9vGbLHNntXXaFcOZrl0vrWrefZ2Um8BRu5i5Lwq24JIlyWWJta9m/iSbdQ03IuMjqQ4UXGxo8Q2hUIxOwFLrDHzl05s+kPzIC/LaqTuQmYVK7EtHQprkD4/zu7pjqR6/wngPFScZRUhvYUTJgnawEmMglo0h3Nh44xTcx2yoAb3i/da8ToPoPe9THz9+3E4FyhmdglaqI+3X1LKse4x7nkuefuIYUp+ebCdK2ryWTQlcdWCbZi5lWmt4joXX0ql7OJEU+ZCWKJxN3uNZVxR4abSP2VVvOwS5Ipb8Rz+PjI8iM+lc8MKP48c6yMcS2QcR6FQKBSKi5roCCI+humbNJAaiSR48swoQYefp184yLq/fZQPfn/6QuZkZZtdyS4E0luEGJvemjiDcADpyadxIJLSiXQqdSXZNAWSV5WZ/pVIBPSfOSvWlMq2gRDVhZ704uVapgg9opj24ORcM+n0WmYMc8xsM92W82nbYARDpnYincpSfxatgYhVHZdmZZuMjU6rbGsNhKkqSF1Nt2NlKWMxgxeaJ0U96fLN3SY7FbuyTWYVA5NVh1+5fRWDoQT/8XTy/BHALL0EvedI5iYJkZEJsQ0hiG/9BA4zQuLkY5ldR3HRocQ2hUIxOwMNSM0BU1rvnm8aosqfi7z0fRi1NyixLR2EgMotOLsOTH6AGzH05qcxchejefMWPqZ/GY7BRsBqI11wJ9KpaBpiy0csMbHrMK7D/4vpykG/9I6Fi5FdijDjvHW5myuW5vPPD5/kTO/MFcPdp/voGY5y62r/tOcVwdaJYcmpWLL6MgBe3J+hScJoH46Bk/zBWMX1S5wzYontn0OLjeLY9x0Ablu3iLGYwSNHOjOLo1AoFArFxY7demlmT4ptd/7kCJ964Bin4n4q6OWa2gKeawxMG8ngiXRj+vxonsm2TOnzQyiF2BYKIL0FNPSHqEnhRDqVupJsmgciGIYxc6fDjZm7eGLxeoJxwcqTR2N/iOo0WzpxuJEr38xR3xbahqaYCDi8CCRyNvfT8CDSbS0AjjuR1pak0bZqU1OcTatd2SYiQ+mJUbFRpMuqbIsbJp3BKFWF3pSnbaiyRMEzvVMMEZxZiHiaBgkTYps1s62pP4RTF9y0ehHv3lrFzw92c7I7ecWZWboWfbgVc2wgvVgApoGITRHbAKNiM3FHNpz4XfrXUVyUKLFNoVDMTqABM68KzW69i8QNDrUFuaw6H+3Wr+Pe/hev8g2+dhCVW9GDLZYbVnQY7y/fi6NjL9ENHzkvIpjw16MPNSIjw2gjnQvvRHo269+NdPpwP/evOE79ntiqd+DMKli46+dYybYY6+Mf37Qct0PjUz89RHyKM+kLTQH+4meHKcl2sa2ucPLceBhtrBeZn55RQ37tZgCCzRm2ErQ8A0Bv4QbKspOsUC9ag1x5G57DP0CGAmxakseiHBe/WGBX0lAsQWAstqDXVCgUCoXiFWXEmq9l+izRxJSSEz2jvGVdCevXXsJy9wBffctKCn1Ovv3U6YnTvOFujNyq6a2nviJEKIWAEh4i5sxlYCxOfRpOpOPUlWQzGjPoGY4m3S8LatAGz6qmCg8hHV6iOOkKRqlJx4nURrzzh7QsfhPtg5EJ0Us67Ur+ZK2WpgGRYasFFGgKzEdsy6J3NEbcmYuIBNMU28Ym2ki7glESpqS6KPVzFma5yHLr0yv3XFYbqUxnvMdoj9U27LEWshttMwiX08FnblxOjsfJXY+eSfoMxqJLgAxNEuxWUeme8j41B/2Fm9AbnkAac7ugKi5ulNimUChmZ6ARI2/JRIXOwbZhYobkqnprDoKqasuAKqtaynHqd/h+9jb09r2M3fgNPNd88vy8R/8ytFA/Wsc+688LbcJwNt58WPtHuJqfQphx2PwnC/tc2eNiWw/FOW6+dHMdRztH+PYTlvnDrw61857/2Uue18Hd71qJzzM5m00b7rC+KahOL1bOIkLOQvyjp2gbGE37FgMvP8Wo9LBi3eWzHiO2fxYRH8Ox/7toQnDr2lL+0DRI91Cas0jS4K/uf5Er/vlJfry3NfNWCIVCoVAoLgTOqmzrCkaJGZJLFufh9NegjXbjljHet7WCZxsGOdRiGRx4wz2YedMr2aXPjxYemPMzUYYDjAhLMEnHiXSccWFufDbY2ZiFlthmTq18Cw8hPXl0DceQkJYINZXqoiw6gtHJBUenVTEmY0mqvyJBq+ptXGwbCFOc7STPN/cM26ks9Vv3Nyiz0KLB9E6aMrOtddCquKtJo3VVCEFVoY+Ooakz6bIQZgKZSC5oTmO0F+nzI2yxtXEgxNIiq3Iw3+fiMzct52D7CA8d6Z5xqlFizVCWnZmIbcPWOe7pPzP9/i1o0SBGY4ZdEoqLCiW2KRSK5EiJDDRi5FdPJCzPNw3i0ASX1xW/yjf3GqRsPVJzkrXry4ihNkJvuQfv1g+cv9ZOfz0AjtO/B0BbtPr8xJmC2PIRAGJVV+MqW2Bxz062NXvA8Y2rSnjj6mL+Y1cDn7n/RT79sxe5pCKH/333ampL86Yl2WK41fpaWJ12OFl2CatFE48end256myMxj0ckMt506alsx9Uusp2b/0JMhHlTWtLMSX88uDCGCV0BcM8crQbn8vB5391hDvvO8DgWVVuvSMROofmcC1TKBQKheLVxq5sk/bnf4tdkVVTkg0F1QgkBNt418Zycj06337yFCRiuKP9GLnTncelr8gS2+aqjAoFGDAtMWh5WWon0nHqxsW2JI6kAGZBDVp8FHOqI2lkCOnOo9uuhqsoSN1eOZXqoiwSpqTL/iyfrGxL8tluz4cz3ValV/tgmMX5nozyz/HKu76EbcQwW7vqOFJabaT2fbXYM+2WplnBV1XooyMYnVm5l0xMPJuxXquNWNOIJkw6hiLU+ifjvmtzFctKs/nRviQjPLwFGHlViEzEtogltpnO6WLbQMGlSN2NVK2kr2uU2KZQKJIz0o2Ij2HkVU9ser5piHXl2eR43a/efb1WcXpgyZWYvmIidzyAb80bz5/QBhOOpK6Gx5EOD1rhHALQQrFoDeat38K84SsL/2zjYtuUmSufv6kef7aL+w+08+a1xfz7O1bgz53prqUFLSFLpFvZBmQt2cgyrYOdL7emdXxiuIfiSBO9BRspyZs7mRRbPmpVHZ54iBq/j1WLsnj46MwV1vnw833tlnj3Z1fwhVtW8tSJXm7+1h7u3t3AX/zsMNf8y062fOVJbv7WHkxTVb0pFAqF4gJlpBvpykbzWMLXuONnbXHORKW6Fmwly+3gPZsreOrUAKdPvYzAxMitnHYp0+dHJCKYs7lDSgnhQfqMLNwOkZYT6TjFOW5yPI6JWWhnYxbUWCH6J1tdCQ9huvPoHrEWw8rTcSKdwpKicRHLijmnGGXPh5N2W2XPSIxFOe6Mug+qi7IQArrjVhwZSuFIGg9Z1XQuS4hsDYTxOTWKczxpxasq9NEZjGLY4uj47DcZS91tIEd7ML1+hBA0D4QwJdROaQvWNcGt68o51j1G30hkxvlm6Tq0TEwSxivbXNOr9kzdQ6LqKrTTj6TX/qq4KFFim0KhSM6A5Zxk5lcDMBiKc7xnlMuXFpxfkegiRrzzhxgf34936dbz34KbvwSpOdEiAYyCOjTdcX7j2WibPoCn8pKFv7A7B+nwIsZ6Jjblehz89x1r+cc31vJ3t9Tj8yQXgbWhVqTuQstdlH68snXomIy1v8zgWOq2hZMvPAJA0eptqf991I67t94DwI7lxRzpHKUjkObw31kwTMnP9rVydb2fan8WH7mmhl997Ep8Lp27fn+C3af7WFmWw42rSwmG43QPz0wyFQqFQqG4IBjpwswqnciXWgJhslw6JbkesGewakFrQezdmyvIcuk8vPs5AIy86TNapbfI+jraR1LiIYQRpTfhozTHja6n50QKVttjXfEcjqQTYtukI6mMDCLdefQMRxFAWX6GlW12pVbboP057rDPTya2jTufuvOQUtI7EqU0N7NFc49TpzzPQ1vYaj2V4RRim30f4yJg62CYygJP2u+1qtBHNGHSOz4Hz25HTauybbQP02eNu2myW3vrz5pPd92KEiTw9OmZphlm6Tr04TbM0RSGGuPYlW24Z1ZDGnU3og+3Y3S9lN61FBcd5+03ZiHE94UQvUKIo1O2FQohHhdCnLa/LuD0bIVCsaDYzklGvpUk7LUtuK9eplpI540nF2dW/isz6053QFEtAEZR/WtfIBUCskumVbYB1BVncdv6ChwOW0yUEs6a6SGGWzFyFmcmOJZZguEq0cwTx1JXnQWOPsUYHjZu2Z762pqG2PIntnvrS+xYbv0SkEnLajJ2neylMxjh3Vsm22fWVOTx8Keu5tnPXse+L1zPd967ifddXg1AyyzzZRQKhUKheNUZ6cbMKpkmtlWNCzbZpUiHB33YMhjK8zp518Yy+tqs6rGzDZGkz/qcZWwWsS1kzXvrivkozXFlnKfVlWTTHIgkrYaSOeXWwP5plW2DmO5cuoejFGU5cTnSF/cASnLceJzahCOptGe2JW8jHa9sy2cwFCduSBblpVdhNpWl/myaQ/Z59vualXHTgPGZbYEwVQVpOq4CVUXjYqLdJuuyK/eiKSrbTAPG+jB91u8qjf0hBFB31gy+1eW5lOa42XNmpmholK6zLpVuK+n4s3pmzvlL1N6ARCCPP5TetRQXHefzt68fADedte2zwJNSynrgSfvPCoXiQmSgAam7Ia8CsFpIs90666sKU5youGCw57aZ59uJ9JUiuxQtNEuibON+8vNk3b0Fpjh/acE2zNzKzJLn/CVITx4bXa089vLcYttoNMGiwf20Za0jJzfNOS/r3410eHEe/gE1fh9LCj08dqwn9Xlz8OO9rRTnuLl+Vem07W6HTkW+d+L5qwrt9pOBc6ukUygUCoXifCFHujB8k2Jb00CI6kJbsNE0yF8yUdkG8N6ti6nWe4nhnBg9MXEtu9JpVrEtbIlHbREPi3Iza7EES2wbGIszFEriBK7pmPnViEDjlHhBpCef7pEopTmujBdEhRAsKcqaEKOwK8iSGiSMV7Z58+mx21bL8jKrpAOoLc7i9Ihd2ZZKbBu/D1cWccOam1ZVmH7M8TylfeL50mwjDQUQ0kBOiG1hyvPc+NzOaYcJIbhuZQnPNweJJYxp+4xS2ySh42B6N2sbRkjXzPxPZhVjlG1AnHo4vWudA08c62EsmjjvcRSZcd7ENinlbuDsf4m3AffY398D3H6+4isUinMk0IiZV4WmO0iYkj0NATZX5eJ2OVOfq7ggEPbcNlF6/s0RXglETilaqH/WORqOk7/F9eIPEeEA3gc/MrHCqwVbZziTpQ4mYNE6NrtbeaYhQDg2ewLz1P4j1It2nDVXpp8wewtg7Ttwn/oNRIbYsbyYfa3BtFpWk9E5FGbnyV7+aNNinPrc91Ce78Wpi4lZL5lysnuE6//1aTqUyYJCoVAozgdSTlS2AUQTJl3BKNVFU2abFSxBH540FyrKcnF5VjdtsmTCiXLicrbYNmsbqS1ItUa8LMrNvOqrvtSa19XQl3wRyyyoQQw2WvlLIoaIj1mVbcHovMQ9gOoiH+1DlomAnMuN1K5sw5NP74iVY5Rn2LYKliNpZ9w+L2UbqSWKmc4suoJRDDnpaJoO1gIhdATHK/fsc1NVto31AmDYlYyNAyGqi5JX1O1YUUoobvJC01lyhScfI28JovNwejc73kbqSb7YatTdiKP3KEagJb3rzYP2wRB/cu9+frZvYcy2FAvHKzPEZ5JSKeV4n0w3UDrbgUKIjwIfBSgtLWXXrl3n7aZGR0fP6/VfD6h3eO5caO9wc+tLhLyLOHLgAPu7DXpHYryzFp5++ulX+9Zm5UJ7h682RYMeVmkuDnTEiQ/sSvu8C/U91gcTlAx3sm/fvhmJqSfSy+YDf0kwp56WJX/E2qN3MfaTD3Gq/k+5JjpM+6hGe4bPVJsoojz6PPF4jI9/96ivjZsAACAASURBVEneuyp5a8nR557izUBAX0SbHSOdd5itXcqmxL10P/x1ynLehGFK/vPXu7myInNB+1enY0gJ1UYnu3albnstdMP+E83s8mRuzPD7xhhneuP8v1/s4fY6V9JjzgwZ1ORpaOfQMn2h/hwqFAqF4jwTGUIY0Qkn0rbBMJLpbpaioBq95Q+YhoGm6+itz7IqfIBvGW/lpuEo5VNMDqTX6sqQo73J49mVWgGZTXl+5mJbXbHVQtjQN8am6pkdIGZBDa7GJ5FGAmEbFpjuXLpHolxZk59xPLBMC3ae6MUwTbQJg4Qki2iRIaTTh3C46Rm2YpfOo420pjiboLRERTku4M3GuCjmypp0IvVnz3HCdFwOjbI8z6TY5krTjXTU6hAwfcVgSloGQly2pCxp7nZlnR+3Q2P3mUGuqp8+IscsqkcMNSOlTC2ERoeRmhP05HPw4nU34t5zF+bxh9Cv/Pjc15onrfZYkMb+1AYSileWV1psm0BKKYUQs9p8SCnvBu4G2LRpk9y+fft5u5ddu3ZxPq//ekC9w3PngnqHsRBydxdixS1s3ryZf7/3MBV5gk+8ddsFXdl2Qb3DCwG5DfOWj3CFN7M5cRfsexQvQOfDbLxkDbp7yuq2mcD3s7cjNA3XHT9kXflKzGJYtPMrFBRbpgiL115F3YbtmcUr7IVf/ppPrYnztaMOVtRW8X9vWjntkAcOtFMZ/jZRp5f1N78fp9ta9U3vHW5H9v6U2sBTlN7+d9x9bB+NsRy+sP2yjG4zYZh89rmdXL0sn3fcsiWtc1Y0vsDAWJTt26/OKBbA/R0HgS4ODzr5xrZtM362dp7s5R8f2cfX33EJb9u4OOPrj3PB/hwqFAqF4vwyYi0EGb4SBNBiO5HWFE8RbAqqEbERa1i/Nxf3k18k5KvgPwNvpqprZJrYhtNruUWGZhl6b7eRDsrsjJ1BASoKvLgdGk0Ds5skCDOOMdiChuVMGdJyiMTNjM0RxllSlEXMkHQHIyzOtu85nkRsC1tmDEIIukei6AJKc+dX2TaCFxM97co26cyiq88ycagsyuy9VhX66BiyDSAmDBJSiEl25aLMKqZzKELMkNSVJK+o87p0rqgtYnfDIJ81zenVb94CRN+x9G40Mox058yophxHFtZiFNTCyd/DeRLb2gatv3c1i/fC45WemN0jhCgDsL/OsrygUCheVdr3Icw48fJNHOsa4WDbMO/cUHZBC22KJAiB5it4ZQwZXgmyrXaSs5Nl1x++id65n8j1d+EpWwGAdvVfYS67Gfex+wEQhUszj2ebJLxvyQBvvaSU/9zVyH/tPAUNTxE5tZN//uFv+fL9z7PddRKjfDMOV+YrxWLLR9GDrWiNT3HdsiKeaRgklOHMjZ0n++genm6MkIolRT5aBkLpW9tP4aWOIXwuneaBEIfaZq5u3/NcMwC/ebEz42srFAqFQsGI1QhlZlmVbU322IPaqa6SBdUAiKEWXAe+ix44TfTavyeGi2PdM0UZ01uEGJtNbLPEoyDZVBRkLrbpmqCmOIvmQHKXbznhSHoa7Mq2gGmJQOXzqDIDJlpqWwPhFG6kQ5iePAB6RmL4s104UoybSEZ5vheXQyesZ6UttuHOpms4iq6JjAW+JYVZtAfH22TtmXSp2kjtyjbpK6ax33YiLZ19lu6OlaV0BKM09E2/rnTnIqLD6eVI0WGkK2dart0/GuNg7+QsuETdjTjan8dMVRE4T8Zn2zX1q1m8FxqvtNj2G+D99vfvBx58heMrFIp0aH4GKTSMii38aF8HXqfGuy+rfrXvSvF6J9uqUhNjk+s0evteXHv/jcjyt+De9J7JZEfT0N76HcxCy5FVm4/YVlSHdPpw9h/jy7cs4+bluZQ99X/gh2/B8+Pb+WzDe3jZ82EqjTZE9ZXzEzVXvhmZvQjv03/PjbVuogmTXScyM0r46QuWMcKOlSVpn1NV6GMkkmAoFM8o1lAoRlsgzAevrMbt0Pj1oY5p+5v7x9h1so/CLBfPnulncCzJsGiFQqFQKObCrmwjx/rcbxkI489ykuudMrrAdhx1tO/F9YdvEl16Pbkb3kJFtuBY90zRQfr8iNkq20KDxDQvMZzzmmcGUFeSQ1MgnFSgMQuniG224NKTsOLMR9wDWGLPQGsdDIOmW6ZmSd1IJyvbekeilGRnbsgAlqBYXeRjmGxEJJXYZr1/6cyiezhKSbYzY4GvqsjHwFicsUh8wgAiZRvpWC/S4UG4c2i0q7yWLZpdbLtuhZU3PX16+tw26c5Di40ijTQWPyMzxbYf7evg3w/H+M2LlmhsVF2FMBMYLXtTX28etNlidOdQmOhZhg+KV5fzJrYJIX4C/AFYLoRoF0J8GPhn4AYhxGngevvPCoXiQqP5GYyStQxJHw8f6+NNa4opyp1fMqBQLBh2ZZsYn7kSD+F55NOYOYsRb/w6uq5PP96Th/beXxK/5Vvo2UWZx9N0KF2No+9l9ESIf5P/wu36c3w9/nbuFF/myMa7iF7zBaJbPo628b3zeyaHC97+PfThNq546QvkeQSPHO1KfZ5N73CEnSd7efvG1MYIU6kuspL05gwdSY90WK5bV9T6uWFVKb99sZNYwpzY/8PnW3Dqgq+/4xISpuTRFE6uCoVCoVDMYKKyzfrcbwmEqSrwTBeJCiyxzff81wCJvPGf0HWd6jydE71jmKY57ZKW2DaQvFopHGBMzyXLpZPnSz6LNBX1Jdl0BaOMRWcuYklvEaYrBwbOTFSFdUctsW2+4l5ZrgeXQ6Nt0Kqmk05v0jZSGRrA9FhdDj3DUUpyks+fTYcafxYBmYXIYGZb17BlApGpwFdpO5K2jYuJDk8aM9t6MX1+NF2nsT9Ekc9JQVbyWWpgvfuVi3LY0zBdPJS22YGMBFPfaHTYalGeQoNdVfcPjzTQ0DeGUb4BKTRky3OprzcPxl1pTQltAWVedSFxPt1I75BSlkkpnVLKxVLK70kpB6SUO6SU9VLK66WUKXyDFQrFK048jOzYT6x8M7841EPckHzgiuqLpxVR8drFHpQ8Xtnm3n0XIthG9OZv4M6dRUwrqMa55QPzWsUFEGXrcfQdw/vzP8LR9ixD136Vgps+xxc//iesufVjuK/7v7hvuQt3QcW8rg8gqq9CvuEreFp28k8Fv2PX6f4ZVvSz8ctDHZgS3pHhbLQlE+0nmc33eKndSjzXlOfx1g0VDIbiPH3KmpESiiX4+f42bl5TxvblxVQX+XjopfSFQ4VCoVAoABjptqqL7MH4zYEwSwq903NRd44loBkxIlv+HHdpPQDVuRoDY3G6znLM/v/s3Xd03Od95/v3M71iAMygAwTA3qlCFavSlmU7slwiR7aSOOuss6tsinc3u876es/JzeZucu/ebU67TmLHiRPbKbbXbWPZsmyLslWoRjVKbBJIEL0MyvT6e+4fvxkAJNpgCkcCvq9zeCQCg/k9GEDC4DPfoj3NWJKrhW2zzOOjrYIgamerDw1cmF7h56pS5ty2mYGFNtKhtAurRdFaxvw0AItFsa3JzVBxrplt5bCNRHhhQcRENEObf/XwaT3bW3xM5bwLn8OqMjG01YGyORmPpGn3b3zj6rZC2DZc+Dpquxey6y9I0J4WlFJcmE7QF3St+/zvrn1tvDQSZW5JJb52mm236y6CwAzkrqxsG5hOsLNR4XFY+fffeI2kcmO07EcNPbPu/ZVjeDbBzlYz8Bvc4IuooraudhupEOLNbvhZ84lLx03848lRbukPsLdr+WYlIa46r7ktypKYxjr0FI4Xv0jqyMdw7XlH7a7ZcQSVjWOdPkPifZ+j4fYH+fjtO+kOBaoaQFtu+lWMI7/APbNf5ubMCZ56fWrdj9Fa89Xnhrihr+nyodElKL5ivNFhuqdG5ukNegh47Ny+q4Wg17HQSvrNF0aIpnJ87JZelFK893AHT74xzXQsvaFrCCGE2OKiYxjeVpRSzCezzCay9IdWGHTfsod80w5sd/zWws/kvoD56+2psehlN9WeECo5gzZWeDErMcOs4aW9wrANzI2kK9HN27HMDpgLHYDBuKOs9sqlekNehucW55qpK8M2w4DkDIa7mVg6RyKTp73MGXFgLkmY1V6M5Nza88wyMbTdS97QTETSdAQ2HvAthm3FJQmedSvbdGwSwx0CYCCcYHvQs+7X8x37WslrePyN8OL9FMI2Spmxlo5gLKlsy+YNhmeT7Gmy8JmPXMPAdJI/+N458l03YBt/ASNb3edEqWyeiUia23aan7fMbXtzkbBNCHG5wry2h+M7CMezfOzmbWVXBQlRVTYH2hPEOj+I6+FPkm/YhuWdv1vb789dd5PffhfJn/t7PNd+qHbXUgrLvZ8h33Etn7H/Gd979Phl7ZkrOXlpjoGpOPdf37Phy7nsVtobXBsO214enudQl/kk1G618L4jnTxyeoL5ZJa/fXKQg10NXLetCYB7D3diaPjeKWklFUIIsQHR8YWwbbDQFrdjhReV1P1fxPjlh7C7FoO4bX4LVovi9BVz27QniNJ5dGL5vDGdnGEy76U94Co7bOsLerFaFBdWaeMzmrZjiY6iI2Noh4+xWJ42/8bbK6+85tBcymyZtXuWz2xLzaG0gXY1MRExQ55KwrbtLT7mtA+Vml8nbIuD3ctMIkvO0GW1yjZ57PicNobnzHNrhxdVShupN8R0LEMsnWdH6/ovRB7pbqTZ6+Anry9puFtoIy0lbIuinYuLOy7NJMlr6PRauHNPK7/x9h18+5UpTmR3oXJJjNGX1r/PDRgtVP4d6grQ4LJteDyIqC35DVoIcbmLT5AL7eevX4jQ1+ziHfs76n0iIRb5WnGe/RaW+UHSP/M/cfprXHXpb8f6z76BZ99dtW+ltruwPvAVLA437xn9LP/8r58htsZm0q89N4THYeWew+X9N7ot6OHSTOlPymbiGUbmkgthG8AHr+0ikzP4T995lbMTUf7Z2xZbzve2+9nR4uW7L8tWUiGEEKXT0THynivCtjb/8hv6WrEH2i97k8Oq2N3m4/QVG0l1oeJJx1eoHE/MMJnz0t5Qfoulw2ZhW7ObC+FVwrbGfhQaNXoS7QyY7ZUN5VfSgbmRNJU1mIym0XbX8sq2hFmtZbiamYiaoVW5M+LAnNk2jxdHLorOrbEAKR3FcHgZj2TKvqZSim3NbkbmC2Gb3Ytaq400n4NEGMPTsrAcYddK3zNXsFoU121r5NzU4ob2kivbtC6EbYtLGIpf/w6fGbP823fu5sa+Jn7npUYAjMGn1j3TRhTntfU0e+gPeTf8IqqoLQnbhBCLsin08LP8MLmbc5MJPnFnH3a7vd6nEmKRrw2FJnnkl3Htuavep6m+QBeum3+FO6yv8MbA6zzwF08RXqENM5HJ8U8vj3HPoQ58TltZl+pt9nBxA0/KissRDnUvhm1HugNsD3n55gsjNHrsvP9I58L7lFLce7iTpy/MMBlJlXVGIYQQW4xhQHQCw2vOab0YTmJVsK15hTbSVRzuauS1icuXJGiPGbYRm7z8xoYBqTnm8NHZVH4QBeZG0oszqTU3kjL5GoYzwEQ0Q3tD+VVmAL2FZUeXZpJmZVvuiqCvGLa5m5iImsFXR2P5C8+avA4idnNphY6s8UJaJg52z0LAV+7G1W3NXkbmCo+nwwuZNZ6zJKZRaAx3iIFp83EoJWwD83EcmUsvfL+UPLMtEzMrBx2L17lQeF7V4TVjFpvVwqfv2cdgtpGoqwN1qcphW2H2bk+zm96gV9pI32QkbBNCLDCGnkHl03xtZju/fVc/P3tDf72PJMRlVNtB8k07at8+WkfqyANYMPjc4XOcn4xy32efWHgyVfS9V8aJpXN8+OjGW0iLeoMepqJpEpkSVtsDrwybTzoPLqlsU0rxwWvN5RAfuaEHl/3yjbD3Hu5Aa3joFVmUIIQQogTJGZSRRReWIl2cSdAZcOK84ufLWg52B5hL5hieXfzZqT3mIqVllW3peZQ2mNM+uiqo+gJzI+nQbGrFJUdGo/mcWhk50jY/OUPTUUFLJyxuFr80kyzMbEteHvTFpwHQ7uYlbaSVfY46YC5k0rODq98oE8OwexkvBHxlh21BD6PzafKGYX5+ufjq7auxCQAMT4iB6QReh5WOEj/XvqCHVM5YeIy0y3yeo9ZrI01FzGsumdk2MJ2gze/AbV98jnqku5E2v5NTlr1YR59DG2uPCdmI4dkkdqui1e+iL+RldC5JusQlW6L2NudvKkKIDdNa85NHvk1eKw4efTv/6h17Nm2YId7C3vX7qF9/qvbto/UU2oXuup790w/z+V84zGwiwz1/9FO++cLwwpPMrz0/RF/Qww19TWVfZvEV8dKq214Zmac/5KXBdXm16wM39nDPoXY+fuvycH5Xm589bX7ZSiqEEKI0UfPnRd5jVlANhpNsa3Zv6Dnp4cKLQq+OLi5JWKhsKwRQCxLmrK5Z7Ss7FCra2eojZ+iVW/mcfgyPuegpYTXDmUor6TobXdgsytxIanOjsonLw6hCZRueIBPRNE1u27IXxTbKETR/1uu5S6veRmfiaLuH8fk0HruFgLu8LpmeZg+ZvDar4x1eVCaxRthmhqiGJ8SFcIK+ZhdWa2mf67bi86FCSyZ2D1pZ0an5tT8wbYZtV1a29TVf/nW1WBR3H2jj+7HtWBJT5KffKOlcpRiaTdDV6MZqUfSHPBgahlaZGyiuPvlNWoitQGs48edw7geQzzE+n+KX//oZPvwXT/GJv3+B3/+n1/jU/3oZ5/CTjLt38pv33ljyDyghriqlsNjLn6nyVqGO/Dy28BmusV/i7//5tewIufmtf3yJX//KSV4cmuPEwAz3H+2paNZLb3BjG0lfWbIcYalWv4vP/uL1tK3SDnPv4Q6eG5xlbF6e/AkhhFhH1FyqY3hbMbRmcDZJX7N7Qz/v9nb4sVsVry2Z26bdTWjUQiizoNAqOIu/5Eqo1RQ3kg5Mr/xz1WgyW0mjmLfrrjDcs1kt9DR7uDSbKlR+rdxGala2ZWitYNtqUVOnGbalpy+ufqN0FG33Mh5J0+Z3lP07RW9hI6n5+XmXz6RbqlDZhq+NC9MJtoc8JQe0fYXnQwshlVJmddt6baSpYthmfj211lwIJ+kPLf8+eveBdk5kd5m3q2Ir6fBMYmHDfPFF1IvSSvqmIWGbEFvByEn4/qfg7+4n9z/28uM/eZDZCy+Sy2Z5YTDMl08M8u3nBrje9jpNe+/A4XDU+8RCbG0HP4S22LG/+nV6mtx8/ucP8Kn37OWHpye477NPYFFw33VdFV2itzD/5lIJYdt0LM3ofGrFsG09P3PIXODw6JkVhlILIYQQSxUq2/C3MxnNkMoabA+VPq8NwGmzsqfNz+mJJaGDxWYGble2kSbNyra8I4DHWdmc4uLG1IurbSQtzG2b1ebn01nB/LTFa3q5OJNE292oXHJZZZu2uVEOD5PRdMXbTwG6Qk1M6QDJ6bXbSLXDy1gkRXuDs+yAb1shRBqeNWfSqewabaRxcxZfytHMZCxDzwaqBjsLlWFDc4vzZbWzAVViZRuFBQkT0QyJTJ4doeVbUG/eHmTM2UfC4kVXcUnC8GyS7sLn2l8M22Qj6ZuGhG1CbAUDPwbgjZv+gMcTfdyf+ye+bflt/iH4eR76+B5OfPJtPPERJw6dwdJ/e50PK4TA0wy7343z3HfAyGG1KH7t2A6+85u3cbArwAeu6ar4FfiAx07AbWewhI2kKy1HKNWOFi8NLtvCfQghhBCrKlS2aW/rwhKf7a3Lw4v1HOoOcPrKJQnuICqxchupzdtUcdWX12mjPeBafSNpobItnPfgtCmavZW/uL2j1cel2RR5qwuySbObpSgRRrubUUoxEU3T6q/8er1BDyM6hJ4bXv1GmTjYvYzNpysK2zob3VgUjMyl0Q4vKp8GY5U5s7FJtN3LRNoMTDfSEmy3WuhqdDO8JGzDGYD0Os9bCmGcdpptpBfW2IJqt1p4+952njd2Yxl+tuSzrSWezhGOZxYqJBs9dhpcNgnb3kQkbBNiK3jjOLGmfXzomV38e+t/4PT9j5O75d9hP/ddvF96N46x5/FPPYdGYem/rd6nFUJgtpJaElOogccW3ravo4Hv/OZtfOYj11TlGr1BT0ltpK8Mz6MUHOhsWPe2V1JKcbArwCkJ24QQQqwnOobhbkbZXQwWKsR2tJS2VXKpQ12NRFL5y+aSas8KYVtyFgCXP1iVWcU7W3yrhm26ELZNZt20+Z1VGdmys8VHNq+Zy9pRaHR2ybUTYQx3M+mcwVwyR3uFCxnArIof0UEc8ZGVq8xyGVQ+Q9bqZiaRrWgJhMNmoSPgYmQ+jbabVVs6vUqQFJvA8LYwHjGXMmy0Rbc36GF4bnH7u3YFUIU20VUVZ7YVKtuK7cM7V9mC+p4D7TyV3YVt9jz52PSKt9mI4cKMuWIbqVKK/pC35PEgovYkbBNis0vH0ENP848zu3DbLXzpl6/l0P592N71u+h//n2U1Y77qz+H/YUvkm/Zj80XrPeJhRAAu96FdjdhP/2/anaJbc2lhW0vD5vLEfyu8lpsDnUFODseJZOr3gYuIYQQm1B0HMPbilKKizNJXHZLWRs0DxcqsU9dsSTBkpi+PCRKzmBoRUNTdZ7/7mz1cXEmST6/fCNkvvUA2mLnTLaVtirMTyteD2AyVfi1fulcs/g0hquR6XgWoOKKeDCr4qetrfjSE2hjha2XGXNOXsQwQ7ZKl05sa/YyMp8Ch3k/Oh1b+YaxSQx3iPFounDdjX2ufUEvQ3Opha+bdgZQ6fnV21ZhYWZbsY30QtjcgrraDNs797TwstoLgDF4YkPnW0lx2273ks+1N+jlgsxse9OQsE2IzW7wSZSR5cfZA3z2gcPs72lZ+OFu2XYjll97HOPQR7Akw2R7bpENpEK8WdgccOBDOAd+AOno+rcvQ2/Qw8hckmx+7RDs1Mj8wna3chzoCpDJG5ybqM3nIYQQYpOIjmF4zLBtMJykt8mFzbbxCrDdbcuXJBjNO7DMX0InZhfelolOE8FDW6Dy+Wlghl/JrMHYfGrZ+3RDN5FffZ5Hknsraq9cakchbJtImY+RziwGLToRxnA1Mx4xA6hqVLYBJD1d2HUWIzqx/J2FsG02by6z6mys7JrFijPDVvj6ZFcO23RsEsMTYmw+jWLj8/B6gx5i6TyzCbMyTrsasGQia4dt6ShaWcFuXuvCdIL+4OpbUD0OG/7tN5LFhh58ckPnW8lQoWqzZ0mg2RfyMjqXJJ1bIQgVV538Vi3EJqff+DFpHGTbj3K4N7T8Bk4/1vv+nPyv/AjbO/7j1T+gEGJV6pqfR+XTOF7/Xk3uv7fZS97QjM6tvil0MpJiPJLiUHdj2dcpLlZ4dVRaSYUQQqxOR8cxvG1m2DaTYFuTu6wXgh02C3vbGy5bkpDrfwdK5zHOP7LwtlRkmlnto7Ox8qovWFyS8MbUytVFhquJqXiW9lWqnzaqwWWn1e9kNF54jDJLKtsSM+Ym0kK1VzUWMgDQ2AOAnhta/r5C2BfOmJXw3U0bW25xpZ5mDzOJLEkKj9dqbaTxSbQnxFgkTchnx2nfWEBb3OQ5VGjN1E6zjVQba7wYmY6gHT5U4fvzQjhJf3DtLahvP9zHKaOP5EDlSxKGZ83Kz5BvcRZff8iDoZdsVhV1JWGbEJtc4swPeTq/h/uO9q05G8LacxS7r/kqnkwIsa6u69HNO3Ce/VZN7r63sO5+rVbS750yh1WXs4l04TrNHnxOWZIghBCb2us/gny2/I838ubsLV8bhtaMzqfpqqAy6lB3gLNLliQY7ddguJvRZ7+/cJtcLMw8vorbHYuKbZ2rzW2biqYxdOUVX1decyheeI5fbCPNpVGZKIa7icmoWa1Vrco2Z7DXvFT4wvJ3Fto8JzNmAFTJzDZY3Eg6WajcK1bOXSaXQSVnyXtCjM2n6GjY+NbV4vOhS8WQytmAMjKXz8C7UiqCdvpRShFN5ZiKZdbdnHvX3laeM/bgDb+CkalsttrQbILuJs9lFZLF0PCitJK+KUjYJsRmFhnDO3+e561HuPfannqfRgixUUqh7vs86uf+qiZ3X3xSNjiz/AmfYWj++8Nn+d3vvMqNfc1c01N+ZZvFojjQ2cCpkXWGDQshhHhrmngVvnwf+Ze/Vv59xKdR2sDwtDITz5IzdEUVZ/s7Goim8wuzrbBYyfUdw3rhUXTe3GqpEzPM6uqFbSGfg4DbxoVVKouKLZ1VqzLDrKYbLGZQxTbSRBgA7WpiIpLG67DS4K58GylAQ7u56CE6tkLYVgjDJlJ2mj023M7yZr0WFcO2sWShTXalmW3xKQAMTwtjkTQdZbToFq9TXJKgXYXnPKm51T8oHUE7zLCtuIl05zqbc4M+J1Mtb8OmsxhLQt9yDM0k6bliNl1/MWyTjaRvChK2CbGJzb9mlsk7d92J11WdH7BCiKus+3psjZ01uetWvxOnzcLgFa+ARlNZHvzS8/zpo6/zwA09fPlf3ITDVtlThoNdAU6PRcitMx9OCCHEW9DMAAD54RfKv4/oGACGt3Vh5llFYVthg/aZJXPb8tvfiSU1S37oWQBs6Vnm8Je1hGElSil2tvi4uEplWzFsq1a4B2bAM1No21xoIy2EbYY7yEQ0XbWFDAAd7e1EtJtUeHD5Owth20jSSru/8rl0CyFYfI3Ktpg5Oy7vDjIeSZdVTeeyW2lvcDI8Z37fFTeM6uQaFfkps40UWAjbdrWvv7W97dr3MKKDpE58YcPnXGp4NrGwibSo0WOnwWW7qmHbpXCCf/Wl5/kPX3/pql3zrULCNiE2sbGTDzGtGzh2251V+wErhNg8LBZlbiRdUtn2/OAM9332SR49O8nvvf8A/899hyoO2sBsQ03nDM5PrrJJTAghxFvX3CUA1ORr5d9H1BxbYPjaFrZKdlcQSu1t96MUnJ1cMret7F9dbAAAIABJREFU7060sqLPmrNQHdkIKVsDjjKWMKxmR6uPizOpFYfrL1a2VbeNNIG5kMC4orLNcDUxEcnQWsWwrTfoZUSHIDK8/J2FhU7DCRttZbRzXqkYHl0qzKRbugBiQWwSgDlLM9m8pqvMgLa3sJEUzAUJACRnV729Ts8vVLYNTCexWdRCx8Ba9nc189XcMbwjT2Cs1Ipbgvlklkgqd9lyBDDD3v6Ql4vTlbWoliKVzfNHPzzP3Z95jO+/Os63Xhwlb6yxUGILkrBNiE0qnzcITT7FWfe17OleYTGCEEJgzim5OB3noVfG+NnPPsGH/uwpwvEMX/r4jXzslr6qPTk/WJj5dkrmtgkhxOZTGJZvnT699gbHtRQq27SvnbH5QijVVH7Fmcdhoz/o5dzkkuDBFSDfeRR1/geQz+I24hiuxopDoaV2tvqYSWSZjaeXvW+80NIZ8Dirdr0dLT6ShbBtYWZbfNr8p6eZyWi6qmFbe4OLMVpwxseWf62nzqItdk7FfHQ0VP45KmUGWBdixcq2FcK2uBm2jeXNgKyrzO8Zc0N7Gq012lmYU5tau7LNcPgBs7Ktp9GJ025b9zr9IS9fzR9DozCe/2JZZy1uIu1e4XPtDXprXtn2wqVZ3vWZn/CZH57j7v1tfPJdu8nkDAalffUyErYJsUk9+8zjhJjDtevtay5GEEJsbduavZyfjPHrXzlJOJbh995/gMc/9XZu2VndkL4/5MXjsErYJoQQm1Ghss2SDGNExsu7j+g4GgXeFsYjaVx2C02eysag7O9s4NxU4rJQKL/9LmzTp8mPvWy+wd1U1Q6Q4tyulTaSjkfStDdUL/gCaGtwohyFCqeFyrYZ86/OJqZimaptPwWwWhTzznYa0uPLw7aR58kE9zKXtVVtw2tv0MMbxacOa7SRDmXM4Ku7ubwNqL1BL9PxLLFUdiFs08l1ZrY5zWsOTCfoD3pK+rq2+p3M2ls457sBy0t/hy5jqchwYWvqlW2kAH0hL6NzSdK5PACxdI6//OlAVZcm/LeHz5LM5vnyr9zEn/7Cddy+qwWAcxPRql1jM5CwTYhN6uIz3wVgx0331PkkQog3s/cebufu/W38+Uev49FPHuNjt/Thcaz/yuxGWYtLEkZlSYIQQmw6c5cWqnyM8VfKu4/oGNoTQlntjEfMOWOVvmC8v7OB0fk0c4nMwttyO94JgH7h7wGwe5srusaVdrYsBjBXKn5e1QzblFK0BwufQ3F7ZiKMRhHOe9FUvhX0ShlvFx4dx0gsCaMMAz36IrOB/UD1WmX7gl6GIgbaYof0Sm2kU2hnA6OFh3ulaq9SLG4kTYCrGLat0kaqdWFmm59s3mB4Nkl/qLSwzVJoN33I8W4s8Unypx/a8FmLSz+ubCMF6A95MLS5QOHhV8e5+38+xu9/9zRfPrHCjL0yXZyOc/vOELftMl+Y3dVmBsznJmRUyFIStgmxCY3NJ2kPP8W0cxv+jp31Po4Q4k3s+t5mPv/PjvKegx1YLbWd7XigM8BroxGZ6SFQSjUqpb6ulDqjlDqtlHpbvc8khCifnhsk23un+ZfxU+XdSXQcw9eGUsqsAKvCgP39HWZr4dnxxYobo3kX+YZu1KvfAMDpD1Z0jSt1Nblx2CxcXGEjqVnZ5qr6LOXutsLnsFDZNo12BZhKmD9vO6pUZVakGnsAyM8smTkWPo/KRBlx7wOqtwSiN+ghryFvc0N2pbBtAsMTYmw+g89ZfotuX2He2tBsamFBwqptpNkESufRTj9Dsyny2mznLf1aHr6bPIThbYMyWkmHZhL4nTYa3MtfHC3Ojfu1Lz/Pr37peQJuO00eO9Ox5W3N5Uhl84xFUmwLLn59PQ4bPc1uzkpl22UkbBNiE/rxqSFuUqcx+m6XFlIhxJvGoa4AyWyegSl55VPwR8D3tdZ7gSPA6TqfRwhRruQcKh0h13IQw9uKnni1vPuJjmF4WrBYLIzNp6rSbrmwkXTJkgSUIt9/F9aUuUTA11jdsQlWi2J7yMuFcOqyt2dyBjOJLO1VmGV2pR1tAdLaTjpRCDsSYbS7mcmYWdHXUaVtq0Wuln4AYhNLwraR5wE4b98NVLZJdqm+kBkeZSzulWe2xSYxPC2MRysLaIvh0dBsEqx2tN0DqVXaSFNmlb52+BcqGHe1+Uu+Vl/Iy6VIjtT+D2O98CjG7MaqzoZnk3Q3r1xJtz3kRSnzNv/xnr3870/cRm/QSzieWeGeNm54NoHWi5WARXva/JyXsO0yErYJsQmde/lp3CqDd9cd9T6KEEIsKC5JeEXmtm1pSqkAcAfwBQCtdUZrvcZgHCHEm9q8uRwh39CNEdqHZaqM7FxrdGQEw9NKJmcwHc/SWYWAqNXvIuRzcG7i8pCm2EoK0BRsr/g6V9rZ6uPiTPKymWaDhUq3SpY+rGZHi7mRNBZbDNsMVzMT0ULYVuXKtkD7dgDmxt5YfOPI82iHj7P5DmwWRVtDlWa2FeaSpZQbtULYpuOTGO4QY/NpOgLlB7QNLjvNHjtDc2YFmHY2rF7ZVti6ajh8XAibYdvOjYRtQS/ZvGZ42wfM+3nubzd01qHZBD2rfB81ehx85Vdu4pF/dwcP3rEDu9VCyOdkKlqdyrbBwud75ebVXW1+BqbiZHJGVa6zGVR/KIsQoq5i6RypkVNgA3vn4XofRwghFuxo8eKyWzg1EuG+6+p9GlFH/cAU8NdKqSPA88C/0Vpf9luUUupB4EGAtrY2jh8/XrMDxWKxmt7/ViCPYeXeqo9hcPppDgFnxhO05RvpmX6Cx378I7Sl9O6KwNyrXJsI80Y2xCtPPAtAanaM48fDGzrLSo9huyvPi5fCPPvsswtvsxgOblFOHDrN8Og4kejlH1MpWyLD6HyWJ048g9Nm1rd86bUMNgWe+UGOHx+u6vVmYgZJHExOjnPu+HGOTg6SdLXxyvlL2C3w6slneK3EEKqU78ORSI60tjM18ApDhdted+Y4OXcfpy9N0ujQPPnkExV+ViatNQ4rzGetGOExTl1xttvmRplw7GZ4Jk6Xw8pjjz1W9rUa7XnODE/x7LNRbjQcJMYHeW2Fx8IfOcv1wMDINCfHhgg44KXnnl54/3qP4VzYXF7w8OlZgk1H8D771zxhvaWk/2a01gxOJ+hzpda8xuvD8Hrh37PRNKMz+ar8/+WHF82FDsNnXiQysPg9lZ/JkTM0X/vecbr8ldd0vVX/f7iUhG1CbDI/PTdFHyMYFjuW0PZ6H0cIIRbYrBb2dzTIRlJhA64DPqG1flop9UfA/wH8ztIbaa0/B3wO4OjRo/rYsWM1O9Dx48ep5f1vBfIYVu4t+xieOA2nYNcNd+EadmAZ/ja37mvD1nGw9Pv45j+gHX463vnrTExpePxlbrvuAMcOdG3oKCs9hieSZ/jC4wMcvuZanPbFX3/feOl6dkSe5u673onbU93Kr2jTKN96/QWatu3hQFcj4XiGJ3/8DPceauWD774ei6W6DWbZvMGlZ13YrXDs2DH0c2lsbf2oVBNtDRHuvPPOkq9ZyvdhKptn5LkgjSrG3mPHIJtC/2SQ5DUfJzPkZVtIc+edt1dtNt32l35CMuGl22W9/GyZOBxP4O/eS+ICHNnVw7FjB8q+zrfGX+DpgTBHjx7F9UYbTmVZ+bF4PQ8noX/vYdLTPnpDee68846Fz3e9x3DvfIr/99kfYW/uwtP3cVwP/Wtu3d2Mrfvadc8YjqVJP/xD3nZ4N8du7S/p83oufZafjrzO7XfcWfF83ke/fQqfc4T33X3ssq9vy+g8n3v5cRq27eXYkc6KrgFv4f8fLiFtpEJsMo+cnmCfbZR8Yz8WW2Xr0oUQotoOdgV4dXQeQ5YkbGXDwLDWulgG8HXM8E0I8VY0N4S2ucHdjBEyN1HqjSxJSM6hX/0W6d3vw+ZuYDxitrtVa8D+/s4GsnnN65OL80KzeYP/HP8gX278NRzO6j9f3tlqDssvzvP6yrMjZHIGD96xvepBG4DdaiFvdZNNJcxNmYkwOWcjp8djtDdUvmjiSi67lSlrK67kmPmGiVMoI0u+7UhhCUR1r9kb9DCbd6Cyictac4mMAhC2tgDQXeH3zLagl4lomlQmB85GVGr+8usVpRdnto3MpegKbGzpRavfictuMZcx+M1A2YhNlvSxY/PmLMCNzOEL+RwYmsu28pZrcCZBb3D5vLgdLT4sCpnbtoSEbUJsInlD8+iZSfbbxjCad9bkh7kQQlTiYFeAeCbPhfAKQ47FlqC1HgeGlFJ7Cm+6C3itjkcSQlRibhCjoRuL1YrRvANtsW0sbHvla6hckuT+Dy9sIgWqMrMNFjeSnplYDNt+fC7Mk4lu2o49WJNlYv0hLxYFF8JJ4ukc//D8GMd2NbG3s6nq1ypSDg86k0CnIygjyzNTVi7OJPnoDV1VD9sAoq4OAulxM4waOQlAuvUwk9EMHQFXVa/VF/Qyk3Us30YaGQFgzGgGKg9o+4IeDG0uF9CuBlQhVFumsCAha/czHknTvcE5fBaLojfo5dJcCu02z068tJbpqcJW0dYNLNoI+c3bTseqELaFE8uWI4AZwPYFvbKRdAn5TVyITeTkpVkSiTih3Dg6tLvexxFCiGUOdppLEv76iQvE0rk6n0bU0SeAryilXgauAf7vOp9HCFGuuUvk/YVAx+bEaNqBmtxAfn7yb8m3HkR1mi10Y/NpAm4bXpe9KsfrD5nzQs9NJhbe9rWTY3Q0OHjngcrb3VbislvpbvJwIZzk6y+ME03lePD2/pq+EG5zerHkEqTnJgB46KLmXXuDvO+63ppcL+vrpknPkU/HYeR5DG8rYUsLOUPTWeWwrTfoJWo40Zn45ZVm82bYNpQ3Q8yNhl7Lr1PYSDqXRDsDqPTalW0TGSeGLu+6fUEPQ7MpDFcjADpRYthWWHTQ4is9bAt6i2FbZUsS8oZmeDaxbDlC0e42P+cnZON8kYRtQmwiP3xtgp3WcSwY0LJn/Q8QQoirbE+7nw9e08mXT1zijv/6KH/50wFS2Xy9jyWuMq31i1rro1rrw1rrD2qtZ+t9JiFEefT8EEZD90L1lNGyD8v06ZVDiiuNvgjjL5Pcd/9Chdl4JE27v/ytkleyWhR72/2cmzLDtgvhBE9fnOND17TjdFQn0FvJzlYf56cT/O0zwxztaeDGHa01uxaAw+PDRYbhEXM7bNoW4Pfet78mlXsA1qYeAJJTF9Ejz5NrPcxkwnwRrbNKLcBFvUEPCVyozMptpAOZQFU2oBZDpKHZFNrZgMrE0MYKz1FSETSK4YQ5A3DbCpVe6+kLeRmZT5O1m5WXKjFT0scthG3+0sO2Fr/ZKl1p2DY6lySb1wsbYq+0u83HxXBcntcV1CVsU0r9llLqVaXUKaXU3yulqht9C7FFPXJ6gneFzP9Rq5a9dT6NEEIsZ7Uo/vCBa/nWb9zKgc4Gfv+7pzn2347z0Ctj9T6aEEKIjUpFUMlZ8v7FCjGjZR/W6ChGooQM/eTfoG0uMns+sPCmsUiK9gZnVavA9ncGODcZxzAMvnZyDKtF8cCN26p2/yvZ2epjcCbFZDTDv7h1W81CryKPtwEPaf7hsZcA+MBNe2lv9tfuei19AMy88TwqfJ5s22GGZs15YtWat1fUG/QQx4U1nwRtLL4jMoLhDjIcU7T5HdhslT3GQa8Dr8PK8Fwa7WpEodHJFZY6pSPg8DEaNTdzbgv6NnytvqCXbF4zFs1iOBsgWXrY5nfZcNlL/1xDvuq0kV6aMQPr1cLF3e1+DA1vTEl1G9QhbFNKdQH/GjiqtT4IWIEHrvY5hNhsBqZiDEzFucU/hVYWLC3SRiqEePO6pqeRL/3KTfzdv7yJzkYXpRRACCGEeJOZN6uojIaehTflW/YBJSxJyMTRr3yd9M57sPmCC2+eKAzYr6b9HQ1EUnkGpuJ8++UJ3rGric4aBlEAO1vMAGZ3i4e7atSuupTP34BbpZkLjwNw2zX7ajKrraixcwcAtnMPAZAIHuLPfzpId6OTna3VfWw7Am7SymWGX5nFdmAiIxi+9qotZVBK0Rv0MDRnVrYB6NTc8humIminn7H5DFYFXY3ltJGaVXSD4aQ5t63UsC2W3lBVG0DAbcdmURVXtl0szNvtW6ONFOCczG0D6tdGagPcSikb4AFG63QOITaNH502N9jsto5iNGzD4qjuCnMhhKiFW3aE+F+/dgv3HGqv91GEEEJs1NwlAPKFjYoARsjsrjDGX1n7Y1/7NiodIVVYjAAQS+eIpvNVH7C/v9MMTv7ksUEiqRw/f2NPzReJHewyZ5Q+eNs27PbatasW2V0+PCpDh90MRKz+2ratdnRvJ68VLRM/AeAvL4S4NJvi9967B4+ruhterRaFw2N+DcksLknQhbBtNJKmM1CdDah9IS/Ds4thG8kVKjTTkYVNpG1+J/YyKur6Q2ZgdWk2iXY1baiNdCPz2sAMEYM+B9PRysK2S+EEDpuF9oaV//vsC3qxWxXnZG4bYIZeV5XWekQp9d+BS0AS+IHW+gdX3k4p9SDwIEBbWxvHjx+v2ZlisVhN738rkMewcpU+hl9/OkmPT2Gdeo0ZVzuv/vSn1TvcW4R8H1aHPI6Vk8ewcvIYCiHEW8CcWdmmA4uVbdrXgeEMwMSri7eLjsN3PoFORVCeIHiaYPAp8k070N03LdxsYRNpGZVCa9nb7kcp+PH5GXqbXdy+u62q97+S/Z0NPPGpY3RUaavquuwe3KT50C4r+g0Hylnbyr3mBi/jNNORD5P09/H5F6L87OFW3n6ga/0PLoPPF4A06MySICcySrblGqaquAG1N+jlB69OkLUXHr/UChtJ0xEMh5+R+RQdgfJanlv9Tlx2i9l662lGRc3NrusFhtPR9EJ4vBEhn5NwvLI20sFwgp4mNxbLymd02Cz0h7ycG5fKNqhD2KaUagI+APQDc8DXlFIf1Vp/eenttNafAz4HcPToUX3s2LGanen48ePU8v63AnkMK1fJYzgbz3D+4Uf4+E1teF8ex7b/3i359ZDvw+qQx7Fy8hhWTh5DIYR4C5gbRNtc4Aktvk0pjJZ9qMnT5t+j4/DFe9GREXJtR1DhN7AMz6LS8yRu/x1sS6q+xubNsK27yjO/PA4b/UEvA9Nx7r+m/apUmgF0Na3cblcTdjcKTaeaxXA3o2pcuaeUYsbWSkc+zBPJXpo9dj79M3trVjHoDzRCGIxkIcjJJFDJWSK2FjTltXKupC/oIWdoJjNOAoBeYfagTkXQjgAjkylu2d5YVkWdxaLoDXq5NJdCB5qwTJ0u6eOmohtvIwUzbKtGG+lqLaRFu9v8vDS8QuvtFnTVwzbgncAFrfUUgFLqG8AtwJfX/CghxKqeGghjaHhnSxRlZGUTqRBCiKpSSnmBpNbaUErtBvYC39NaZ+t8NCFEPc1dwvB3Ybli+L/Rsg/bqa9izI9g+dIH0ZER5u79K6z9twKgtV6o4lkazdSqsg3gYFcDI3NJPnxjX9Xv+03BYYYglugI2t2EpYbz2ori7k6InebxZC+/87O7aGnc+KKAUjU1NgIwOzdDey8Lm0inLWbQW62lDAuz1BJ2drHKzLZ0hJyni+l4lu4Kvlf7gh7Ojs1jtDViS82tW9mWzOSJpnNlh23nK5ilprXm0kyCt+0Irnm73W1+/unlMeLpHF5nPeKmN496zGy7BNyslPIo8zvpLqC0GFcIsaITA2Hcdgt7beY2P9Uqm0iFEEJU1U8AV2HR1Q+AXwK+WNcTCSHqb+4S+YbuZQGBEdqHJRtH/eU70fPDzN/7Baz9t6KUMgM2iwWr1bqsCmosksKioL0GrZe//e69fPFj19MSqG7V3JuG3fy8LJERDFdTTZcjFOX83QA4uq/l3mu31fSawWYz5JkKF2abRUYAGDGaAOhprs7XtThL7WKsMHcuufKChJgyb7etguv2hbyMzKfJO5tQ2QQ6m1zz9sXKtI3ObAMI+RxMxzPoMjdSTccyJDJ5etf5fItLEl6flLltVz1s01o/DXwdOAm8UjjD5672OYTYTE4MhLmm248rcgEAi1S2CSGEqC6ltU4A9wGf1VrfDxyo85mEEHWm54fI+7uWhSzFjaSk5pi/9wtY+m8rKYiZiKRp8TnKGji/np5mD2/b1XpVQqi6sJsBpYpPoD3Bq/J5uve/ixesh/j5970Hq7X6X7Ol2kJm2DYzV2jrLIRtgzkzbKtWNWSL34nHYWUgakErC6Tml98oHWHeMK+3bZ22yrX0Bb1k85o5zPvQ8fCat58sLDgot7ItkzOIpnMbPygwWNhE2htar43UrG48KxtJ69JGitb6d4Hfrce1hdhspmNpzk3E+M3be7DOvE7e14HFHaj3sYQQQmwuSin1NuAXgV8pvK22v1kJId7c0jFUIozhXz4Q32g9QHrfh0jsvX+hoq0UY5E0bX5HzTeFbkqFNlKFRrubr8olr739Xoxb77kqX6/WoBm2RSOF8KsQtr2RCtDsieNxVmcOn1KK3qCHS3NpcyPplW2k2RQqnyGcMwOvSirqii2r4xkvnYBOhKF526q3n6okbPOblXrT0TQNro0/VoPhBMC6lW29QS8Om6WiltXNQv4vJsRb3DMXzFLqo9sasITPk2/eJU9QhBBCVNu/BT4NfFNr/apSajvwaJ3PJISop3lzE6nR0L38fVYHmXv+CNv20iraisYjadobnJu3+qyW7EtCEM/ac7Wq6Wr93uFwm+2J0WhhO2hkFMPdzFBcVf17pi/oZWg2hXYGlle2pc3rT2VdOKyKtobyK+qKLavD6cJ9JGbWvP1UrPywLeg1P2Y6Vt5G0sGZBBa1/vISq0Wxs8XH2QlpI5XfyIV4i3u6MK9tX5sHy8zrGM075QmKEEKIqtJaP6a1fj/wJ4W/D2it/3WdjyWEqKe5SwDkr6hsyxuaLz0zzO3/80keOT1Z8t0ZWjMeSdMRcFX1mFvGkrBNXcWw7aopVO6lEoWKqfkRDF87Y/NpOhqcVQ39irPUDGcDqhCuLUiZfx9LO+kIOLFV0PLc6nfislu4kDTDNp1Yu410OprGohaDs40IFea8hcvcSDoYjtPZ6MZhW/9x3t3m43WpbJOwTYi3uhMDM1zT7ceTnkLlkrKJVAghRNUppd6mlHoNOFP4+xGl1GfrfCwhRD0VwjYdWGx7OzsR46NffJH/+sgAiUyeP31sEKPEgewz8SzZvJawrVyOJRVH3lD9zlErdjcGimwyimEY6MgIUXsLo/MpOqv8PdMX9JAzNCmrH3VlG2narHQbSTnoClRWUWexKHqDXs7HC+HZOjPbpmJpmr0OrJaNX3OhjbTssC1Bb7C0ltltzR7GIimyeaOsa20WErYJ8RYWjqU5OxHlum4/1tnXAdlEKoQQoib+EHg3EAbQWr8E3FHXEwkh6mvuEtrqBG+IvKH54+MXeOCvXmBkLsl/+cAe/st9hxgIJ/nRmamS7m48YoYAXU3V30S6JWz2yjalyFk9WHNJZuNpcnMjPDzioMFl44Ebeqp6qeIstSgeVDp6+QbPQmXbpYSNrkZXxR1FfUEPZ+bNGWrrVbZNRdMLFWob1exxoBRMldlGemkmwbbm0pZBdDS60RomIqmyrrVZbDhsU0pZlFINtTiMEGJjFua19QSwhM8DYGndV88jCSGE2KS01kNXvClfl4MIId4c5i5hNHRhsdr44olhPv/EEO/ZF+ShT9zCR27ewfuv6aK7yc1fPTV0eVixioWwrbH8gfNb2tKwzbcJK9sAw+7BQ4q/+NGr2NOzxByt/OO/vIH9PdUNF4uz1OYMD5b0/OXfv2mzPXIi7Vx3flkp+kJeBiMGht23/sy2aLqseW0ANquFJo+jrDbSSCrLTDxDX4mVbcXq1LF5CdvWpZT6O6VUg1LKC5wCXlNK/XZtjyaEWM+Jwry2/R0+LOHzGO4glk36w1UIIURdDSmlbgG0UsqulPokcLrehxJC1NHcJQx/F6cn4vzpYxe5a3czf/jz19PR7Ecphc1q4Vfv3MGpsThPX5hd9+7GClUwXVUIMLakpW2kns35+4By+vCqFD94+kUAfva2a9nR3lT1edUtficeh5WpnBuVjlwRtpmVbRE89FShCrMv6CWb1+Scjahk7cI2gJDPUVYb6aXiJtISw7bORvNxGZ1Lbvham0mplW37tdYR4IPA94B+4JdqdiohRElODMxwpMuP2+nAGj5PrnmnbCIVQghRC/8K+A2gCxgBrin8XQixRen5IdLeTj797TM0eWz8wQcPYrPZLrvN/dd3E/I5+MJTVxbGLjceSeO0KZq9jlodeXNbWtnm3YRtpIDd5afJluEDvTkAfG19NbmOUoreoIfxjAuVT6OzS0KjQhtpVHvYFvRVfK1iy2rC2gBrhG1aa6ZilYZtzrK2kQ4WwraS20ilsg0oPWyzK6XsmGHbd7TWWaC0SZdCiJqYiWc4OxHl+h4/CrDMnMdo3iWbSIUQQlSd1npaa/2LWus2rXWr1vqjWuu1h8sIITavTAIVn+KnU14uhJP8wfv30ta0PHhw2a18/NZ+Tlyc59TI/Jp3OTafps3vxGotf7vjlmaxoq1ODIcPZSs/kHkzU04vN3XYePCwOeNMNXbX7Fp9QS8jqcLjmFryvVuobIvhZluJlV5r2d5iBlgR1YBKrl4BGknlyOQMWsqc2QYQ9DnLqmy7GI4DpVe2+V12/E4bY1LZVpK/AC4CXuAnSqleILLmRwghauqZC+bvOEd7Aqj4pLmWWjaRCiGEqCKl1H8o/PNPlFJ/fOWfep9PCFEn82al2vdG3fzi0Q7eebB71Rd8P/q2XnxOK194cu3qtolImna/Q144roTDg3YHN+1jqBw+VC6BNT5u/r2hs2bX6gt5GUyawZZOLtlImoqQtrhwOew0eSqvwmwttKyGtQ9LanbV+YZTUTMkq7SNNFxGZdulcIKQz4nXaVv/xgUdjS5GpbKDrK/QAAAgAElEQVRtfVrrP9Zad2mt79GmQeDtNT6bEGINJwZmFua12QYeAUB1XlvnUwkhhNhkinPZngOeX+GPEGILSlx8FoBUYAefvmf/mmNMGlx2funmXn50boaBqfiqtxudT9EecG7aoOiqsHvQ7ubN+xg6vFiyCSyxMQxXExZn5W2cq+kLepgzCpVcS8O2iVeYVUE6A9WpwlxoWc15UTUP25zE0jlS2Y3tN7oYjpdc1VbUEXAzNi+VbetSSrUppb6glPpe4e/7gY/V9GRCiDWdGAhzpMuPy6ZwPPNnZFsPY+29ud7HEkIIsYlorf934V8TWuu/WfoHSNTzbEKI+pk/9QOmdQP3v+cd+DyudW//8du2Y7MovnZydMX3D0wnmI5n2d/ur/ZRtxaHb5OHbT5UNoGKjGL42mv6efYFvczrwoyyYtg2/Tpc+AkPWe6kM+Cq2qzs7SEfI2k3lkwMnVu58myq0P7ZWkHYVmxBLQZ3pXp9MsbOlo0Fm52NLsbmpLKtFF8EHgaKdZrngH9biwMJIdY3E89wZjzKdd1+HOf+N5b5QXJv+zfY7PZ6H00IIcTm9OkS3yaE2Oy0pmHsCZ40DnBtX2tJH9Lid3LbrhCPnA1jGMay9//g9BQAP3Oodm2BW8K7/jP52/59vU9ROw4vZONYYuM1D9v6Q14imNVcOlUI2577K7TFxl8l76C7cf2QuVR9IQ+DSXODp06sPA51obLNV/51gz6z7TUcL72VdDqWJhzPsHuDQXhHwE04ntlwFd1mUmrYFtJafxUwALTWOWDrPmpC1Nnxs5MA3LjNj+OZ/49c827sB99f51MJIYTYbJRSP6OU+hOg64p5bV8EcnU+nhCiHqbO4s1M86LtCE0b+MX/fUc6mYhmeGFo+aKER85Mc6TLR09IKtsqoXa/G9eOW+t9jNpxeM3Ktugo2t9Z07Ctxe8kaze/H3ViFjIJ9ItfIdZ7N8O5BnqaK1+OUNQX9DKji9daeSPpVDSNw2qhwV363LQrhQqVbdMbqGw7NxEFYHfbRivbzPBwfAvPbSs1bIsrpYIUNpAqpW4G1l4nI4SomW+cHKGr0cX1qRNYw+fI3PQJbHZZky6EEKLqRjHntaW4fFbbd4B31/FcQoh6GTgOwGjTjRtqo7t7fxsOm4WHX5u67O0XwwnOTcZ5976WqrXliU3K4UUZOXORQA2XI4A5S62pucX8S3oeXv0GKjXH6z0/B0BPU/XCtu0tXmYphFnx6RVvMxVN0+KvbKZhqNCCupGNpOcnYgDsbttYEN4ZMIP40S08t63UWPTfYT6p2qGUegJoAX6uZqcSQqxqbD7JE29M8y9u6sTz3O+SD2zDfs399T6WEEKITUhr/RLwklLqK4XOBiHEFqcHHuWSbsff2ruhX/z9LjvHdrfww3NhPvVuA2shWPvhGTNckBZSsS7HYnWVauiq+eW6Qo2k5hyo5Bw8+0Pyzbs44zgMnGdb0Fu16/QFvcyuV9kWSy+EZeUKes3ijI2EbWcnogTc9g3PiusoVLZt5bltpW4jPQncCdwC/CpwQGv9ci0PJoRY2TdfGEFreKD5DNbJV0jf8BvYne56H0sIIcQmpJT6auFfX1BKvXzln7oeTghx9eWz6IuP89P8AXa0bnwT5HsPdzAVy/L84OJ2xx+cmeZQh49t0kIq1uNYEnAFumt+ub6QlzntxTr4Uxg9SfLgLzAeywJUtY202esg52wEQK9V2earLGxz2a34nTamY6XPbDs/EWV3m2/DFXUdhcq2rbyRtNRtpPcDbq31q8AHgX9USl1X05MJIZbRWvONkyNc0+Wn98wXyPvasR/9pXofSwghxOb1bwr/vBd43wp/hBBbycjzWDIxHjcOsWuDbWUA79zXhstu4fuFVtKh2SSnx2PcvS+E1Wqt9mnFZrMkbFNXI2wLeohoD7bp02i7m/iuD/Lo+TAhrx2/u3ojfJRSBIJt5l+Sq89sa6mwsg3MVtJSK9u01pybiJX137rLbqXZ62BEKtvW9Tta66hS6jbgLuALwJ/V7lhCiJW8PDzP65MxPrZtEtvos6SvexCbs3qvqgghhBBLaa3HCv8cXOlPvc8nhLjKBo6jUTxp7C/rF3Cv08bb97Ty43Mz5PIGjxRaSO+RFlJRiqVtpIHaf8/0Bb3MYwZ86d0f5H88NcfLI1E+edf2qs8X7GppJokT4su3keYNzUy8SmGbz1Fy2DYZTTOfzLKnjP/Wwaxuk8q29RU3j74X+LzW+ruATGMX4ir7xslhHFYLx2yvAmC77hdquoVHCCHE1qaUiiqlIiv8iSqlIvU+nxDiKhs4zrBrN3lHAx2B8saY3Hu4k3AiyzMXZ3nk9DT72730tzZU+aBiUypUthnORizOjbcxb1R/yEtEm9f8ruM9fPXkGB+7sZMP37y96r+D9YfMjaT5FcK2cDyNoalK2Bb0OgmX2EZa3ES6a4ObSIs6Am6Z2VaCEaXUXwAfAR5SSjk38LFCiCrI5Ay+89Iox3Y14Zt6gVzTTqz+1nofSwghxCamtfZrrRtW+OPXWstvx0JsJekoevhZnrMcobfZXXbb5zv2tuJxWPmbE8OcGoty915pIRUlKoZtvvarUnDQ4nfyjDrEY447+dTTDm7pC/Af7z1Yk625/SEvs9pHJrp8ZttU1KxEq3RmG0DIX3pl27kyN5EWdTa6tvQ20lK/Sz4MPAy8W2s9BzQDv12zUwkhlnn07CSziSz37GvCNvocua4b5ImJEEKIq0op1aqU2lb8U+/zCCGuosEnUUaOR1J72R70lB04uB1W7trbypMX5wF472FpIRUlKrSRXq2wTSnFT4L387HIr9IZcPCZjxzB6bDX5Fp9wWJl2+yy9y2EbVVpI3Uym8iSzRvr3vbceJSg10GozJCvI+AmmsoRS2/NZealbiNNaK2/AcwXnljZgTM1PZkQ4jLfODlM0GvnjsAUKhNF99xc7yMJIYTYIpRS71dKnQcuAI8BF4Hv1fVQQoira+A42urkR4ntbG+pbGbwvUfMgG1Pq4cdbYFqnE5sBYXKNt3QddVG6exu8+N1WPnTjxymral2G3P7Ql7m8GFJz6K1vux9xe2hrdVoIy0EZzPx9VtJz01Gy24hBbOyDWBsbmtWt5W6jfTKJ1gXkCdYQlw1s/EMPz4zyXv2BnFPnATA0n9bnU8lhBBiC/nPwM3AOa11P+bCrBP1PZIQ4qoaOM5c6DrSONjZUtm8rDt3t9AZcHHfNe3SqSFK5/SjUdDYc9Uu+X/eu5/v/MbbONTbUtPrBNx2ErZGHJn5ZWFbsbKt3AqzpVp85uj99VpJtdacn4iV3UIKLMx1HJ3fmnPbbCXervgE64da62uVUm8HPlq7YwkhlvrLxwfI5jXvO9iC7YVnyPvasTX31ftYQgghto6s1jqslLIopSxa60eVUn9Y70MJIa6S6ARMvsYb238DgF3tlY1sdNmtPPnpuzCM9VvZhFjg9KF/4auotmuu2iWDPudCNVitKU8z7ngMnc+CZfGaU9E0PqcNt6PyYLoY2E2vsyRhdD5FLJ2rMGyTyrZSZLXWYWDhCRZwtIbnEkIUXJiO8/mfXOC9B0Ls62jAOvI0uc4bsMirgEIIIa6eOaWUD/gJ8BWl1B8B8TqfSQhxtYy+AMBLln3YLIq+UHU2QdZi0LzY3Cy734UjsDmXxDn8ISxojPjMZW+fiqWrMq8NloRt0bUr24qbSCsJ29oDLpTaupVtpf7fTZ5gCVEHWmv+03dexW5VfOL2HqzRISzxSYyem6/anAIhhBAC+ACQAH4L+D7wBnBvXU8khLh6omMAvBZvoKfRidNeaoOUEKJU3iYzRIzNTlz29qloqiqbSAGChTbScHztsO38QthWfrBut1po9Tulsm0lSqmdSqlbWf4EKwx8ovbHE2Jre+S1CR47N8WDt3TR2ezDOvwMAJa+W+t8MiGEEFvM/6m1NrTWOa3132it/xj4VL0PJYS4SmKTALw056Q/6JEXfYWogcZgOwAT48OXvX0qWr3KNp/ThtNmWZgDt5qz4zFa/U4aPY6KrtcRcDMmlW0r+kMgorWOL32CBXwT+E81P50QW1gqm+f/+qfX2BHy8MD1HSilsI48jeEMYG0/UO/jCSGE2FruXuFtP3PVTyGEqI/YOIarmQtzeba3SNgmRC2EWjsACE9fWdlWvbBNKUVv0MPA1NqNiucnoxW1kBZ1NroYnZfKtpW0aa1fufKNhbf11eREQggA/uz4GwzPJvnk27fhcZn/c7UOP0Ou8yhWm73OpxNCCLEVKKV+TSn1CrBHKfXykj8XgJfrfT4hxFUSnSDlDJLXsKPCTaRCiJV1dHTB/8/efYe3WV79A//eWt7biR3bsZ2942wSkkAIK2Fv0kUpbYEXaKHlfd9CoT/a8rbQ0lKgFFooUMqGsEkhkMXKsrOnncRJHNvxiPce0v374/hBsi3Zsi1Zjv39XJcv2VrPrUeydOs85z4HQE15yTfnNbbYUd3Y6rNgGwBMSIzEwaIaj5c7HNKJdFwflpAaRkSF4GRlY6cOq0NBd8G26C4uC+ntRpVS0UqplUqpg0qpA0qpBb29L6LB6OipOjz9+RFcMDEOC8bEAQBUXQnMlUdhTzmDRxOJiKi/vArgUgAftJ0aP7O11uxMTzRU1Baj2hILABjng2wXIuosJGoYAKCpuuyb807VynJPX9VsA4CJiREoqGxAdWOL28vzKxrQ0GLHBB/8r4+ICkZDix1VDe63NZh1F2zLUkr9uOOZSqkfAdjWh+0+DuATrfVEABkADvThvogGlZNVDbjh+S0Itphw15JUmNu6jpoLMgEAKo312oiIqH9orau01se01t/SWh8H0ABAAwhXSqUGeHhE1E90bRFOteVhjB3OYBuRX1hD0QwrWtu6kdY1teJ3qyRUkhob7LPNTEyU/+EcD9ltRidSXwTWk6IlR6uwcujVbeuujcxdAN5VSn0HzuDaHAA2AFf2ZoNKqSgAZwG4EQC01s0AmntzX0SDTWlNE77z7BaU1zbjqWsnIiXWmbprLtgKbQmGOWVmAEdIRERDkVLqUgCPAkgCUAIgDXKwlEVEiQY7rYHaEhSEL0BChA0RIX0rmE5EHiiFBks0TI3lyCurw80vbUNOcQ3uOnskMpJ8t3x7Qluw7WBRDeakx3a6PKfECLb5YhmpBAkLKxswOSmyz/d3Ouky2Ka1LgZwplLqHABT285epbVe14dtjgJQCuAFpVQGJIh3p9a6XYU+pdTNAG4GgISEBGzYsKEPm+xabW2tX+9/KOA+7Luiilrc//halDRo/GymFfbSXGSV5n5z+Zyc9agNG4vdmzMDOMqBja9D3+B+7Dvuw77jPhxw/g/AfABrtNYz2+aGXEZKNBQ0VEDZm3GsKQKj4kJgMnW3OIqIeqs1KBphTdW49MmvoDXwxNUTMT89yqdlhJKjQxARZEG2p8y2ohokRQUjMrjvdcKNzLaTQ7BJQneZbQAArfV6AOt9uM1ZAH6itd6ilHocwD0AftVhm88AeAYA5syZo5csWeKjzXe2YcMG+PP+hwLuw76pbmzBZY+uQUkD8NhVE7Bo3LD2b6hNNQj/8hga597B/dwFvg59g/ux77gP+477cMBp0VqXKaVMSimT1nq9UuqxQA+KiPpBrRRrz6kPx+gx7ERK5FdhcYipKUdcqBV/vmI8xiREoqXFt/XOlFKYkBjhMdh2sKjGZ7UZ48ODYDEpFFYNvWWkgTgskQ8gX2u9pe3vlZDgG9GQ9efV2circeAPl43tHGgDYC7MgtIOqPQzAzNAIiIa6iqVUuEAvgDwStvB0rpubtMlpZRZKbVDKfWRT0ZIRP5RWwQAKGiNxJjhYQEeDNHgFhOfiHHhzXjhO1MwNtG3GW2uJiRG4EBRdacuoZX1zcgursGctBifbMdsUkiIDMbJyqGX2dbvwTatdRGAE0qpCW1nnQtgf3+Pg2igKKxswGtbT2BRkhlLJw53+4ZqOboO2hwEM4NtRETUj1yaIFwOoB7AzwB8AuAIpCtpX9wJNskiGvjaMttKdDSbIxD5mSk0DpG6GtFhvmuI4M7ExAjUNLbiZIeMsy1Hy6E1MH9MnM+2lRwdwsy2fvQTyFHR3QBmAPh9gMZBFHB/W38YWmtcMsrivgaG1rDkrkXLyIWwhAytopJERBRw7wFAW23dt7TWrVrrF7XWT2ity3p7p0qpFAAXA/inj8ZJRP5SI5ltpQy2EflfaCxUYyW0w+7XzUxIlO+VHZeSbs4tQ7DVhOkpUT7b1ojoYNZs6y9a652QrqZEQ9qJ8nq8mXUCV0wfjriQKrfXMZXlwFSVB/ucW2FjjQwiIupfrh88o314v48B+F8AHr+5s1nW6YX7sO8G6j4cczgLw2FDqzkEObuzcGgAz0cH6j48nXAf9l1f9mFyYQXGaQd2bfkCdpsExLTWMJlMPl1SWtciy0f/s3EnVJGzw/Ca3Q0YHQls+upLn23LUd2MwooWfLp2PWxm7x7DYHgdBiTYRkTiyXWHoaDwgzOSUHS02u11LLlrAABq4kX9OTQiIiIA0B5+7zWl1CUASrTW25RSSzxumM2yTivch303YPdh2csoOhmLUdHhOPvsswZ0N9IBuw9PI9yHfdenfbirGDj8T2SMHwnzsPEAgObmZoSFhSE42LdLS3+XtRbNobFYsmQmAKnXlr/6M/z8vPFYsmScz7bTMrwYH+ZmIXp0BuaNivXqNoPhdThw3ymJBrljp+qwcns+rp4xHClx4R6vZz6yBq3DpsAam+rxOkRERH6SoZSqVkrVAJje9nu1UqpGKeX+KFH3FgK4TCl1DMDrAJYqpV721YCJyMdqilDsiEJ6bMiADrQRDQphUivNXJXn90117Ejqj3ptADC7rdlC1vFyn97vQMd3S6IAeWLdIVhNCt+fN8JjSrCqL4f55Da0jDoXZrO5n0dIRERDndbarLWO1FpHaK0tbb8bf/eqkKjW+l6tdYrWOh3ACgDrtNbf9enAichnHDXFKGiNwqj40EAPhWjwGzkfOmwYgjOfArRPEso9mpAYiSOltWixOwA467VlpET7dDuxYTaMHhaGbccqfHq/Ax2DbUQBcKS0Fu/tKMA1MxKQFNNFVtuxdVDaATVxeT+OjoiIiIhI6JoilOoojBnmec5KRD4SFA6cfQ+shVuhjnzm101NGhGBFrtGbmkdAGBzbjnmpMXCZvF9mGhOWgy25VVA+zmAOJAw2EYUAK9szoPFZML35yV1WejScmQNHKHDYBnJfiJERDT4aK03aK0vCfQ4iMiDlkaYm6tRomMwhp1IifqFmv196JhRCP7yYcCPXUknJMr/9MGialTWN+NgUTXmj/auplpPzUmLRWV9C460BfaGAgbbiPqZ1hprDhRjXlokhkeFeL6ivRmWY5+jOf0cmC3W/hsgEREREREA1BYDAEoRhVHxzGwj6hdmK9R5D8BSngPT3jf9tpnR8eGwmBQOFtU467WN9m29NsPsdKnbtm0I1W1jsI2onx0prUVeeT0WjY7ussisOX8rVHMN9PhlPm3zTERERETkldoSAEBL8DCEBfPgL1G/mXwFdNIsBG/6M9Da6JdN2CwmjBkWjuyiGmw6IvXapvu4XpthdHwYYkKtyBpCddsYbCPqZ2sOyKTlrLExXV7PkrsG2myDZdy5/TEsIiIiIqL2aosAAEFRw9mJlKg/KQV1/m9hri2CbeeLftvMxBEROHiyGptzy/xWrw0AlFKYnRaDbcc7B9scDv1Nk4bBhO+YRP1s7YFiTEwIQ1J0Fx2dtIYl9zO0pCyAOaRXzd6IiIiIiPpE18gy0vC4ZK60IOpvoxZDjz0PYdv/DjRW+mUTExIjUFjViINFNVgwxj9LSA2z02KRe6oOZbVN7c7/ZF8Rzv3z5zhRXu/X7fc3BtuI+lFFXTO2Ha/A4tHRMJvNHq9nKj8CU+Vx2Mecz6OIRERERBQQ9WUFsGuFYQlJgR4K0ZCkzvsNVGsjTHmb/HL/ExOdjU/81RzBMOebum3O7DaHQ+PxNYdgNSskRXdRz/w0xG/xRP1ofXYJHBpYPKbrJaTWPa9AKxPUxIv6aWRERERERO3VlhWgHJEYNZwrLYgCInEq8LN9sE67wi93PyFR/rdDrGZMS/ZPvTbDtOQo2MymdsG21fuKkF1cg58sHQezaXBlz1oCPQCioWTtgRLEh9kwJclz63RVXQjrzn+jaeKVsMWP6sfRERERERE5tVYVoVJHY2wCg21EgaLCh/ntvpOighERbEFGSrTf6rUZgq1mTE2O/CbY5nBoPL72EEbHh+HSjMGXPctgG1E/aW514POcUpw3IRZWi+d/PdumRwGtgbPv4RJSIiIiIgoYVVeMMkRjfkxYoIdCRH6glMKj183AiKjgftnenPRY/GvjMTS12rH+YAkOFtXgL9dnDLqsNoDLSIn6TeaxctQ2tWLx6GiPBWZNZYdh3fcmmqZ/B0EJ4/p5hERERERETsFNp1Bvi4fF4rnWMBGd3s6fnICpyVH9sq3ZaTFobnVgT34VHl97GKPiw3Dp9MGX1QYw2EbUb9YcKEaQxYT5ozyvhbdtfASwBAOL72bHJyIiIiIKHIcDkfYKOMKGcbUFEfnErFSpXf7HT7Jx4GQ1frJ0LCzmwfn+MjgfFdEAo7XG2gMlmJsaifBgm9vrRNQchjVnFRpn/ghBsSn9PEIiIiIiIqfmmlOwwA5zREKgh0JEg8SwiCCkx4Vi67FypMeF4rJBWKvNwGAbUT84XFKLvPJ6LBod7fHI4JijL8MRHAPTojuZ1UZEREREAVVUcBQAEBo7IsAjIaLBZHZaLADgjqXjBm1WG8AGCUT9Yu3BEgDAWWNj3F5uPrEREZW7UL/4foRExPXn0IiIiIiIOik5eQKpAGKGc8UFEfnOinkjoRRwxYzBm9UGMNhG1C++PFSKccNCkRQd6vZy2+Yn0GSLgWXBLcxqIyIiIqKAqy7NBwAkJKUGeCRENJjMTY/F3PTYQA/D7wZvzh7RANHYYkfmsQrMTY2E2dy5k5OpaCcseV8hL/lSWEMiAjBCIiIiIhpSDq+BfukqoKXR41UaKwoBABHxzGwjIuopBtuI/CzrWAWaWx04I919O2Xb1r/BERSJk0nLmdVGRERERP7V2gysuhvqyFq07nnb49UcNUWoVyGwhLqfwxIRkWcMthH52ddHTsFiUpg9svNExVR2GJZDn6Bp+g1wWN0vMSUiIiIi8pms54GKY3DYwoHM5zxezdZQilpLrMfmXkRE5BnfOYn87OvDpzAtKRwRIbZOl9kynwYsQVAL/isAIyMiIiKiIaWxCvrzP6Bl5EI0zb8LlpPbYC/c3elqlfXNiLKXozl4GFdeEBH1AoNtRH5UWd+MPQVVmJsa2emooKouhOXA22iacj2CYpIDNEIiIiIiGjK+egyqoRy1C/4HrVOvhzbboDP/2elqR0rrMAyVQDiDbUREvcFgG5Efbc4tg9bAvLTOS0ht256RXxbcwUkMEREREflXVQH05qfQNOFymJJnASExaJlwGcx7V0I3Vre76vbjFRimqhAcPSJAgyUiOr0x2EbkR18dPoVQmxnTktp3GVX15bDufgVN4y+DbfjYAI2OiIiIiIaM9b8HtAP18+/+ZsVFS8b3oFrqYN/5RrurfrYrFxGqAaExiYEYKRHRaY/BNiI/+vpwGWalRCAkqK1em9awHF6NkJUroFobgIV3sugsEREREflX8T7ona+gcfr3YY4b9c3ZjhGzYI+fDLXteUBrAEBeWT2KCvMAAOaopIAMl4jodMdv+UR+UlDZgKOn6nBGWhQUAMvh1Qh9eTlC3v8h0FyHuoufgi15eqCHSURERESD3faXAEsQGub8V/vyJUqhZcYNMJfuhz1vCwDgoz2FGI4KuTyCmW1ERL1hCdSGlVJmAFkACrTWlwRqHET+8vXhUwCAuamRsG57BsGfPwh7VBrqL3wU1lnfRlhQSIBHSERERERDQt4mtCbMgDk8vtNFLZOuQNDnD0JvfhporMSojc/jmeCtgAZUVEoABktEdPoLWLANwJ0ADgCIDOAYiPzm68OnEBtmxfiEcFg2rUNr3ETomzcglEE2IiIiIuovzXXQRXvQMvsW9+VLbOFomXwVbLteAg68h4U6BMXDFiJk/jUISpzc/+MlIhoEAhJsU0qlALgYwO8A/DwQYyDyJ601vj58CvNSI2Exm2Au2oWmCVcgmIE2IiIiIupPBdugtB0tI2Z7rCHUPP9O2G1ReK9yFB7YMwyfXXc2QoZH9+swiYgGk0Bltj0G4H8BRHR3RaLTUU5xLU7VNmNuaiTMFblQzbXQSbMCPSwiIiIiGmraarH911ehaNq8E8FWM0KsZqTEBOP2s9IQbDVDhyeiZfEv8Owz2zBtpBkj47n4iIioL/o92KaUugRAidZ6m1JqSRfXuxnAzQCQkJCADRs2+G1MtbW1fr3/oYD7sL3Vx1oAABF1hTi+cQMmA9hdZkVDF/uI+7DvuA99g/ux77gP+477kIjIN5qPbUQeRiK31oqkKI2K+macbHFgbfYpHCyqwV+vm4pgqxmHSuuRe6oe9104xv1yUyIi8logMtsWArhMKXURgGAAkUqpl7XW33W9ktb6GQDPAMCcOXP0kiVL/DagDRs2wJ/3PxRwH7b3wvNbkRpTgwsWzUbo+vfhsIZj9oUrYLHaPN6G+7DvuA99g/ux77gP+477kIjIBxwOtB7fgkz7fPzj+xnIGDUcWmsAwJuZebjnnb346Vt78dfrpuGTfSUwKeDi6ckBHjQR0emv34NtWut7AdwLAG2Zbf/dMdBGdDqrb27FptwyXJMxHGazGeainWhNmAarxRrooRERERHRELI1cyPmOeoQPmY+pqcPAwAopQAA189LgwZw7zt78ZM39yC/sglzUyORGBMWwBETEQ0OzA8m8rGvD5ehudWBRaOjgf5unl0AACAASURBVNZGmEr3w54445uJDRERERGRv9U2tWL9Zx8AABYvWeZ2LrpiXhoeumoqNh2twomKRiybMpxLSImIfCBQDRIAAFrrDQA2BHIMRL627mAxwmxmzE6NgqlkL5SjFSp5TqCHRURERERDyCOfHERG0z40h8YiPHmSx+utmJcGpRRe2XwMl2Sk9OMIiYgGr4AG24gGG6011h0swfz0KIQE2WAu2gkAMKXODfDIiIiIiGio2Ha8HP/efBxZ4Uegk+fAbOn6a9/1c1Nx3ZyRXIlBROQjzBEm8qF9hdUorm7CotHRUErBXLQT9rAEmKN5lJCIiIiI/E9rjd//5yAmhtUhruUkHCnzvAqiMdBGROQ7DLYR+dC6gyUAgIWjowEAppM7YU/IYO0LIiIiIuoXXx0+hW3HK3DX2FIAgEpdEOARERENPYwAEPnQuoMlmDoiHAlRoUBDBcyVR+EYMZNHComIiIjI77TWeGzNISRE2LAo6Ai02QZz8oxAD4uIaMhhsI3IR07VNmFXfiUWjoqCyWSCuXi3XJDC5ghERERE5H9GVtsPzkhCUPF2tA6fDnNQaKCHRUQ05DDYRuQjG7JLoTWweGwsAMB8cgc0FMwpswM8MiIiIiIa1LSGtrfg8bastismR8Fcshf2pDksZ0KBk5UFxMUBhYWBHglRv2M3UiIfWXewGMPCbZicGA4A0hwhZgxModEBHhkRERERDWrrHoRj45O4uXkqzBMvQmRxNZSjBUidH+iR0VC2YwdQXi6nSUmBHg1Rv2KwjcgHmlsd+DLnFM6dEAuLxQJoDVPRTrSknY0gsznQwyMiIiKiQUyf2IJaRxAyzMeQcOhB4JCcb0pjsI0CqESax+H48cCOgygAGGwj8oGsY+WoaWrFotFRUEpBVefDVH8KjhEzAz00IiIiIhrkmksOY03rdJxa8kf8cGwN9L73YYcJtsiEQA+NhjIj2JaXF9hxEAUAg21EPrD2YAmsZoX56TEAAPPJnQAA08i5gRwWEREREQ12zfUIqi9CseUs3HDmWFhCgoC0+bAGelxEDLbREMZqmUR91NRqx3s7CrBwVDQiQmwAAHNhFrTZBtOIaQEeHRERERENahVHAQDWuDEIC7YFeDBELkpL5fTEicCOgygAGGwj6qNP9hahrK4Z18wYLt2eWhthOfAumlPPgtkWEujhERERDShKqZFKqfVKqf1KqX1KqTsDPSai01n5iQMAgOiU8VBKBXg01K+uvRb4y18CPQrPjMy2ggJA68COhaifMdhG1EcvbTqO1JhgLBgdCwCwZH8EU0MZHHN+xFbrREREnbUCuFtrPRnAfAC3K6UmB3hMRKetoqP7AQDpY6cEeCTU7z75BPj000CPwjPXYJvdHtixEPUzRgKI+uDAyWpkHa/AVRnDYbNaAa1h2/E8WmPGwjr+vEAPj4iIaMDRWp/UWm9v+70GwAEAyYEdFdHpq6EoB2U6EhNHjQz0UKg/1dcDtbVAYWGgR+KewwGcOgVERwPNzUBRUaBHRNSv2CCBqA9e3nwcQRYTLps6HABgOrkd5uLdaFj6fwixsiwtERFRV5RS6QBmAtji5rKbAdwMAAkJCdiwYYPfxlFbW+vX+x8KuA/7rrf7MLr8MIrMiSjN3Or7QZ1mhtLrMKioCAsANOflYaMPH7Ov9qGlqgqL7HaUjx6N2O3bse2DD1AzeWgkMQ+l16G/DIZ9yGAbUS/VNLbg3R0FuGBiHOIjpTabbcfzcNjCYZ71nQCPjoiIaGBTSoUDeBvAXVrr6o6Xa62fAfAMAMyZM0cvWbLEb2PZsGED/Hn/QwH3Yd/1Zh/WN7eian0xSuLmcf9jiL0OMzMBALbKSiyZNw8IDfXJ3fpsHx6QWoKxixYB27djdkwMMESemyH1OvSTwbAPuYyUqJfe3VGA+mY7rskYDqUUVG0xLDmr0Dz5WljDYgI9PCIiogFLKWWFBNpe0Vq/E+jxEJ2u9h4rwghVjqBhYwI9lIHn66+Bt98O9Cj8x6iHBkhNNG98/DHwxhv+GU9HxvhmzJDT48f7Z7tEAwSDbUS9oLXGS5uOY0piODJGRgMArLtfhnK0AnN/zE5QREREHij5kHwOwAGt9aOBHg/R6Sw3ew8AIC5lfIBHMgD94Q/A7bcHrgtmYyPw618DNTX+uf/iYufvJ054d5v77wduugkoK/PPmFyVlsrpmDFAeDiQl+f/bRINIAy2EfXC1qPlOFRSi6szhsNsNgP2Zlh3v4LmtLNhGzEp0MMjIiIayBYC+B6ApUqpnW0/FwV6UESno/I86UQanjwhwCMZgEpKJCBVXh6Y7a9eDfzmN8BHH/nn/l0z2/Lzu79+Swuwd680Vvj73/0zJlfG+IYPB1JSvA8IEg0SDLYR9ZDWGk9tOILIYAsunBwPALDkrIKprgSts38Ik4n/VkRERJ5orb/SWiut9XSt9Yy2n/8EelxEpxutNZpLjwAALMMZbOvECPYcPBiY7Wdlyam/lk+WlACWthLs3gTbDhyQrqAhIcDf/ibBN38y9n9cHINtNCQxKkDUQ//4Ihef55Ti5jOTERESBDRVI+jrR9AaPRq2ScsDPTwiIiIiGgJyT9UhsbUADdYYmEKiAj2cgcdYxrh/f2C2bwTb/BVkKikBkpOBsDDvarbt3Cmn99wDnDwJvPaaf8blOr7YWMBqBUaOlDEGakmvP+3bBzz3XKBHQQMQg21EPbDpSBn++MlBnD8hDt+ekwQFIHjNvVDVBWha9igsVlugh0hEREREQ8C24xUYZSpCa1Q6V1Z01NAA1NbK74HIbNPaGWzztnlBT5WUAMOGAUlJ3gfbQkKAW28Fxo0DHnvMv8Gv0lIZn1KS2XbqFFBX57/tBcpTTwE//rHU6CNywXdlIi8VVzfiJ69tR1psCH61bDSsViss+1fCevB9NJxxJ0LGnx3oIRIRERHRELH9eAVGmYphjR/N5lwdGVltQGCCbXl5ElwCvFvi2RslJUB8vPfBth07gEmTgKAgaRyxYwfw+ef+GZsxvrg4Z7ANGJxNEvLzJWjJbqvUAYNtRF5osTtwx6vbUd9kx8OXjkVMeAhURS6C196HlqQzYFt6D48oEhEREVG/2XfsJIajAjp2VKCHMvAYwbaQECAnp3f3oTXgcPTutpmZcjppkv+WT7oG206e7HobWktm27RpgMkErFgBxMQAj/qxIbRrsG3kSDlvMAakjEBnbm5gx0EDDqMDRF54+OODyDxWgV+en45JSdGAvRkhq+6ANllhv/wpWGxBgR4iEREREQ0RVfUtaD0lzRFU3NgAj2YAMorzz54NHD3auyV+b7whnTR7s/QxK0tqlZ1/vnREbWrq+X10xeGQgGJ8vNRtKyoCWls9Xz8vD6isBKZOlb9DQ4GbbpJOqYcO+XZsBmOZK9C3zLZNm3y//3yJwTbygME2om68uiUPz311FNfPSsQl0xOhlIJt8xMwF+9GwwWPIGj4mEAPkYiIiIiGkO0nKpCuigAw2OaWkdm2YAFgt/cuoLRmDVBWJsG6nsrKAqZMAcaMkawyX9dtq6yU4Fp8PDBihDzGoiLP19+xQ06nT3eed/PN0s30scd8OzZAxlZeLuMDJPtOqZ4H2/LzgYULgWef9f0YfaGlRYKpQO9eJzSoMdhG1IUvD5XiV+/vxcLR0bh7aTrMZjMAwHJsPZqTz0DwjGtYI4OIiIiI+tX24xUYbZLgiimeB347MYJtZ54pp72p27Zrl5wWFvbsdkZzhIwMZ0aXrzuSGpl7w4ZJZhvQdW24nTtl+ejkyc7zRowAli0DPvzQ98tcjXp1RrDNZgMSE3sebMvJcS6BHYhcl+8eOxbQodDAw2AbkQc5xTW47eXtGB0Xgt9fMhYhQc5Oo6rqBBwxY74JvhERERER9ZetR8sxPaQM9pB4mEKiAj2cgaekRAI8s2fL3/v39+z2ra3A3r3ye0+z0o4cAaqqJNhmBMJ8HWwzsqmMbqRA18G2HTuAsWOBiIj250+cKMHElhbfjs8IBsbFOc9LSen5fjCyxQ4c8M24fM14bVgsg7MeHfUJg21EbpTWNOEHL2QiyGrCX64cj9iIUOeFzXUwNZQD0WmBGyARERERDR01xUCVfLFvbLFjR14FxluL4YhOZ5Mud4x6ZpGREozqaWbboUPOOm89zWwzmiPMmOEMtvm6C6cRzDIaJABdB7J27pR6bR1fK2lpsgTVn+MzjBzp7NzpLaMOWna2f5pMuFNZ6czM644RbJs+XYJt/TVGOi30+zuzUmqkUmq9Umq/UmqfUurO/h4DUVccDo3bX9mOstomPHrFOKTGtz8CZKpq+zCKYbCNiIiIiPrBWzdCP7MEuqYY249XoNmuMcJeCEfMKJY0cce1E+b48RKs6QljCSnQ88y2rCwgOFhqtkVFSTaZu0BYTY1kv33xRc/uH2i/jDQ+XpoxeMpsKy+XYJrRHMFVaqqc+rremLGMd/hw53kpKbIve9Lh1Qi2lZU5s/n8SWvg4ouBq67y7vrGa+OMM+Qx19b6b2x02gnEYZBWAHdrrScDmA/gdqXU5G5uQ9RvXtmah63HynHPeemYkRrbaQKjquTDUsWmB2B0RERERDSk1JZC522CqiuB4+0fY/ORUoSrRgQ3lUHHjAr06AYmI7NNKWDCBMlUs9u9v/2uXbI0MDVV6nL1RFaWBLaCguTv5GT3gbBdu4Ddu6URQ0+VlMhji4uTbLXERM9BQaPe2bRpnS8zgm2e6o3Z7b3r5OoaDDSkpMh9GZd5IzdXApcAsG9fz8fRUxs3ys/Bg95lqeXny/M8Y4b8zY6k5KLfg21a65Na6+1tv9cAOAAgub/HQeROcXUj/vjxQcxLi8Jl0xPcHik0VUtmmymWkxsiIiIi8rNDq6Gg0TD1OzAf+xwJe57GOfHVclkcmyO4VVrqrBc2frxkHHVV06yjXbvkdmlpPQu22e3A9u2SsWYs2UxOdh8IM4JHvSmsb2TuWa3ObXha7moE29xltqWkSNDOU2bbI48Akyb1fHlkSQlgNgPR0c7zRo6U054sWc3NBRYtkt/7I9j26KNyWloK1NV1f/2CAmk0kZ4uf7NJArmwBHLjSql0ADMBbHFz2c0AbgaAhIQEbNiwwW/jqK2t9ev9DwWDZR8+uaMRjS12XJ7cgJ0eut6MO5KFEeZgfL39AKB60dnIg8GyDwOJ+9A3uB/7jvuw77gPiYjaZH8MR/gINC79P6CxCtcfegmj42W5moobG+DBDVAlJc56YePHy+mBAxI888auXcDChRKI2rJFgk3eLNfNyZHA3syZzvOSkyWDreN9GE0belMvzXh8xv0lJUlQzd04d+6UgFBiYuf7sdnkMk9Bok2b5LKSEiAhoefjc20mZ3RmPX5cll12p7paaqedeSawebP/g21HjgDvviuvkePHZenvpEld36agQPa9EWxjZhu5CFiwTSkVDuBtAHdpras7Xq61fgbAMwAwZ84cvWTJEr+NZcOGDfDn/Q8Fg2Effra/GFnFWbh9cQouXey5/kVwwdNAdBrOOvtsnxakHQz7MNC4D32D+7HvuA/7jvuQiAhASyP0kXVonnglzBYLvp54H8bmZGJB2dsAAFM8M9s6qa+XrCQjs23CBDk9cABYtqz72586JVliU6YAFRVAUZHUGXMNHHmSlSWnGRnO85KTJVOqoQEIdWm6ZgSP8vK8D+YZ3AXbPv7Y/Th37JAlpJ6+t6SleQ745eTIaW5uz4JtxjJe1226Btu8YWTbpafLc9jTJhc99fjjsnT43nuBW2+VcXoTbMvIkEBmcLDva9/RaS0grWuUUlZIoO0VrfU7gRgDkavaplb8v/f3YuywUNwwL7nLQrOmqjw4IkeyGC0RERER+dexL6Fa6tGUvhRKKWwpbMWdrT+BNllhDx0GU3BkoEc48BjF+Y1gW0KCNCk4cMC72+/eLadTpkjWV1OT990pMzMloDZxovM8I8jUcRmrkdlWUNCzenKA+2BbQ4MEB101NsrjnjLFczAvNdUZ8HPV2irZXkDPM7Y6jg8AYmNl33ibyWdsMzVV9qe3ddR6o6ICeP55aYwwf76c1904tXYuI1VKlslyGSm5CEQ3UgXgOQAHtNaP9vf2idz586fZKKpuxH3npyM0OMjzFbWWYFsUg21ERERE5GfZ/4G2hsI+ciEAYOvxKjgSpsNx5T/QuvC/fbrKYsCx23vWudJgBNuM4vxGR1IjS6s7RifSqVMlkAJ435E0KwuYPl2WZxqS28qTuwZvKiqkFlxaGtDc7LnemiclJe2bDyQldd4GAOzdK/vRXXMEQ2qqbL+lpf35x445z+tNsM0IdhqUksCju86s7hjbHD1agm0lJd4HPXvq2WclG/LWW+X5Uqr7DLzycglmGstzjeWnRG0C8e68EMD3ACxVSu1s+7koAOMgAgDkldXjpU3HcdX04ZiVFgsAUBVHoWo7t5dWDeVQLfVAjJf1HoiIiIiIekNr6OxP0JK6GJbgMNQ327HvZA3mpkXBPO1qBC28dfAe/C0slKWD993X89t2zGwDnME2bzKjdu2SbLjERGewzZtgWGurLNnMyGif0WVktrkGmYwlpOeeK6c9CdI0NwOVlc6adIAzoNcxe66rTqSGtDQJyHUM1LkGJ3sabCstbR8MNPQ02BYdDcTEOJcCG9mA3qqtBe6/H7jySuDii4HzzwfOPluCallZ8npobgaeeELOnzlTuosmJHSf2WYEYI19byzH7U2AmAalQHQj/UprrbTW07XWM9p+/tPf4yAy/G39YZiUwo8WJMvRwdZGhL5+FWyf/uKb6wTfdhuC7r4bqkredFV0eoBGS0RERERDwsldUDWF3ywh3X6iCq0OjQVj4rq/bSAUF/tmmV9dHXDppbKE8d//7l0nTKB9sGfCBMkkq6zs/va7dsmyS5PJmbXkTSfTrCzJdHJtjgA4s85cg0xG0Oj88+W0J8sPjcfnGmwzgoLugm0REcCoUZ7vLzVVTjvWG8vOltO0tJ6Nr7FRmht0zGwDZKllfr53z2lurtRrM5mcy3J7Emxbv16yDH/3O3kshYUyrpYWeV3NnSvP1S23SODsllucNea8CQoawTbjNZKeLq8vb15jNCQM4rxjou6dKK/H29vzceX0YUiODQcAWPe/A1N9KSxFO6DbjkyYV6+G5dNPYaqSN10Vmx6oIRMRERHRUJDzCTQUWtLPAQBkHq+CxaQwb3R8NzcMgKNHJcPn44+9v83Bg7IUz5XDAXz3uxIkuvJKCZBs396zsXRcRgo4O5J2V2S/pUUCOkaNM28z206cAK6/XgJgZ53V/rLwcCAqqnNmW1iYdNoEelZY312wLTFRxtsx2LZxo2S1Wa2e788ItnUMqOXkSGbZrFmSeedt0NPY//FuXqcpKTL+hobu7yc3V8amlJyGhHjXkbSmBrjtNmDpUrntBx9IV9XPPwfWrAFWr5bg2yOPyPX/9S8Jxl5wgfM+vAkKdsxsM/ajUeeOhjwG22hIe2rDYSgF3DBvhKThawes254FAJgayuCoyocqK4OptBTqxAmYSuTNk8E2IiIiIvKr7P/APmIWzJGSOZN5vBJTRoQjIqSL+sKBsmOHLEX8+mvvrl9aKsst09KAX/zCGUC65x7gvfeABx8EHnpIzvtPDxdBlZTIUsBIl+YRRrCtuyYJBw/KssIpU+TvoCAp7N9VsK20VDLUKiuB1193Lht1lZzcPhC2f7+MKSpK7r8ny0jdBdtsNgkuutaW27dPnpfly7vudJqSIpd3DPjl5ABjxkjGVn6+LJPtyfg8LSMFus8as9sl+JfWVrrHZALGjev++bPbgYULgb//Hfiv/wI2bACWLJHbu+6D6GjJZPvyS+Crr4A332xfZy8lRfZlV0tCCwrkPl1rtgFskkDfYLCNhqz8inq8lZWPK6YNx8i4CACA+eh6mMsPoSnj+/J30S6Y2lKolcMBU85eOIJj2fmJiIiIiPynuhA4uQtN6UthMplQ29SK/SdrMDc1amA2RTDqe3WXOWZYuVKCWvPnS4ZRerpksj3yCHDTTRIoSUqSgFxPsuUACX7FxzuXBAKyjNJi6T5YYzRHMIJtgARTPAXbqqqACy+UWl0vvyxLE90xgjeGffskm8pkkoyo3gTbOgazkpLab+PFF+UxX3NN1/dns8ltOwaJsrOBsWPluWlp8b7WmruaeYbJk+X0gQe6DmQVFsrrIz3ded7EiTKmrrLNVq8G9uwBHn9cgrXR0d2Pd/r0zstsU1JkOayxr93Jz5fnwAjSGcG2nta3o0FrAL5TE/WPpzYcgVLA942sNgC2bc/AHpYI0/m/hlZmmEv2wuQyaTAdOgx7ZMrgLUZLRERERP6XtwU4+gXQ2uT+8pxPAADNo6SA/vYT1bBr4MyxA3AJKeCs72Wcdue11yTY9OabwNatUqPtww+lYcDDD0uQCJBA1pYtPetCWVoqgR7X+brVKl0tuwsG7tol2WxGQX5AlpKePNn5ug0NwCWXSMfPF16QAvueviOkpEgASWtnJ1JjG6mp3geyAM/BtuRk5zhbWyX4d955zqWwXenYSbO2VgJ3Y8b0PIjUVWbbzJkSaHvjDeCOOzwHzoxtGdsGJNhWUNB1TbS//x0YPhy49tr2wdaeGjlSTrtqklBQIEFKYzuxsVIfrydLgmlQY7CNhqSCyga8lXUCl08bjtR4yWozleyDJe9rNM38ASxhMcDwSbCU7Ibp4EHo4GAAgDpWCEfUyIF5RDHQXnlFPjiJiIiIyLOSg9AvXgK8eCn0H0ZBv3IdsOUfSDy5BvjsAeD170Cv+x3sUalAvARkMo9XwmpWmDtqgDZHMDLbDh+WLKiunDghy/euvFKCahMmAP/8pwTCXn0VaJt3A5A6Wg4H8Mkn3o+lpEQy2zoGvsaP7z4YuGuXBHVclxQmJQFFRZ0DQytXyhLEJ57ofqlmUhJQVibNH4wi/8bSVqM+mN3u/eMLCpIlqK5GjJCAnsMhtclOnpQ6ct58b0lNlcCS8RgPHZLTvgTbhg93f/nPfw785CfA008Dv/qV++sY2+qY2QZ4zk48cQJYtQr41rekHl5fGMtdu8o4LChw1soDnLXluIyU2jBiQEPS0xsOAxq40TWrLesfcFjDYJ57E5RSUEkzYWnLbHOMHw/HiBFQhRXQUakBHn2ArFgB/OUvni+//37PH5hEREREBDjswAc/AWxhqLrgcTROvBKOkgPAx/+Lidl/hd70N9iLD6AlYSZqF/4SZosFDS12/GdvCWamRCAs2Nb9NgIhOxsIDQWamroPyhgHZ6+6qv35CQlSBN/V7NmSpfbRR96Pxchs62jiRMk66qo4v2snUkNiogSQOtYs27FDxnvNNV0H2gBnEf0TJ5xF/idNktPUVKC+3rn8sjslJZI11jGIlpwsWV91dVL0PzYWWLbMu/tMTXUu3QScwdMxYyQYaDL1LNgWHCxZXu4oBfzf/wHf+550Cn300c7Xyc0FzGZnhhngzAT01CThueckWHjDDd6NsyvGdrsLtnXMGuyYIUhDmiXQAyDqb/kV9Xgj8wQumzYMI+OkA6mqKYQl+wM0Tb8BQZFtKc9JM2Ha8RJwoB72hYuhwoNhOVYMRKd1ce+DVFWVpPkfPgz87GedLy8rcx7FKSnxfCSLiIiIaCjb+iyQvxU15/0ZaupVaJ12NVq0BiqOYe+eXZi0YBlMFhuUUjC1BXBeySxASW0z/njlpIG5uqKsTH6MpaBGPTJPXn1VlhOOG9f9fZvNshRyzRoJdlm8+PpqZLZ1NHmy3MeBA9Jhs6OiIrmtUVfMMGKEZIudPOnsOAlIx9RJk7ru9GkwMqXy8iSzLSzMeV+u3UCNYvtdMYJtHQN8RuBn715pMvG970kA1BtpafIYjWWTrsE2o6abt8sj3dXM60gpyQisrATuvhuYM6d9F9fcXNlnQS7NQEaNkrG4C7a1tgLPPisdSMeM8W6cXYmNlUCqp2WkDQ3ymncXbPv8c+87t9KgNgDfrYn864m1h6CgcNP8pG8mLLbtzwPaAcy/1VmPLWkm0KhhKi6FY9w46JR44JQDKnoIZrZlZsqHxp49Uiy0I9eW7Js2ub+PJ5+U2gwkHA5px95doV4iIiIaHCqOQ6/9DVrSz4FjytXfzDmVUlCxo9AYmgyLLRgmk+mbyyrrW/D8xhNYPDoaiyd6UXsrEIzAzPLlcmosk3QnO1sywq68UgJp3rjgAglsbN7c7VVNjY2SJdZVcf49e9zf2F1zBMAZUHFtkqC1+yw4Tzpmto0f7wwcGllU3i4/LCnpXJPOdRuPPSYZhtdf333GncEI+BkBtexsCXaFS2IC0tO9z9jytIy3I7NZAmQREXLqKjdXAleu92GxSMMGd3PnVavk+bnhhr7VajMoJY/fUy0947XQMTialgbU1cFaVdX3MdBpj8E2GlJyS2vx9vYCXD3D2YHUVLIP1p3/QvPY5bANdznCljAFukze4O1jx0InhgHNgGruYw2A05ExuWludk5EXG3bJqcmU9fBtmef7Tp1f7DTWgKT//M/MmlZuFAK/3bVjYmIiIhOf1oDH94JKIXaJb+F2ZsMLQD/3HgCtU123H3+WJi9DU71NyPYNnu2BB+6akLw2msSyLjiCu/v/9xzZY65alW3V7UaxfPdBdvGjpWAzd697m9szHGnTWt/vhFsc+30mZ8PlJd3Dsx54hps27/f2YkU6Bzo6o6nzL2kJDlduVIy7mbP9u7+XMdgBPxyciRDzBhjerpc5k3GlqdgoDuhocDllwPvvivLXw3ugm2A546kf/+7PE9GwNcXugq2Ga8F43k1tNWYC/bUvdadQ4eA88+XgDINKgy20ZDy2JpDsJkVbpyXJEcMGyoQ8sGP4QiKhl72cPvUfEsQ0JQAAHCMGwfEyQTHVOCDIxVvvCFvxkuXArfdBvz1r4gYyBlOmzc7W2dv3dr58m3b5ANx6AtUJQAAIABJREFU6lTpGNVRQYF8MDY3S8r9UHXrrTLxeewxObr6gx/Ih/gXX/hne5s3y4SxosI/9386+OADWZbQsc4KERFRf9r5KpC7HnUL/hfm2HSvblJY1YhXswpwydRhmJ7mprPjQJGdLUGs9HTJ2PIUbNNagm1nntl+OWZ3YmOBefO8apJgM4Jt7jph2myydNVTsC0rS8bVMVDnLtjmKTDnSUiIPI69eyUrymiOAMgcOyLCu8wxrYHiYvePzxinwwFcd513S24NyckSWDt6VLaRkyPdW41gV1qabNc1IOaJp2CgJytWyP2++678XVsr9+HaHMEwcaIs7aypcZ537BiwejXwne+0b67RV0bjCncBRuO10HEZadvrOrioyPvtrFwpy6TfequXA6WBijXbaMg4WFSND3cX4sZ5SRgREwY47AhZdQdUTREav/U2QmJHdrqNqg6HtgCOlBSoaCkYajrig3bOjz0myzFraqSLZ3U1ZgPy4fvb33qf8t0ftJYA2vLl8kGWmdn5Otu2AdOnS622N97oXFNj3Trn71u2AAsW+H/cA01DA/DSS3L07k9/kklSfT3w+uvyGliypPNtjhyRiUd9vdy+oUGOGP/0p97V4PjoI5nUff55z44gD2Ray4+3SwRefFE6nu3dC8yY4d+xERERuao7Bex/H9j3LvSxr2BPmouWjO8h+2QtfvPxIRRUNiLIYkKI1YQgiwkjbM2IG1WP0fHyGf+3z49BAbjrvHEDs1abISdH6mkFBUnG1uuvS8Cn45h37JDr3nxzz5f6XXCBzJELCjpnE7noMrMNkIOdRnmUjvPtzEyZK3TMIDSaEbgG24yDx95mtgEy7vXr5feONe1GjvRcH8xVdbUcvHYXzAoPlw6lNTXStKEnjLpsx47BWlEh9ZrHjnVebnQkPXZMDq57orWzZpu3Fi2Sbb/0EvDd7zoz/EZ2/m6GiRNlGwcPSgAWkJUzSkmNOl9KSZGgX0ND53m3p2Bb234KPnnS++0Yq4I++kgOzLtTVORdPT8aUAbwuzaRbz36aQ7CbGZ8b65ktdm+fgSW45+jfsmvETJ2sbNWm6tSO1S8CbquAMpaDm0zQRmp8r115IhkHN1yiwSh8vKAAwdwcvly6cyzYsXAWmqZmwucOiWFS2fNci4ZNZSXy4fijBnA3LlyNKrjEcO1a+Vo3rBh7oN1Q8GXX8rzumKFdNsymWRSdNFFwNtvS22Njm68UZacPvAA8Oc/Ay+8ANx7rxxF3bCh+23u2CGn7rIRT1c//Skwf753yxgcDud+ysry67CIiIi+0VgNvPFd6D+NB1b9HPaqQjTMvQNlFz6JZzYV4jv/2oGy2iYsnxyPRaOjMWVEOBIjg7DppB1X/CMLP31rLz7YXYwP95RgxewRGJ0QHehH1LXsbMmCMpkkiFRTIxlBHb32mhyMveyynm/jwgvl9KWXZNmd8dNh/tRlZhsgwba8PAkmuSotlUDSzJmdb2OxyAFl16WBu3ZJgDEqyvvHkJLiXG1gdCI1pKV1DrbZ7cDZZ8tjNpSUyKmnYNaECRKYdBeo6k5qKpCXh1DjuXNtNDBqlJweOdL1fdTVyXy3J8E2k0nqy61dK0Elo+upp8w2QOaDS5bI8/mnP8ljNgKCvmLsQ3dLSfPzZR4f3eF/MyICiI1FiLeZbVo7g23r17v/Drh7twQj337b+7HTgMBgGw0Ju05U4tP9xfjunBGIjwyBJfsjBG19Eo2Tr0fwwlvdB9oAIK8UGGaC6dQ+mGoLoZOiobKz+zaY116TU6PduckEJCcj++67gV//WlKIzzlHUrUHAqNe2+zZEmw7eLB96rYRfMvIcB5hcq3bprUEFRctkvsYqkGP1avliO+iRe3Pv+46mXh1XBrx1Vfy8+CDMgEsKZHlBR98IEGkc86RI8NdFWA1jroOln3e1CQTzsxM75Yj79kjwWCgfRMPIiIif2mqAV6+Gjr7YzTM/BEqV6xCzQ1rcWjyT/CDd4vx9Jd5uGBiHD68fQEevnYW/vLtuXj6hjPw0o/PxJ/PDsWtZ6VjW14V7vswG+FBZty2ZKzneepA4HBI0MvIgjIytjp2jHQ4ZPXDOef0rmv91KkScLj3XlmCafxce227q1m9Cba5G58xV3IXbAMkg8k1W2nnTrmvntTRMzLyQkM7L6MdOVKCOq51fL/+WkqN3H+/sxyGEWzz9PhWrpRMr95kQrYF20KM4JJrt1gjkGUEwjzpLhjoyYoVElx89VXnNowAn6sxYyQBoLxcMvzGjJFsuF/9yjeNEVwZHWTdLe8tKJDXhLv/zbQ07zPbjhyRpIaLL5aVLGvWdL7Oiy9KwHf+fO/HTgMCg2006Gmt8ejq/Tgn+BBua/03wv51DkI+uhUtwzNgvvRRz8Vma2uB/JPQw22wlOyEqiuGTk2UCUVv2zlrLUsGzzyz89EapYCf/xz497/lCMYZZwyMQpmbN0t78ilTJFjmcLTPbjN+nzFDPvBiY9sH2w4flsnD4sVy+0OHBmYNMbsdeOgh71L4e+OTT2T5bGRk+/PPPReIiZHJhauHHpKJyo03SpDObJafJUvkObntNuC552TC4a4eWUmJHIG1WiXQNBiaMKxd6wwuGkHrrhhLNVJTGWwjIiL/a6oBXr4GumAbqi94HC1n3wdzcgay8muw4vntKKhqxJ+unIgnvzsXCTERnYJokUEKv7hoCjbecy4euGQi/nTVZCTEtHWDdDhkrjLQ5OXJwTAjC8oItnWsRbx1q8wHr7iid0ERpYB33gGeftr5s3w58Nln7bKBrJWVUrcrIsL9/RgZZR07kmZmyjY8lZwYMUKyrgA56HzkiPf12gxG8Ma1E6khNVWWiLrOkd9/X07z8iRQCXQfzIqO7lm2XccxFBYi7NgxWVbqGhBMSJD92l0Th9LSrsfnyaRJsj9feUWCbZGR7pcCW61yED8zU+bWr74q5Xl6+lx4w3i+3H036C7YVlTk3ffFjRvl9M47JQj74YftL29pAV5+WTI7PS2NpgGLwTYa9N7ZuA//L+8mvIAHELHnRdjDEtCw5NdwfPstWEPCPd/QKO46Jg22vHVQ0HCMGS1pw7W1vRvMzp1yv1dd5Xmicfnl8kabnw/84he9244vbd4sGW02m5wC7ZclGs0RjK5Dc+e2v3ztWjk1gm1aD8ylpGvXAr/8pWSL+VpennSeWrq084eyzSYTz48+cr6udu0C/vMf4Mc/dj9hCg0FHn5YJheHD3de2gs4M7+WL5egrbcdrgayt96S/XHmmXLktrtJzLp1clR0+XKZVLNJAhER+cK2bZJh5VpapKkWeOVa6PxMVF/wGDDpUphMJmzIKcNtr+/FiMggvH/rGbh63uhuu4qGB1vxg0VjcGFGqgTk7Hb5sn3WWfLleyAxVnwYmW0JCfJZvX9/++u9844EmJYt6/22Jk+WIvjGzw9+IDWQXRpN2SorJdDjaZ6dni7zKHfBtvHjOy8LNBiZbVrLbbXuWb02wNkt1LUTqaFjR1Ktgffek7nj2LGyVFLr7jPb+iItDXA4ELN9uywLtlqdlyklY+xuPtnbzDYA+Na35ODop5/KWLoKyppM/q9xbWQi9iazraTEu2YSmzZJYHjmTMn6/Pjj9vPbjz+Wfdohg5NODwy20aCWXVSDltUPYJSpGLXn/wktP8uG5QcfIWTJzxAUndD1jdsmCWrKTJjr2z44Jk6VN8DeLiV99VX54OquVsW8eVIg8/nn3Xf37C8NDRK0mTVLPkwSEmSi4BosM5ojGBPHuXNl/xjL99atkw+r8eOdwTpvHpPd7jw61h/+/W85Xb1aAl++tHq1nJ57rvvLr7tOUseNLkwPPywfvD/6Udf3e/75cvrll50vM4JtN9wgp4F8HfXEjh3OWnOumptl0rlsmUzGjh7tOmhrt8vke+FCOUpdX9/5KDsREZG36uoko3zuXMkqf/hh+YzZvl0aIbxyDfSJrai+4C/A5MthMpnwn30luGvlPowdFopXfjgX6QnRvVsS+qc/yfKyjRuBP/7RN4+nshJYtar3qzUMRsDRCLYpJcEk17my1hJsO+ss32bnLFok8+pPP/3mLGtlpfMAsDsmk9T9cl1GahwInjHDc4AnMVHmtg0NPe9EajAypTo2RwCc9cGMwM6+fZLhdfHFUp9s5045MOzPYFtbwC88N1cyFTvui/T07jumHj4spx0bB3jjmmtkmzk5MpZANwUJDpYlzx0z2xwOWT3iqWHBRRfB1NICPPFE99vYtEmSEWw2mePm57cvlfKvf8lzvXRprx8GBQ6DbTRo1Te34ul/v4wVpjWonHIDQhf8ELaIOO+7Oe3fLx/gGS41tqbPkVNPLc0NlZWdC4g6HLL07dxzvatVce+98uZ6++2BWwK4Y4dkA82e7Txv1iznkjyjOUJGhvPyuXPldPNmGfe6dZLVZrHIEtNRo7ov2N/cDFxyiXzQ98dS2poaCXR9+9tyJO/uu3175Hj1agk4diyGa1iwQIKYr74qk5Q335Tlo90dFUxOlonb1193vmznTpm4LV4sH+CnS5OEFSskE63j0cB16+T/6tJL5cdikW5nnuzYIUtOFy1y1l9xlwFIRETUndxcCTT86EeShf7QQ7J8MSQEOGsx8D+zoQu2o+b8R4HJV8BkMmHljpO4572DyEiOwEs3zcWIWA/LGruze7fUozI+/x580DcHj269VeZaL7/s3fVra4G//a1zQ6fsbFny5xp4mDBBAiZGIG/PHpkXX3yxbwMo4eEy7zRWUaAt2BYf33XW0+TJsg+N8eXnS63krrqWG1lphYUyx4qO7nkTgilTZM7sLnDi2u0TkAOMgGQ0rlgh3wkeeUSCbVFRUmLE11yXjY4e7X6Mx451vZz5ww9l/3bRMdajxEQplwK4b44QCCkpnRsklJTI9yPjNdHRggUomzdPnq+uSufU1Mj/xpw58no1moAYS0lLS+X3a66R9xo67TDYRoPWg+/twB21T6A+ZATClj3Q85bp+/fLUboUCTRpkxVq2hnyZthVsK24WOqtTZ7s/KAEJMumoKDrJaSuIiOlO+m2bcAzz/Rs7L7i2hzBMHu2s0OpEXRzDbbNni37aNMm+QApK2vfFGD2bLmdpyOpDocEmj75RD6E3nrLpw/JrXfekcynb39bJtA5OTKh9IWWFpmQn3NO5/ocBpNJ0sPXrAHuuUeCvLfc4l16/Pz5sq87BmR37JBJXXCwHHk9HZok5OTIT3GxdF919dZb8j+xdKkEbZcu7XopqVGvbdEiyaoMCWGwjYiIeueee2Se8N57kl12++2yCuFP34cObYR+9gTqYu4Epl4Fk8mEo2X1ePDjQ1gwKgov3DgHcZFhvdtuU5MUf4+Jkey2Rx+Vz7Obbupb/bZt26QGWEgIcMcd3tWr/X//T6774ovtz8/Jkfmy69LYCRMkIHHqlPz97rsyp1m+vPdj9mTpUglItmV82YzMtq5MnizXN5qRGZnyxgoMd4xgYkGBZLZNnep5XudJTIysRnDXhCEuTp4PI9j2/vsSSExJkbncLbdIBt+GDXLQ3h9LKJOTnd9RjExFV+npMjc3Vq90VFYm33eWLetZ4whX118vp77uLNpbI0d27qxbUCCnnjLbABy96SY5SNxVJmpmpszfjUSFxER5baxaJX+/9poE9Yx9QqcdBttoUHp3Rz6G73oaY02F0Mv+gKCI2J7fyf798iU9fhy0JRiO8BEwhUfIm66nZaRlZbK0Lz9fOvhcc40U+gQkayksrGcTjeuvl6ynX/6y6wyvggL5YOuuQ1BPbd4sR7lcj9wYE5HMTGfwwnXSEBkpGVybNzuPNJ51lvPy2bPlqKC7lvBaS4HQ116TzkujR3tXCL+vXnpJJhALFsh+XLIE+M1vnJNEQIJVV17pXOrprS1bpOBtd+nf114rH6hvvy1HML09WrpggUwWXZ/7ujp5jU6bJpOxWbPkKOxAr1lmTC5mzZIvFcb+b2mRLzgXXij/Q4A8FydOuM/qAyTYNm6cTBwtFpkUs0kCERH11KZNcsDn9tudB84aK4H3fwTsfwItv1oO+6TJCLvrAVhXrgQA/PPrPFjNJjxy9XREhYf2ftsPPCAHLv/yF1mWl5Agy1c3b/ZuiZon994rB65WrZK5wY03dr2K4uBB4K9/ld+ffbb9ZdnZMl9zDf6MHy+nRt22d96Rg4OeMoH6YskSmT9+9hkAwFpV1f3KAKMjqVG3LTPTOVfwxFgWeeKEBPemTOl9wMvd7ZSSuV9enmwjK0vmPUbw64c/lGDc3r3dZ+71ls3mfI48BdsAz983Vq2SIHBfgqpXXCH1k/0RmO2NlBT5nuUa3DaCbV28nmvHjZMEi7/+1dlYoyOjodycOc7zli2T12NxsSwhzchon9RApxUG22hQ0Vrjta15ePadT3CH9X00jLsUwVMv6fkdNTTIB8mECYDJAqQsgD1+itTZGD/efbCtqko+FHNypP7X6tUysfje9+SNduVK4KKLOnej7IpSchSzulqOqnry61/L9p5+uscPtUubN0twzPXolBFY27q1fXMEV3PnyiRhzRr5sHYNHBkfKO5qiP32t8CTT0qnzZ//XAJQX37p/FDzh/x8WaJ47bWSUaaUTGSrq2WSW1AAfP/78pjee09qoBn1KLyxerXsv7PP7vp606Y5C+befrv3kyijDfhXXznP27tXJp7GpHH2bAnAdSxWPNB89JFMgJ98Upar/P73cv769XIU9dJLnfvlkktkUmh053LV0iKvm0WLnK/djAyZHA/ETm5ERDQwaQ38939LkMv4bC7cBry0DProOtTN/R/UXfY3NKx8B/bZsxF8882ofPUtrNpbgmtnJCAprpdLRwH5XP/jH2XecfHFzvO/9S0pSXL//b07yLp2rQSmfvYzmZP9/vfyOfv44+6vr7VcNywMuOsumd8ZNaUaGiQ41DEwY9Qk279f5ky7d8sc2B81uGbNkrn1p58CdXUwNzZ6l9kGtA+2TZniPKDnjhFs++ILedxdBeZ6KzVVaqJ98IH87fq8x8VJlqPxu7+aAxhLSd0F24xsM0+vu/fekwBUVxmC3QkJkQOuAyWzLSVFslpdkx68CLYBkP/Rxkb5fuPOpk3yv+L6el22TP7nHnpIVqlcf33vswQp4Bhso0HjVG0Tfvzvbbj3nd34c/DzMNlCoZY91G3HJ7eys+WNru3InLrsGZiWP+YMth050j5LqLZWJhG7d0tTg/PPlw/+d96RCdFPfypr9q++uucfjlOmyBGe555zn8Vz6BDwwgsygXnzzb4XujUUFMiRNdejLYDUqBgzRiYmWVntmyMY5s2T1OlPP5WaYa6XG9fvGGx74QUJGn7rW1KPxGKRzECt3QdUfOWVV2Qb113nPG/yZOlw9Y9/yPP9+uvyHH75peznb3+7c003h0OOPLsuHQZkOeycOd1P/Iwg3x//6Dwi7I3Jk6WZgmuTBKPBgFG411gGPJCbJFRVyQT2vPNkArtiBfDUU/IafOsteYyuDSaiouS6b7/d+Wj8tm3yP7lwofO8mTPlvN42NyGiwcnhAD76CBEHDsjyrfp632+jqUlqkdLp5913ZdnoL34BxEQDmU9Dv3E1HFqjevkLaM24ERarFQgPR8NLL8GRkYERt9+Cc49k4uazx/SuGUJrqwS+LrpIAg6/+U37IJVSktVmMklGWk+y1h0OeSwjR8pSVEDmOxdcIKso3B2UW7VK5jL//d8yF7LZnOVNDh2S0471vVJTJWiyf79zRYBr4MiXLBZZQbFunbN5QHdzroQEWdK5d6/sk6ysrpsjAJIJaLM5m171tBOpN1JT5SDw++9LsGvixPaX3367jNGb2s+9NXo0mqOi3Ddg6CrY1tAg+2b58vZdTE93RsKAsbwXkO9IZnP3z8PYsRIg/ec/298ekO8emzfLdwTX192MGRLYfeIJ2Y/XXOOLR0EBwmAbnfa01vhsfzEufOwLfJFTiienH8ekln1oWvxLBMWmdH8HJ07IBODWW51FLI3JhnFkzhoCS3Db0a5x42QybhTLbGgALr9c3jD/8Q/JuDEmVyEhEqi55hoJoJxzTu8e5H33yXK4G2+U7bn69a/lw/9Xv5Kji64ZTn1hBGY6BtsAOWK1cWPn5ggGo/aA3S7BNlchIRIgcq0hduKELB9dvFgmmMaH9IQJEnjxVbCtsbH931pLFuK8efK8urrvPpn0nHeeBDkffFAe62OPSaDxN79xXrehQY48/fznsrzxzjvli1VpqQR+zjnHu6O5554rgdWeHPk1m2X8Rio64Czca0yKxo2TIsJdde8MtE8/lS8MF1wgf//ylzIB/uUvZaJ+4YXyGFxddRVw8qQE6Vy51mszGK/TgbCUdNMmZ/YhEQXW/2/vvuOkrK7Hj3/utO2NZXeB3aUjsKBUASvYG7aAkag/S2INGqPGqIlJviYqmhg1RowaC2oEJKgEDRIjipoYlKaCFEEEXFj69jY7M/f3x5lhC9tntsF5v17z2jblmbvPPM95zj333vx8OP98xvz4x7KAT1ycHGsGDpQL+GnT5Nj+4IPSATB7NixaJMmHhQulM+Bvf5POllBF9oQJ8vj0dJnEPDpavsbFSZXEMcfIsW76dDmn/POfkrTo7EP9W2LXrkPjla7G65XE1JAhcPFZ8ObV8NEDVGVPomDyXByZY2rPBxwfzzdPv8C6tH489eaDZK/8X4NPjdcr8dttt8k5Lrj6esL69XJO/+lPZf7f11+vP3GUnS3VPx9/LPetKxCQ5x48WDprQx2E8+dLXPLzn0snFkjMOnMmxMZKZ2LNpIDXK89z1FFw3XUyfPH88+VzUFZ26EqkIU6n/G7DBul4HjlSPl9t5dRTJUkV6pRuaqVOYyQW/eorqbwrLGx8cYTQY3r0kFjb5Wp40atwZGdLBdUHH0jSqm5ndv/+cl3x4x9H/rVD7r2XNQ8+WH81VVKSJCnrS7a9957sE51l+GekhFaQDc1ruHOnFAgMGdK8pOLdd0tc/6tf1f79pk3yv645LzZUL5RgrVS5ZWSE/x5Uh2nhrI5KdR7b95fx5uodvLk6l637yzgqPY4nvzeQce//H77kfrjHXd10j+KiRTLMs6JCep4XLJAhbF99JSeZugkYqK46Wr9eyoe/9z05Kc6cWX/lmscj1W5+f+vLgBMT5fkvvFCSQI8+Kr9fu1bmNLvlFlkh6+GH5ee6Ca7W+PRT2fb6ljUfPbp64YL6km1HHSXbXFxcO+ERMnasBJB+v5yAbrhBvn/sMbkoqWnqVAlIt2ypf2Wk5vrLX6SdLrtMXic1VSrA1q2TgLVugqt7d5kANxCo/bepU2X4xYwZcrE0dChccIG0169/LXMsPPGEDLP93vfkZNnWy3VPmAAPPCAn7dRUSbbVnLjX4ZDKrs68SMLbb0uv8fjx8nOfPjI/ydNPy881h5CGnHOO7C+vvVa9ehXI5zEnp/bEtUOHyv68YkX1MIyOsGqVfCYCAbkIuuQSuYXm11NKta+EBPjkE758/32OSUiQuSL37pUKmV275JiRl9e8ireYGLkw69VLzo2JifL8CQlyLigoqL7l5VXP6RnidkuCYvBg+ZqZKbdeveSc5HTK8dzhkCTIjh2SYMjNlQvAvXtl+/ftk/Nvenr1c2RnS0fYscdKUqWt7NkjnVNPPy0x1FtvSTV8JAUCkqhcuFCGWF57betew18lU4U0dOx95hlJxDx6J/a1yeAtpnT8PfiGXYa7gYnxn/u6gven/Y5PFt+H6+KL5aL80ktrv0ZopMMHH0gS9vHH5feDBjF682Y5dz3/vHTeNTYB/2WXyTDImTPlHHLDDdXt8+Mfy/b37i3tM2OGxCj33y/nx2nTaj9XRoYkk6+8Uv5v11wjQ+Bee03aYO7c6v3mmmskhnvtNdnvoP4hh4MHSwKmoEA6ztpyKFyoM3v2bPnaVGUbSDvMnVvduVzfogV19ewpSZfBg9tmdcjQEE6fTxIt9Wno95HSqxfFQ4Y0/LkIrUha14IFkoyrL+7vykKVbdu3y3ngggvkuD17dvM6xzMzJVE9c6ZcF1x8sfw+1EkeKlCoafJkma/tsss0NuziNNmmuoS9xZVs2l3M5r0lbN5TwtodhazaXoABxvZO5Mqx/Tl3WBpJ29/FuW8DZec8QWxUIyfBqirpYXj4YQlQnn1Wkm233CIXvrGxErjVTfxAdbJt7VqZJHbxYkl+NXVADDfIOOUUCXAef1wO1ieeKIFTQoJsd1KSJH9ef12SPS1dIamuZcuk972+oLxmL0x9PYEOh1QE7NpVf4n1mDESgG7cKMmHd96RALC+5OaUKZJse/XVQ3uFmsNaqUi49155P3PmyP/siSfkROfxyGSsDanvRPrII/LYK66Qi6OdO6VEfMoUuf+ECXIhsGyZBHzhzF3RHMcdJ1//+1+p0vzySwmYa+6PY8ZIIF1e3vwAMTdXgoLf/a55wZ218honnSRt3Vx+vyS+Tz9d/h8hd94pi1cYU3sIaUhCgmzXrFlSyXfXXbK//uc/cPnltf93brcM+QgNse0Ifr9ULqalSSXCokWyb95/v/R8zphR/+N+8Qu5ELr11vbdXqWOBB4PHHssB0pLq5P9NVkrt/JyqX4pKJCv1spxxeORW7ducrx3OOSY1ZwLpEBAEmSbN8tt0yb5um6dHB9aMvQ0KUkScqmpkhAYMECSbmvWSOVwcbHcz+WSpMIJJ8h5+qSTmp5MvjlKSujz0ktSOVVeLufDf/9bqrTmz299ZX9dfr8kj2bNknPrH/4gUzCcdpokkDIy5HyQkiIXuSkphz5H/lZY8ltY+zrWFQNx3SEuDZPQEzJHQfYE2BmA394Hw3tBwdMEug+l6IxncGbk4Gzgf7ur2MsbX+3nwlHZuG5+SzrnfvAD6XB98kmJH7dskeGhW7ZUd9KuWiWjBT77jO9GjaL3ww83L1kEcv6563rLAAAgAElEQVTYsEFWCR0yRP6fN94o8emtt8rcs4sXy7nmqqvkMa++Kkm+us49VzrrHnlEVhydNUti17POklvISSdJ5+dzz1UnhUNVcjUNHiz/e5AOs7bUv78kqoKLJDRZ2QaSbCsulsq70KiLpoTmbRs2rG3mnwsl29LT5bPTGfXtWz3XXYjfL8nvM85omyRkR+reXT4v334rsfWqVTIqpjnJ2ZBf/lI+45ddJgnoE06Q64ikpPorJM84Q+7fnH1SdWqabFOdVkmlj0Vr8pi/Iped2zaSY7YyyOxggiuX77sLWTviOoaPP5Ps1Hic332HdTvwfPIovm6D8Iya1vATh1bJWbJEhmXef3/1ogUffiiLGTz0UMNzN6SnS1Bx333SwzFjhsx70RYn3bruv18O0ldfLcmqN9+UBEMooXXJJXKyW7KkdmDUEtbK+//oI5mbo773FZp3LSur4SD9mWfkQqG+x4eSdW+9JXOUjRsnPbL1BbB9+kivz7x5LU+2BQIyx8hjj0nb/PnPEuDefLMEwA6HJKeaE5TVlJAgQeZZZ0kg/8YbcuIMbf+UKRKIXXstHH98289dEVrE4j//kYRlefmhFYmjR8v/4/PPq5NzTXngAanquPpqufjr1sSqvr/6lTwmLU0q+0KrVjXl00/lovDMM2vvA2lpkhTNz68/kAfZf5xO2WefeUaSg+Xl9fesjhwp/6u61YqNsVYqHEeMCL93ceZMGb7z7LNyUTh9ulSB3H67JOxvvPHQCYE3bpT3eO214b22Uqp1QomzuDi5RXI1RYdDkkMZGbXnmASJVfbvlwq4vDxZJCYQkJu1ctzr2VO2JzNTti20rTWPVaFk4f79cqz97DO5PfNMdUXVsGGSeDv2WDlX5OQ0fN764gtJxLz2mhy3/f6DC8/0A0mq/OIXcgG5davMh3rmmXL+vfHG8NrL75dOx1dekWGQ99wjbfPyyzKU97rrat8/KkqSXKHjZ3kBfPxH7KdPg3FSccyVWIcbR/l+HGX7cexaj2vhAvifF7b5sTEOODGO8mOupWLUj3FHN14R+MLK3VgsNx2fjSM9WeYQe/ZZOS8OHy7bN2+e/A/nz5eKbGPkfBU8Z21ZvpzezU20gewHL74oFfRTpshF+ty5cl65915Jrk6eLIm0BQskBmpsmF9WluwXd9whicylSyXerdlhbIwk7n7zG0lADBxY/zk1NBXLUUcdOvdYpBkjbTBrlvzc3GQbyDDuUaPqT0DWFUq2tcXiCFBdRXXmmbU7HzuTvn2lzb78srpj9ZNP5HhwzjmHXyWWMfK5ePFFWWzsvvvqH23RmLg4+cyfdpo89pNP5DZ6dP3HWmPabh9T7UqTbarT+e5AGX9asolFa/LIqMrlN7HzmRRVPe+FPyELAj6GfXMPZSOzMe8VEjt1Kr7zT8I56mvKzn+aWE8jJ8ynnpJk1O9/f+j8WC6XzE1x5ZUNV4aFFklYuVICjZtuap9EG0jCYeZMKWE++2xJftx4Y/UB/8wzZa6ZOXNal2yrrJSk10svSdB211313y82VioA+vZtuGKvoeQISNAVFyeBoMMhiYbGgpypU2Vb1q5t/smnqkr+v7NmSYA7Y4YELsOHy///qackkfOjH7UuMBg3TqoF0tPrXzFpyBBJfgUCbR94xMVJMui//63uaavbTqHqus8+a16ybds2GcYyaZK8j+nTZb9qyHPPyQXF+edLova88ySQSEpq+rXefls+b/VVPlxySeOP7dFDAqBbb5XVnl54Qdq77oUrSLLtxRelcqS5i1D87nfyOb/vPqkkba3cXNnfTzut9mS36emyby5eLBWcL75Y+3F33y2ft9tvb/1rK9UJGWPOBv4EOIHnrLUPdfAmdS6hybfT0+ufrqG5Qsm3tDRJukwOrtBeWSmdKf/5jxyrX365ekXz0LkyM1MqrFJTpVrlrbck2eZ2S1JnwADZTqcTXC5W9erF6KuuguId8O4d4IqFec/Azx6QWGnRIokxzjqr3hjLWkt5lZ8yr5+ySj8pcW4SooMXon6/JHhefRV+dhv88Dw4sBGyciS5d9ddsnjVgQNSfbj2bZi3EK67DjvrV/CDQdiibZjKQtZ2P5t/7zmO1BfX0ct3gB6+UrpVVpC6vRDXtnICGan4rszBjkumYuzVkDkOdxNx3s4iL69/tZ/JRyXTPy3YgetyyXDOKVPk+P/UU1KB9eqrkZ1cPzlZkp+nniqJtp/9TNqkZhs7HDIqormysyVGamhu0csvl/NjXp7Eo/XFOaEE23nntc9qiqecArNm4fd4cNad47U+oe2rqpL4oDmxWs3KtrbQs6fEGued13mTVlddJfvZxImykMPJJ0si1+OpfxTC4SArS44vV1who4lac93Xvbu00+mny/Vabq6M4Ois/2cVEZpsUx2rqgKWPohd/Tds+jA+c4zgkU092EN3nu22iOOL/gkOD+VjbsUx5GwcGUNxRCfiKNuHffEcYl6+HP5ahY2NxfXWx/hj++C5t5FVW/LyJOCZNEl6Ohs6WDbVq3jnnTKpf2PP0VYmTZIE0fPPS89uzW2NiZFAesECmYeuvmGwDdm3TwKxjz+W57377saHoi5c2PoJ3p1OuXj45BMJCOubF66miy+WHuw5cySh05Rdu2SOlI8+kv/VPffUfi9Op5wsb765ddsfUt88C3W11/4xYYIkmpYtk4Cnbll6drZcbDV3kYQHHqhe8WzuXBmCMnWqXDTU9a9/SdL3tNMk6fbpp7IvTZ0qQ4SbGtL89tuSAGxJb35doaq1jz+W/399vdqhC9aVK5uXbFuyRBJg3brJ1wkTqhdwaKlbb5U5WB5++ND2yM6Wz/Szz1ZPxg3yXhYskP03EsO8lOokjDFOYCZwBpALLDfGLLTW1rMUomoTUVHSKRHqmPD7ZbL7L76QipWvvpKqpZUrpbq4vFw6c2bMkON7aiK4Y8BUn+OKP1sGq/6K/e8j8gvrx3zxEvaS8Zh+U2D+e5Kw6xYPJ/bDDu9FQWImX/q7825BCuvK3MS5K4n3VJDsKqVv5V7OKN5N3207cH6xHXYVY89MxsQ9D3Oel5foMxFzwh3Qc7Qc1/esg3/fD+ZzfDflYBbvxfnON5RvLWXZ2cP5euuxnLhmObfvkYWXyjzR5EclUBgTz+a4FL699grOuO0KEpMlWdPcM/gfPs7FYeAnJ/auvWgCSOXiX/8q0wf06BHeua4hgwbJ+WLdOhmqFqnkVkOJgPR0qZZbuLDh+fIGD5aRBW21CmldJ58MxlCVnIyzObFXSopUhu7c2fwhgccdJ4notpoexBhJlnZmAwbIKJuLLpLE+Zw5su9NnFj/sO3DweTJ0nn8hz+EN01Pv35S4XbOOXINVd8idOqwosm2kIoKmdh8927p7UtOlguslBRJYLRF1tnrhZISKUl1OKp7B91uGdbYFhfp1sr7c7nCn9OrIRUVkv13uyWY83jk/cTF1b7f9k/hH9Nh/yYO9DyZwu3bmBD4iPnB+MAWOakc/gOYdBfR3bJrL3aQkIG56i3scUOhsJiqB6fheebvOF7PxfxkhQzdq8/tt8v7f+ih8N7/uee2/rGR8MADUll14YWH/m3qVEmOLFpUuxdz2zbpMauvLH3xYul1zsuToSWXXtr0/hduefv3vy8VOz/5SdOfrx49ZIjFnDmSCGysWuqTT6QaKj9fqgDrzt1V0+HUm3TccdUr5Q0demiloDESHK5c2eRTReflSYXV1VdL1d4dd0hC7KabJJiqmfj5/HPZ53JyJNEWEyMJ4Ucflf/tLbfIdjXU1tu2ydwfv/1tZI55jS0OMmyYfO5XrpRhxI3ZuVMuWAYPluHaF10k+9Lnn0u1R0u89ZYkAu+9t/55CUHa+OWXpUd73jw5Vt95p3xmb7qpZa+nVOc3Dthsrd0CYIyZC1wItH+yze+D7ctIKlwPuYfROaE1EoAT+8uN0FymwWGoFeVQtAX2fIl9Zxom/xusJwF6jMD0GAHdBjF69RNQsoWq7ImUjr8HZ3Q8zvXzid4wD2evnTDdwqYY7OcV8PYazMI1pAATg7daHEBAvg14DN5+8TjOGorvjPH4k/rgT+iNs3g7MWtmYWZfgO17CqbbAOzqFyE6meKTZhAYNJldZ/p5LeNv3Db7IU55/n+cAvhGjCDw0wcx3/seMenpUOUn/0A5yzbs49lPd/KX17/lt2f04fjeic1qtk+2F/HeN4VMH5dO//RG4pO2qoYKGTPm0JUN29K110qyraERB8ZIR1J7Cc6RW1lWRnRz47ucnJYl28aPl1EEh1P82Bqh+fGmTKleDGz69MO3XW64oXoBknCNGiWx+hNPSCeuOqxpsu366zlx9mxJeDXE6ZQL19AtLk4uNrt3l+qJ+Hh5fHFxdfLM662+VVXVvoWSbKFluOvjcMhJIy1NXsfhqJ4XI7SqZShh5nLJc1VWSqKroqL26/p81X+rrKx+jaSk6oRiVpZcVA4ZIrfhw6vnMWsGz/79cqH99tty8K27apfLCacdC5eeBcceA7nLscv+gj++F89nPcxDm7NJi3fzm0lJnBG3GbtnA4HhlxCVOfzQHsKQV97ErC8mcGEantJF+H40Eucz++TCf9Wq2isRgmzX3LmSrGmL5brbU2xsw8mCU06R/+ucOXIC/OwzmUvr3Xflwn36dDlhdO8u1Xm33SaLKgwaJEmFmnOPtaUf/lDmXmnua117rQzv7dNHqoRuu02S4iEVFWS+8YYMg+ndWyqqRo06fE/8dYVO2Pv2SU9jfZ+b0aNlP9i6tdH51Pq88oocY269VdrP7ZaV5SZOlMTPQw/JKmrvvy/tnJQkw2Jq9tZffbVM9v3nP8vPv/519fCLmv75T/na2oqxloiKks/+qlWN38/nkznVSkokSZaZKfMBTZwoidwPPzx0jg2/X4Y5Bye5Hr5xoySki4pk2GpOjlRSNlYlcOON8Mc/yiIOmzdLheDjj0v7+nyRaQOlOodM4LsaP+cC9axO0A68xfDyeYwCWNPUnVUgJg1fag6+rNNwVOzHtX8dzuVPY6wfjzuFohNmEOh3Jq5gh2bg6GsoG3Yl5P4XX0Ux7wxN5U9DYqk6UMLZzgNMTKxkXNQB4ot3QHkZxu8GvxNTZSA1gw2DRvN/Baks3+tlQLKHPx/dh+xEDwbJxZUcdQmudbOJXvcKZusHVA64kLKRt+CK787/thZy95Id+LPHcuLzczll0wockybhGjasuvIrECDWaRieFsvwtN6cOSCZ2//5DTcs+IZLc1L4+Qk98Dgb7giq8gd4aOl3ZCe4uWlcJqax2L45rG3Zwhgd6fjj5TzVp0/n2eaZM9n45ZeMa+7/Yfx4WWCid+/O8x46g+bshwkJct1w9dWyH5x6qrZhTY21YY15GpvdZsG5MVXXYmxrh4GF86ItnKdj7NixdsWKFW2zMU8/Te6//kXW0KGS2EpPlwuyoiKZ8yE/Xy64vF5JVHm9kkzLz5eL2gMH5O/x8ZKEi4+XREhohSq3W5JhNb93u6vvFx9fPdTP55MPUlWVvPa+fTKhbX5+9WS4oSXfra19/1AVWehW87VCrx8TU11pFnqN/Hx5Dzt2yKSpoQ+8wyGTXp50ktxSU2VIwZo1ckGZm1s7oRhKVqYnweAoSAuueuWz4Af2BuBLL1QA3R0w3M3exBze3dcHU1bB4CQXOTl9iM7siUlPl0TZkCEyt0V9pfBr10rp7cknw9MP4X/vbirH3ExsZXcZCz9qlAwBC7VtRYW8H79fhmY1Np9YB1m6fDmTmjMssTl++lNJLJ5+uvQ6pqZKcmvFCkmSREdLWf/ixdImt98uiYDmzHHRkVavlmF4ixZJMnjaNFnJbe1aqaYMBGTukJkzW77oweHgmGMkkTZjhiRV61q5UvYJYyRpdMstkqSrmQDavBk7eDDmuutkXsOaf/v972WRjpD0dAkW7rij/qHAfr8Mh5g1S45F110nw5PT0mRbli6VJD3Ivtkec7rcfLPMMXLnnXLs279fjg9Dhsh7OPpoGaL9+99LRd7ll1e3wd//Lr30t9wiweWaNTLc6osvJKkdWu0vPZ3ipCQSQp0xyclS5dfUCq35+XKfY4+V4VvR0dJGHo8c75taoOIws3TpUiZNmhSx5zPGrLTW6piNTsAYMxU421p7bfDn/weMt9beXOd+1wPXA2RkZIyZO3du5Lcl4CO5YC1l5eVEddYJyTsBa6E8NpPK6O7U7TIwAS+xpd+x36QQHX/ocarSb/l0V4C3vvWxvwKGpBimDnIzMKV5ff7WWj7f4+e5tV6MgVtGuBmUXDsB5vSV46oqoiImA3/A8o8tfhZt9ZMZb5g+wk3P+ObXF3j9lvmbvLy7zc+x6Q5uONqFo4GOksXbfMzb5OfWkS5GZYS//5SUlBDf2WOxTq5FbRgI4PD5COhnv5aWtqG7qIiqmh3gqm0+y0dKAUFQpNvwlFNOafc4sN2TbcF5Or6mxjwdwA8am6ejTZNtwNIlSyTJ0ZodOLTKE1Q/vqt+ELxeGdK1YYMMlVq2TC6Ia1apJSVCn+6Q4ga3AacBp6WSAqJ6F0O6A1/GKLxZJ+GP64GN6U4gJhUblYQpLcX1z3cIzFlA4tebAKh0eXAkJuCKicYUFBxaYRgdLRfBQ4dKcjI01Pa99yRZ+NFHB4d0WWtlqGnogjg6WoZaHn+8JC6fe07+1tpVOttYRJNtn3wiSaekJJmc9/rrq6uO1q2T6q/XX5dEyf33S1VbV9pvP/9ckm7vvisVWsGqzDUJCRw9fXrnXcGprd1wg1Q0vv22JKLr8803MlR49mzpVBg1SqohR4+W4ScPPoh/3jycq1ZVr4oV4vNJVVtqquw7Q4ZIMr+pfWfzZpnnYt686mrc0Gc9J0eqTVsycXM45s6VzwPIMaVbN9me7dslWRty1VVSVVY3AXjHHTL3Tkh0tOx/Y8ZIkmzcOOjXj6WrV7fu8/zIIzKkNrSt555b3bmiybawaLKt8zDGHAf8n7X2rODP9wBYa2c09Ji2jAV9Ph9Lly5l/PiOKa7rDKy17CisYMOuUtbtKmbTnlL2lVRRUF5FYUUVJRV+use76ZcaS//ucQzoHsvQnvEMzYjH45LE1/Llyzm2xnFvy74y5q3aycIvd1Nc6WdoRhy3ndaf04Zl4mxF58o3e4r54azl7Cys4L7zjuL8ozMOuc/mvaXc848NbNhdyoVHp3HfBcNJTmh8FdGGPPvhNzz4zgYuG9OTu88aWHs6E2BPcSXnP72CMdkJzPrhhFa9p7oifdw7Emkbhk/bMHzahuE7HOLAjhhG2nnm6QD430yGrVsAW91QVYKtLAHrB088eOIxngRwOMFbWv13vzf49zhMVIKsttSWiQobgKoy8JZivcWyLU6PbF9UAnjiwNHAEu3Nen4r78lbjPWWgLcEeln4QTxcfiJmpxcKDmCjcjExVWD2YT0JWGcU1uEGp4cy+uAbPBlv3zNwJGUeHPppkPLFHUWVLPjOyT/cp5N38UQyTQXXHZ/FZRP6466ZGCkrk8RYXh5s3CiJvw0bJHnk9VYPo42OluqlGnMnHQyCLrlELkoXL5bJ4B95RC5UL75YVs86Ehx/vFS05eRIFVHN/TMnR4b2hVaZau8FHiJh5EhJKvn98t6C72H/8uVHbqINZJXajz9ufMGJAQOkautXv5KE22uvyWepxhDznVOnkp2VdehjXS6Zd6ylBg6UBN9dd8GTT0pSKzQxd48e7bsPTpsmQx1iYiTZFlqpr7RUEtFffSXVbjfcUH+l3YMPyvtJTZX5dwYOlKq9SL2Hm26SZN6QIe0ztFapjrEcGGSM6QfsAKYBl3XsJh1ZfAHLxl0lrNheyIrtBazOLaKwXIarOw306RZDRoKHrOQ4kmM8JES72F1cyZZ9Zby1ZhelXumccDsNOT3iOTozkf17qliwayP7S7zsKfGyaU8pLofhtMHduHxcNscNTMdddwh+CwxIT+AfN5/IdS8t5xcLN7JyewE5PRPokRBFekIUn24r4IkPviXO4+RPU3OYPKp3WAmw6ycOYFdROS/8dxvpiR5+dHz1yuMBa/njki1U+QPce+6QiCTalFJKHV46orKt0wwdABi46a8kHviCgCsWnzMGnzMGcOAMlOPylePyl2OsH58zBn/w79Y4cQYqcPkrcPrLcPorm3ydcPmd0TW2IRpnoApn8PVlGwNNP0kjAg73wffnc8ZIksxfjtNfgcNXRoWJZlf0IHKjB7HNM4h8RzeoMZCg3FuFcbrw+sEbgHIf7KuwHKiA/RWWQq/cOyfFcFIvB6PTHAd7Qtuao6KC+C1bKOnXj0BMTLu8ZmuUlJcT34m3ryvQNmwd4/MRu307CZs2EZ2Xx8bzziPqSByGG0Hh7IuuoiL8MTHYmhelxrTPMNtO5HAYPqAaZow5F3gc6ZN7wVrb6FLTR2JlW2mljz0lXvYWeykoryJgpQItYMHpMGQkeMhIjCIt3oO7kXnFQs/1xY5ivsgtYnVuIV/uKKbUK3MA9U6JZnRWIkdnJXJMVgpDeiYSF+3BGHNINReA3+9nZ0E5n3+Xz6pt+azeXsD63SX4/ZbUeA/dYt10i3Uzpncilx7bh57d4huef7cVvL4Av/7HGv6+Ihd/ncuYiQNTePCi4fRKTah321sqELD8ZM4q3l6zi/snH0Wf1Bj+tW4f767fy54SL9cel8kvLxgRkdcCrYaJBG3D8Gkbhk/bMHxa2daGrLXPAs+CBFhttrNOmsSSJUsYO2YMUQ4Hddbvw1qLRRZFchpD3ZoZay3tNV2hC3DXczIPRChh6gCKSqv4Kq+Y9btK2Li7lA17SthRUF8ysW5yz1Hrdx6noUeih54pURydGEW/1FguGJlJ37TEiAZch5OlH37IpImHrMelWkDbMDK2ajuGrU32xa401DsCNFA9vFlrFwGLOno7mssfsJRU+iiu9FFc4cdai9spHYdupyE5xk2sp+UJ8eIKH9sPlLP1QDlb95fx7X75mltQcTAZ1hQDpMS6SQkmuZJjZVv2l0qibk9xJfnBqjUDDEqL5dxh3RnXN4UJA9LolRKHw+FodsLI6XSSnRpPdmo854+U6QaqfH7+8/FHnHzyyS16rtbwuBw8NGUEv71gGHuKK8jLL2dnYTlRTsPpw3oeXJwhEhwOwx8vHcn+0s+49+2v5fWdhuP7JXPH8P5cNLp3m75XpZRSXVdHJNt2ADUnAsoK/q5DfLBxD0u/85EXvZdot5MYlwOX0+ALSG+WP2Ap9/kpKPNxoMxLQZkEWpW+AF5fgCp/gICFGLeTuCgncR4nMW4nbqfB5TS4HfJ8bqfB5XDgcsj3sR7nwVuM2ylJO2vxBSw+v6Wwwkd+aRX55VUUlFVR5vVTXhWgospPhS+Ay2GIcjmIcjuIcTnxuBxEuRx4XPJ7V/B1XQ65eZxy36hgYOj1Bygq91FYUUVhuY9v95exdmcxu4tlgQQD9O4WzbAe8UwZ0YM+qXEkxLiJi3ITH+0iyuU4OFmsMbBq5UpOPG48MW4HMR4XbqfjYLClQUgLaFuFT9swMrQdw6dtqFSnV+UPsCGviK/2B9i7djcHSqs4UFbF3hIve4sr2VPsZW+Jl6KKplcETohy0iMxih6JUXSL8xAf5SQ+ykV8lBNrobDCR1G5j6IKH7uLK9l2oJz8supVEx0GeiVF0adbDKOzE8lIjKJnUgwZSdF0i4vC5ZCYymHA6w+wp6iSnQXl5BWWs7uokvwyL/llVWzeW0qZ109KrIv0BA9H94qnR2I0I7KTGdM3leS4qIh3fLpdTowx7Tqc0uN2kdUtnqxubbugQJTLybNXjuWxdzcyKC2as4b1Ijk+WjuPlVJKNaojkm2dap6OuZ9t518bfLDh6ybv6zCQFOMiMcqF22kO9mY6jGFvSRXbDgSCSTE/voClyi+l/uGKDybxot0Ool1y8wUslT5Lhc8fTPxZKv2SAGzpazodhsykKEZlJXB0r0RG9k5heFYy8dGeZvdO7ohzktnGwY5SSimlVCQVV/g4f+b/5IfVGwFwOQypcW7S4t30TolmTHYi3eI8JMa4SIxxkxjtweUweINxV6UvwIFSL3mF5eQVVrCrqJKv95RS6vVTWuknFJY5HYbEaCeJ0S66x7mZNDCFPqmx9OseR/+0BPqlxRPjcYVdGWatJTRNjCaEIiMh2s2vLxje0ZuhlFKqC2n3ZJu11meMuRn4F9XzdHzV3tsR8uj3R/LvDz5i+KgxVIQSZX57sCrMGawg6xYXRVKMG6fz0GotY8zBoKZmgANSHef1+akKWHx+qYSr8ltKK32Uen2UVvooq/TjMBKEuZwOnA5Dcqyb1LgoUuI8eIK9haHXqqvmawN4ffIefAF5rarg61ZWBSQ5V+XH43KSHOMiKdZDfJQEdm1d9q+UUkop1Zkkx7iZedkocjevY9KEMXSPjyIxxh12XBQIrm7s9wcoqfRhDMR5nLWq/tsq5tJRBUoppVTH65A52zrTPB1xUS6Sox0MzEgK63kaSoY5neB2t20z133NmCNsEm2llFJKqdZwOAznHdOLpQe+ZnCvlAg+r+Pg15Q2jgOVUkop1flobblSSimllFJKKaWUUhGiyTallFJKKaWUUkoppSJEk21KKaWUUkoppZRSSkWIJtuUUkoppZRSSimllIoQTbYppZRSSimllFJKKRUhmmxTSimllFJKKaWUUipCNNmmlFJKKaWUUkoppVSEaLJNKaWUUkoppZRSSqkI0WSbUkoppZRSSimllFIRosk2pZRSSimllFJKKaUiRJNtSimllFJKKaWUUkpFiLHWdvQ2NMkYsxfY1oYv0R3Y14bPfyTQNgyftmH4tA0jQ9sxfNqG4Yt0G/ax1qZF8PlUO9JYsEvQNgyftmH4tA3Dp20YPm3D8HX5OLBLJNvamjFmhbV2bEdvR1embRg+bcPwaRtGhrZj+LQNw6dtqNqT7iKW5HIAAAiaSURBVG/h0zYMn7Zh+LQNw6dtGD5tw/AdDm2ow0iVUkoppZRSSimllIoQTbYppZRSSimllFJKKRUhmmwTz3b0BhwGtA3Dp20YPm3DyNB2DJ+2Yfi0DVV70v0tfNqG4dM2DJ+2Yfi0DcOnbRi+Lt+GOmebUkoppZRSSimllFIRopVtSimllFJKKaWUUkpFiCbblFJKKaWUUkoppZSKkCM+2WaMOdsYs9EYs9kYc3dHb09XYIzJNsZ8YIxZZ4z5yhhza/D33Ywx/zbGbAp+Tenobe3sjDFOY8xqY8zbwZ/7GWM+De6PrxljPB29jZ2ZMSbZGDPfGLPBGLPeGHOc7octY4y5Lfg5XmuMmWOMidb9sHHGmBeMMXuMMWtr/K7e/c6IJ4Jt+aUxZnTHbXnn0UAb/iH4Wf7SGPOmMSa5xt/uCbbhRmPMWR2z1epwpHFgy2kcGDkaB4ZH48DI0Fiw5TQWDN+REAse0ck2Y4wTmAmcA+QAPzDG5HTsVnUJPuAOa20OMAGYHmy3u4El1tpBwJLgz6pxtwLra/z8MPCYtXYgkA/8qEO2quv4E7DYWjsEGIG0pe6HzWSMyQR+Aoy11g4HnMA0dD9syizg7Dq/a2i/OwcYFLxdD/ylnbaxs5vFoW34b2C4tfYY4GvgHoDg+WUaMCz4mKeC52+lwqJxYKtpHBg5GgeGR+PAMGks2Gqz0FgwXLM4zGPBIzrZBowDNltrt1hrvcBc4MIO3qZOz1qbZ61dFfy+GDmxZSJt91Lwbi8BF3XMFnYNxpgs4DzgueDPBjgVmB+8i7ZhI4wxScDJwPMA1lqvtbYA3Q9bygXEGGNcQCyQh+6HjbLWfgQcqPPrhva7C4GXrVgGJBtjerbPlnZe9bWhtfZda60v+OMyICv4/YXAXGttpbX2W2Azcv5WKlwaB7aCxoGRoXFgeDQOjCiNBVtIY8HwHQmx4JGebMsEvqvxc27wd6qZjDF9gVHAp0CGtTYv+KddQEYHbVZX8TjwcyAQ/DkVKKhxgNH9sXH9gL3Ai8EhGM8ZY+LQ/bDZrLU7gEeA7UhgVQisRPfD1mhov9PzTOv8EHgn+L22oWorum+FSePAsGgcGB6NAyNAY8GI0lgwsrp8LHikJ9tUGIwx8cDrwE+ttUU1/2attYDtkA3rAowxk4E91tqVHb0tXZgLGA38xVo7CiilzlAB3Q8bF5xL4kIkYO0FxHFoObdqId3vwmOM+SUyTO3Vjt4WpVTDNA5sPY0DI0LjwAjQWLBt6L4XnsMlFjzSk207gOwaP2cFf6eaYIxxIwHWq9baN4K/3h0qiQ1+3dNR29cFnABcYIzZigxbORWZdyI5WMINuj82JRfItdZ+Gvx5PhJ06X7YfKcD31pr91prq4A3kH1T98OWa2i/0/NMCxhjrgYmA5cHA1XQNlRtR/etVtI4MGwaB4ZP48DI0FgwcjQWjIDDKRY80pNty4FBwdVWPMikews7eJs6veCcEs8D6621j9b400LgquD3VwH/aO9t6yqstfdYa7OstX2R/e59a+3lwAfA1ODdtA0bYa3dBXxnjBkc/NVpwDp0P2yJ7cAEY0xs8HMdakPdD1uuof1uIXBlcCWqCUBhjSEGqgZjzNnIkKoLrLVlNf60EJhmjIkyxvRDJhj+rCO2UR12NA5sBY0Dw6dxYPg0DowYjQUjR2PBMB1usaCpThYemYwx5yJzJjiBF6y1D3TwJnV6xpgTgY+BNVTPM/ELZL6OeUBvYBvwfWtt3YkjVR3GmEnAz6y1k40x/ZEezm7AauAKa21lR25fZ2aMGYlMLOwBtgDXIJ0Iuh82kzHmPuBSpFR7NXAtMgeC7ocNMMbMASYB3YHdwG+ABdSz3wUD1yeRIRllwDXW2hUdsd2dSQNteA8QBewP3m2ZtfbG4P1/iczd4UOGrL1T9zmVag2NA1tO48DI0jiw9TQOjAyNBVtOY8HwHQmx4BGfbFNKKaWUUkoppZRSKlKO9GGkSimllFJKKaWUUkpFjCbblFJKKaWUUkoppZSKEE22KaWUUkoppZRSSikVIZpsU0oppZRSSimllFIqQjTZppRSSimllFJKKaVUhLg6egOUUqo+xhg/sAZwI0s8vww8Zq0NdOiGKaWUUkqpNqexoFKqK9Nkm1Kqsyq31o4EMMakA7OBROA3HbpVSimllFKqPWgsqJTqsnQYqVKq07PW7gGuB242oq8x5mNjzKrg7XgAY8zLxpiLQo8zxrxqjLnQGDPMGPOZMeZzY8yXxphBHfVelFJKKaVUy2gsqJTqaoy1tqO3QSmlDmGMKbHWxtf5XQEwGCgGAtbaimCwNMdaO9YYMxG4zVp7kTEmCfgcGAQ8Biyz1r5qjPEATmttefu+I6WUUkop1VwaCyqlujIdRqqU6orcwJPGmJGAHzgKwFr7oTHmKWNMGjAFeN1a6zPG/A/4pTEmC3jDWrupw7ZcKaWUUkqFS2NBpVSnpsNIlVJdgjGmPxJM7QFuA3YDI4CxgKfGXV8GrgCuAV4AsNbOBi4AyoFFxphT22/LlVJKKaVUuDQWVEp1JVrZppTq9IK9k08DT1prbXBYQK61NmCMuQpw1rj7LOAzYJe1dl3w8f2BLdbaJ4wxvYFjgPfb9U0opZRSSqlW0VhQKdXVaLJNKdVZxRhjPqd6ufdXgEeDf3sKeN0YcyWwGCgNPchau9sYsx5YUOO5vg/8P2NMFbALeLAdtl8ppZRSSrWexoJKqS5LF0hQSh1WjDGxwBpgtLW2sKO3RymllFJKtR+NBZVSnYHO2aaUOmwYY04H1gN/1uBKKaWUUurIorGgUqqz0Mo2pZRSSimllFJKKaUiRCvblFJKKaWUUkoppZSKEE22KaWUUkoppZRSSikVIZpsU0oppZRSSimllFIqQjTZppRSSimllFJKKaVUhGiyTSmllFJKKaWUUkqpCPn/joKjdyfhXIwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1296x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gFtsSx4h6MD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "364bb4e1-b03a-4821-ead7-fb269ee68712"
      },
      "source": [
        "print('Are futures predicted ' + str(UseFutures) + ' Custom Loss Pointer ' + str(CustomLoss) + ' Class weights used ' + str(UseClassweights))\n",
        "print('Predictions per sequence ' + str(NpredperseqTOT))\n",
        "print('Number of LSTMworkers ' + str(number_of_LSTMworkers))\n",
        "print('Number of epochs for each LSTMworker ' + str(LSTMepochs))\n",
        "print('Batch size for LSTM ' + str(LSTMbatch_size))\n",
        "print('LSTM Activation Method ' + str(LSTMactivationvalue))\n",
        "print('LSTM recurrent Activation method ' + str(LSTMrecurrent_activation))\n",
        "print('LSTM Optimizer ' + str(LSTMoptimizer))\n",
        "print('LSTM Dropout Layer 1 ' +str(LSTMdropout1) + 'LSTM Recurrent Dropout Layer 1 ' +str(LSTMrecurrent_dropout1) + 'LSTM Dropout Layer >= 2 ' +str(LSTMdropout2) + 'LSTM Recurrent Dropout Layer >=2 ' +str(LSTMrecurrent_dropout2))\n",
        "print('Number of hidden LSTM nodes ' + str(number_LSTMnodes) + ' Is there a third LSTM layer? ' + str(LSTMThirdLayer))\n",
        "print('LSTM Initial Embedding layer ' + str(LSTMInitialMLP) + ' Final LSTM Layer ' + str(LSTMFinalMLP))\n",
        "print('LSTM Verbose Option ' + str(LSTMverbose))\n",
        "print('LSTM Validation Fraction ' +str(LSTMvalidationfrac) + ' Method to chose best solution '+ str(bestmethod))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Are futures predicted True Custom Loss Pointer 1 Class weights used True\n",
            "Predictions per sequence 30\n",
            "Number of LSTMworkers 1\n",
            "Number of epochs for each LSTMworker 200\n",
            "Batch size for LSTM 110\n",
            "LSTM Activation Method selu\n",
            "LSTM recurrent Activation method sigmoid\n",
            "LSTM Optimizer adam\n",
            "LSTM Dropout Layer 1 0.2LSTM Recurrent Dropout Layer 1 0.2LSTM Dropout Layer >= 2 0.2LSTM Recurrent Dropout Layer >=2 0.2\n",
            "Number of hidden LSTM nodes 16 Is there a third LSTM layer? False\n",
            "LSTM Initial Embedding layer 32 Final LSTM Layer 64\n",
            "LSTM Verbose Option 0\n",
            "LSTM Validation Fraction 0.2 Method to chose best solution 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGzOGTRnbJZ-",
        "colab_type": "text"
      },
      "source": [
        "# Setting up the Transformer for COVID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_uUU6V6bYzA",
        "colab_type": "text"
      },
      "source": [
        "Other data from LSTM defining COVID problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkI2rG-n41sf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "The original had a BUFFERSIZE removed\n",
        "\n",
        "Compared to original with a single sequence label and dimension, inp_seq_len or d_sample, we have two sequence labels\n",
        "\n",
        "iseq = range(0..Tseq) time\n",
        "\n",
        "iloc = range(0..Nloc) sample location"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dJFhD-nq0fO0"
      },
      "source": [
        "## Important Parameters defining Transformer project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOxm7gWkyjIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Transformerbatch_size = 2\n",
        "Transformervalidationfrac = 0.0\n",
        "Transformerepochs = 100\n",
        "Transformeroptimizer ='adam'\n",
        "Transformerverbose = 0\n",
        "TransformerFullAttention = False\n",
        "d_model =128\n",
        "d_Attention = 2 * d_model\n",
        "if TransformerFullAttention:\n",
        "  d_Attention = d_model\n",
        "num_heads = 4\n",
        "num_Encoderlayers = 4\n",
        "EncoderDropout= 0.1\n",
        "EncoderActivation = 'selu'\n",
        "d_EncoderLayer = d_Attention\n",
        "d_merge = d_model\n",
        "d_ffn = 4*d_model\n",
        "MaskingOption = 0\n",
        "PeriodicInputTemporalEncoding = 7 # natural for COVID\n",
        "LinearInputTemporalEncoding = -1 # natural for COVID\n",
        "TransformerInputTemporalEncoding = 10000\n",
        "UseTransformerInputTemporalEncoding = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEaGePMdYXwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Output parameters used in this Science Transformer\n",
        "\n",
        "print(\"Batch size of stochastic gradient descent Transformerbatch_size \", str(Transformerbatch_size))\n",
        "print(\"Fraction used for a validation dataset \", str(Transformervalidationfrac))\n",
        "print(\"Dimension of value embedding for every input [Model1] d_model \", str(d_model))\n",
        "print(\"Dimension of value embedding for input to Decoder (LSTM) \", str(d_merge))\n",
        "print(\"Number of Attention Heads which must exactly divide d_model, num_heads \", str(num_heads))\n",
        "print(\"Number of layers in Encoder stage num_Encoderlayers \", str(num_Encoderlayers))\n",
        "print(\"Dropout in Encoder stage, EncoderDropout \", str(EncoderDropout))\n",
        "print(\"Size of Encoder stage, d_EncoderLayer \", str(d_EncoderLayer))\n",
        "print(\"Activation in Encoder Stage EncoderActivation \",str(EncoderActivation))\n",
        "print(\"Size of feedforward network in each encoder layer. It appears to be 4 * d_model, d_ffn \", str(d_ffn))\n",
        "print(\"Defines masking used; = 0 none; =1 mask the future MaskingOption \", str(MaskingOption))\n",
        "print(\"Defines use of periodic time encoding; =0 none; > 0 use time encoding with this period [ 7 weekly, 365 annual). Note this added as a property of each input (actually two as cos-theta and sin-theta), PeriodicInputTemporalEncoding \", str(PeriodicInputTemporalEncoding))\n",
        "print(\"Defines use of linear time encoding; =0 none; =-1 make linear over full time range. Note this added as a single property of each input, LinearInputTemporalEncoding \", str(LinearInputTemporalEncoding))\n",
        "print(\"Defines structure of Transformer-style time encoding; =0 none; > 0 use time encoding with this base (10000 in transformer example) TransformerInputTemporalEncoding \", str(TransformerInputTemporalEncoding))\n",
        "print(\"Defines use of Transformer-style time encoding; UseTransformerInputTemporalEncoding \", str(UseTransformerInputTemporalEncoding))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm7X3Ww23_Ta",
        "colab_type": "text"
      },
      "source": [
        "***Num_Seq*** Number of Sequences\n",
        "\n",
        "***Nloc*** Number of locations\n",
        "\n",
        "***Tseq*** Length of each sequence\n",
        "\n",
        "***Npropperseq*** Number of internal properties per sequence including static or dynamic\n",
        "\n",
        "***NpredperseqTOT*** Total number of predictions per sequence\n",
        "\n",
        "***d_model*** Dimension of value embedding for every input [Model1] \n",
        "\n",
        "***num_heads*** Number of Attention Heads which must exactly divide ***d_model***\n",
        "\n",
        "***num_Encoderlayers*** Number of layers in Encoder stage\n",
        "\n",
        "***EncoderDropout*** Dropout in Encoder stage, \n",
        "\n",
        "***d_ffn*** Size of feedforward network in each encoder layer. It appears to bet to be 4 * ***d_model*** \n",
        "\n",
        "***MaskingOption*** defines masking used; = 0 none; =1 mask the future\n",
        "\n",
        "***PeriodicInputTemporalEncoding*** defines use of periodic time encoding; =0 none; > 0 use time encoding with this period [ 7 weekly, 365 annual). Note this added as a property of each input (actually two as cos-theta and sin-theta)\n",
        "\n",
        "***LinearInputTemporalEncoding*** defines use of linear time encoding; =0 none; =-1 make linear over full time range. Note this added as a single property of each input\n",
        "\n",
        "***TransformerInputTemporalEncoding*** defines use of Transformer-style time encoding; =0 none; > 0 use time encoding with this base (10000 in transformer example)\n",
        "\n",
        "***Transformerbatch_size*** is batch size of stochastic gradient descent\n",
        "\n",
        "***Tseq*** is size of sequence window\n",
        "\n",
        "***Transformervalidationfrac*** is fraction used for a validation dataset\n",
        "\n",
        "***d_sample*** The number of units presented to the Transformer which could be dynamic. Each of these inputs is used to calculate attention and is Tseq times number of locations simultaneously presented\n",
        "\n",
        "***max_d_sample*** The maximum number of units presented to the Transformer which is fixed. It is Tseq times maximum number of locations simultaneously presented\n",
        "\n",
        "***TransformerFullAttention*** if True calculate classic attention over all d_sample members; if False calculate separate attentions in location and time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCZ_vAQZnOSA",
        "colab_type": "text"
      },
      "source": [
        "Describe the science data sets here\n",
        "\n",
        "Initial data is [Num_Seq][Nloc][Tseq] with values [Nforcing + ExPosEnc-Selin + Nprop-Sel]\n",
        "\n",
        "Predictions are [Num_Seq] [Nloc] [Predvals=Npred+ExPosEnc-Selout] [Predtimes = Forecast-time range]\n",
        "\n",
        "A subset is included in each transformer call. There are 3 options\n",
        "*   Simplest: (as in LSTM) samples are labelled by [Num_Seq] [Nloc] and have input length [Tseq] with multiple features [Nforcing + ExPosEnc-Selin + Nprop-Sel] mapped into a model for each input of length [Model1]. Predictions for each input are [Predvals] [Predtimes]\n",
        "*   Straightforward improvement:  Divide Nloc into sublocation groups giving Nloc/Nsub groups with Nloc-Nsub locations in each group. There are many choices of groups including fixed disjoint subgroups, overlapping groups (so that each epoch surveys each location twice and this should help spread attention). Then each sample is labelled by [Num_Seq] [Nloc/Nsub] and have input length [Nloc-Nsub][Tseq] with multiple features [Nforcing + ExPosEnc-Selin + Nprop-Sel] mapped into a model for each input of length [Model1]. Predictions for each input are [Predvals] [Predtimes]\n",
        "*   (Too) Clever: Use different selections for Encoder and Decoder steps. For example feed all Nloc locations into transformer but oinly use through multi-headed attention step. One only takes a subset of these through encoder and predictions. This ensures that attention covers all locations\n",
        "*   Extend \"Too clever\"  or \"Straightforward\" method for multiple initial time values in each transformer input i.e. divide [Num_Seq] into [Num_Seq/Ntsub] groups and input [Num_Seq-Ntsub] time sequences into a single transformer. This spreads attention over time. \n",
        "\n",
        "We can represent all the above cases by lasbelling each data sample by\n",
        "{[Num_Seq][Nloc]} [Tseq] where always members of sequences are complete and selection of sequences and location for a single data sample varies in options above. Each member of a data sample has [Nforcing + ExPosEnc-Selin + Nprop-Sel] internal degrees of freedom. These degrees of freedom will be mapped (embedded) in a model variable of length ***d_model***\n",
        "\n",
        "Size of input is ***d_sample*** = Tseq * size {[Num_Seq][Nloc]} in a single data sample. This is important throughout network whereas [Nforcing + ExPosEnc-Selin + Nprop-Sel] is immediately embedded and becomes of length ***d_model***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsYiyg_6c-U3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up data\n",
        "# Initial data is [For Batching][Nloc_sample] [Tseq] [NpropperseqTOT] starting with RawInputSequencesTOT\n",
        "# Predictions are [For Batching][Nloc_sample] [NpredperseqTOT] starting with RawInputPredictionsTOT\n",
        "#  For case Nloc_sample = Nloc, the Batching is identical to Time sequence label\n",
        "# dsample Tseq * Nloc\n",
        "\n",
        "Nloc_sample = Nloc\n",
        "Num_Seq_TimeandLoc = Num_seq\n",
        "if Nloc%Nloc_sample != 0:\n",
        "  print(\"Inconsistent location numbers \" + str(Nloc) + ' ' + str(Nloc_sample))\n",
        "  sys.exit()\n",
        "d_sample = Tseq * Nloc\n",
        "max_d_sample = d_sample\n",
        "Transformermaximum_position_encoding = max_d_sample\n",
        "X_Transformerdetailed = numpy.copy(RawInputSequencesTOT)\n",
        "y_Transformerdetailed = numpy.copy(RawInputPredictionsTOT)\n",
        "X_Transformerflat = numpy.reshape(X_Transformerdetailed, (Num_Seq_TimeandLoc, d_sample, NpropperseqTOT))\n",
        "y_Transformerflat = numpy.reshape(y_Transformerdetailed, (Num_Seq_TimeandLoc, Nloc, NpredperseqTOT))\n",
        "\n",
        "# We need to shuffle for training data but unshuffled (unflattened) data will be used in evaluation\n",
        "X_predict, y_predict = shuffleDLinput(X_Transformerflat, y_Transformerflat)\n",
        "\n",
        "print(\"The maximum number of units presented to the Transformer which is fixed.It is Tseq times maximum number of locations simultaneously presented \", str(max_d_sample))\n",
        "print(\"The actual number of units presented to the Transformer for this batch.It is Tseq times  number of locations simultaneously presented in  this batch \", str(max_d_sample))\n",
        "print(\" Number of locations in each sample presented to the Transformer \", str(Nloc_sample))\n",
        "print(\"Number of locations times sequence window length in each sample presented to the Transformer \", str(Num_Seq_TimeandLoc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nBQuibYA4n0n"
      },
      "source": [
        "## Positional encoding Text and Code\n",
        "\n",
        "Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence. \n",
        "\n",
        "The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the *similarity of their meaning and their position in the sentence*, in the d-dimensional space.\n",
        "\n",
        "See the notebook on [positional encoding](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) to learn more about it. The formula for calculating the positional encoding is as follows:\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmiB1vED2GIv",
        "colab_type": "text"
      },
      "source": [
        "I am not certain if Science wants this type of encoding and/or the positional coding controlled by ***PeriodicInputTemporalEncoding*** and\n",
        "***LinearInputTemporalEncoding***.\n",
        "\n",
        "***TransformerInputTemporalEncoding*** controls this. TransformerInputTemporalEncoding = 10000  will give example given here\n",
        "\n",
        "The base 10000 needs study but otherwise we use this function below later-on\n",
        "\n",
        "The Blogs/papers on BERT have discussion of more sophisticated multi-sentence encoding in BERT\n",
        "\n",
        "Also another Blog questions why this encoding added rather that being concatenated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WhIOZjMNKujn",
        "colab": {}
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(TransformerInputTemporalEncoding, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1Rz82wEs5biZ",
        "colab": {}
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    \n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    \n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1kLCla68EloE",
        "colab": {}
      },
      "source": [
        "pos_encoding = positional_encoding(max_d_sample, 512)\n",
        "print (pos_encoding.shape)\n",
        "\n",
        "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "if not UseTransformerInputTemporalEncoding:\n",
        "  print(startbold + 'Classic Transformer Encoding not used' +resetfonts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a_b4ou4TYqUN"
      },
      "source": [
        "## Masking Text and Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLziWUNR3u_F",
        "colab_type": "text"
      },
      "source": [
        "Masking could be used in time. Basic logic similar between science and NLP. There will be no masking in location.\n",
        "\n",
        "Use flag ***MaskingOption*** to define masking used; = 0 none; =1 mask the future\n",
        "\n",
        "Note use of NaN to indicate undefined predicted values. That must be handled in loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s42Uydjkv0hF"
      },
      "source": [
        "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value `0` is present: it outputs a `1` at those locations, and a `0` otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U2i8-e1s8ti9",
        "colab": {}
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A7BYeBCNvi7n",
        "colab": {}
      },
      "source": [
        "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
        "create_padding_mask(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z0hzukDBgVom"
      },
      "source": [
        "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
        "\n",
        "This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dVxS8OPI9uI0",
        "colab": {}
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yxKGuXxaBeeE",
        "colab": {}
      },
      "source": [
        "x = tf.random.uniform((1, 3))\n",
        "temp = create_look_ahead_mask(x.shape[1])\n",
        "\n",
        "if MaskingOption == 0:\n",
        "  print(startbold + 'Classic Transformer Masking not used' +resetfonts)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xluDl5cXYy4y"
      },
      "source": [
        "## Scaled dot product attention for Science"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoaxZAH4ZQCJ",
        "colab_type": "text"
      },
      "source": [
        "This seems unchanged for science case unless ***d_sample*** is too large. One wastes time then if softmaxes too small. It could be useful just to select the largest (e.g. take top 10 or remove all probabilities < 0.001) softmax values and just process with these\n",
        "\n",
        "Below all vectors Q K V have size ***d_model/num_heads***. They are defined for each head and for each sample member of the ***d_sample*** members\n",
        "\n",
        "This could use the  mask described earlier but that is not used in initial version\n",
        "\n",
        "We have a hierarchial sequence label which limits number of softmaxes calculated although number of Q K V vectors are not reduced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVc8GEGgJNc2",
        "colab_type": "text"
      },
      "source": [
        "## Scaled dot product attention: Q K V Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at4BqdMkqJYb",
        "colab_type": "text"
      },
      "source": [
        "### Discussion and Science version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vsxEE_-Wa1gF"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png\" width=\"500\" alt=\"scaled_dot_product_attention\">\n",
        "\n",
        "The attention function used by the transformer takes three inputs: Q (query), K (key), V (value). The equation used to calculate the attention weights is:\n",
        "\n",
        "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n",
        "\n",
        "The dot-product attention is scaled by a factor of square root of the depth. This is done because for large values of depth, the dot product grows large in magnitude pushing the softmax function where it has small gradients resulting in a very hard softmax. \n",
        "\n",
        "For example, consider that `Q` and `K` have a mean of 0 and variance of 1. Their matrix multiplication will have a mean of 0 and variance of `dk`. Hence, *square root of `dk`* is used for scaling (and not any other number) because the matmul of `Q` and `K` should have a mean of 0 and variance of 1, and you get a gentler softmax.\n",
        "\n",
        "The mask is multiplied with -1e9 (close to negative infinity). This is done because the mask is summed with the scaled matrix multiplication of Q and K and is applied immediately before a softmax. The goal is to zero out these cells, and large negative inputs to softmax are near zero in the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LazzUq3bJ5SH",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  # Needs externally defined  Num_heads, d_sample, Nloc_sample, Tseq, d_model\n",
        "  # Calculates depth\n",
        "  \"\"\"\n",
        "  Calculate the attention weights after Q K V found\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "In the science Transformer, Q K V are all Batch, Num_heads, d_sample, depth\n",
        "where Q K V all have same number of samples d_sample\n",
        "depth is always d_model/num heads\n",
        "\n",
        "d_sample is really [Nloc_sample][Tseq] and calculates separate Location and Time Attention\n",
        "\n",
        "Original returned attention weights but ignored. We do NOT return but rather return two attention vectors in Location and Time\n",
        "If TransformerFullAttention specified, it returns  traditional full attention vector\n",
        "  Returns:\n",
        "    AttentionVector1 concatenated with AttentionVector2\n",
        "  \"\"\"\n",
        "  # To scale matmul_qk\n",
        "  depth = tf.shape(k)[-1]\n",
        "  dk = tf.cast(depth, tf.float32) # dk is depth in all methods\n",
        "\n",
        "  if TransformerFullAttention:\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # [Batch, Num_heads, d_sample, depth] [Batch, Num_heads, (d_sample, depth)T ]\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk) # [Batch, Num_heads, d_sample, dsample]\n",
        "\n",
        "    # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "      scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k = d_sample) so that the scores add up to 1.\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # scaled_attention_logits [Batch, Num_heads, d_sample, d_sample] \n",
        "\n",
        "    AttentionVectorfull = tf.matmul(attention_weights, v)  # [Batch, Num_heads, d_sample, d_sample] [Batch, Num_heads, d_sample, depth]\n",
        "    AttentionVectortemp = tf.transpose(AttentionVectorfull, perm = [0,2,1,3]) # [Batch,  d_sample, Num_heads, depth]\n",
        "    AttentionVector = tf.reshape(AttentionVector1time, [q.shape[0],d_sample, d_model]) # restore shape\n",
        "\n",
        "else:\n",
        "  # Calculate Attention in Time. This requires no reordering and so can be redone with shape\n",
        "  # Note matmul works for all number of indices and multiplication is only done on last 2 indices so using qtime means we look at attention with location fixed\n",
        "  # No mask used with this\n",
        "  qtime = tf.reshape(q, [q.shape[0], Num_heads, Nloc_sample, Tseq, depth ])\n",
        "  ktime = tf.reshape(k, [k.shape[0], Num_heads, Nloc_sample, Tseq, depth ])\n",
        "  vtime = tf.reshape(v, [v.shape[0], Num_heads, Nloc_sample, Tseq, depth ])\n",
        "  matmul_qk = tf.matmul(qtime, ktime, transpose_b=True)  # [Batch, Num_heads, Nloc_sample, Tseq, depth] [Batch, Num_heads, Nloc_sample, (Tseq, depth)T ]\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk) # [Batch, Num_heads, Nloc_sample, Tseq, Tseq]\n",
        "\n",
        "  # softmax is normalized on the last axis (Tseq) so that the scores add up to 1 in time direction separately for each space.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # scaled_attention_logits [Batch, Num_heads, Nloc_sample, Tseq, Tseq] \n",
        "\n",
        "  AttentionVector1time = tf.matmul(attention_weights, vtime)  # [Batch, Num_heads, Nloc_sample, Tseq, Tseq] [Batch, Num_heads,  Nloc_sample, Tseq, depth] becomes [Batch, Num_heads, Nloc_sample, Tseq, depth]\n",
        "  AttentionVector1temp = tf.transpose(AttentionVector1time, perm = [0,2,3,1,4]) # [Batch,  Nloc_sample, Tseq, Num_heads, depth]\n",
        "  AttentionVector1 = tf.reshape(AttentionVectortemp, [q.shape[0],d_sample, d_model]) # restore shape\n",
        "\n",
        "# Code below rewrites arrays\n",
        "  qspace = tf.transpose(qtime, perm = [0,1,3,2,4]) # [Batch, Num_heads, Tseq, Nloc_sample,  depth]\n",
        "  kspace = tf.transpose(ktime, perm = [0,1,3,2,4]) # [Batch, Num_heads, Tseq, Nloc_sample,  depth]\n",
        "  vspace = tf.transpose(vtime, perm = [0,1,3,2,4]) # [Batch, Num_heads, Tseq, Nloc_sample,  depth]\n",
        "  matmul_qk = tf.matmul(qspace, kspace, transpose_b=True)  # [Batch, Num_heads, Tseq, Nloc_sample, depth] [Batch, Num_heads, Tseq, (Nloc_sample, depth)T ]\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk) # [Batch, Num_heads, Tseq, Nloc_sample, Nloc_sample]\n",
        "\n",
        "  # softmax is normalized on the last axis (Nloc_sample) so that the scores add up to 1 in location direction separately for each space.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # scaled_attention_logits [Batch, Num_heads, Tseq, Nloc_sample,  Nloc_sample] \n",
        "\n",
        "  AttentionVector2space = tf.matmul(attention_weights, vspace)  # [Batch, Num_heads, Tseq, Nloc_sample,  Nloc_sample] [Batch, Num_heads, Tseq, Nloc_sample,  depth] becomes [Batch, Num_heads, Tseq, Nloc_sample,  depth]\n",
        "  AttentionVector2temp = tf.transpose(AttentionVector2space, perm = [0,3,2,1,4]) # [Batch,  Nloc_sample, Tseq, Num_heads, depth]\n",
        "  AttentionVector2 = tf.reshape(AttentionVector2temp, [q.shape[0], d_sample, d_model ]) # restore shape\n",
        "\n",
        "  AttentionVector = tf.concat([AttentionVector1,AttentionVector2], -1) # [Batch, d_sample,2*d_model =d_Attention] \n",
        "\n",
        "return AttentionVector # [Batch, Num_heads, d_sample,depth] or [Batch, Num_heads, d_sample,2*depth] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCSKp3Pkp89l",
        "colab_type": "text"
      },
      "source": [
        "### scaled_dot_product_attention Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FiqETnhCkoXh"
      },
      "source": [
        "As the softmax normalization is done on K, its values decide the amount of importance given to Q.\n",
        "\n",
        "The output represents the multiplication of the attention weights and the V (value) vector. This ensures that the words you want to focus on are kept as-is and the irrelevant words are flushed out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n90YjClyInFy",
        "colab": {}
      },
      "source": [
        "def print_out(q, k, v):\n",
        "  save = TransformerFullAttention\n",
        "  TransformerFullAttention = True\n",
        "  temp_out, = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "  print ('Output is:')\n",
        "  print (temp_out)\n",
        "  TransformerFullAttention =  save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yAzUAf2DPlNt",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "temp_k = tf.constant([[10,0,0],\n",
        "                      [0,10,0],\n",
        "                      [0,0,10],\n",
        "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
        "\n",
        "temp_v = tf.constant([[   1,0],\n",
        "                      [  10,0],\n",
        "                      [ 100,5],\n",
        "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
        "\n",
        "# This `query` aligns with the second `key`,\n",
        "# so the second `value` is returned.\n",
        "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zg6k-fGhgXra",
        "colab": {}
      },
      "source": [
        "# This query aligns with a repeated key (third and fourth), \n",
        "# so all associated values get averaged.\n",
        "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UAq3YOzUgXhb",
        "colab": {}
      },
      "source": [
        "# This query aligns equally with the first and second key, \n",
        "# so their values get averaged.\n",
        "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aOz-4_XIhaTP"
      },
      "source": [
        "Pass all the queries together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6dlU8Tm-hYrF",
        "colab": {}
      },
      "source": [
        "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MIKxBremkTX",
        "colab_type": "text"
      },
      "source": [
        "## **Multi-head attention for Science**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgd3H0AVrueX",
        "colab_type": "text"
      },
      "source": [
        "Multi-head attention should be identical between Science ad NLP \n",
        "\n",
        "Note assertion that ***num_heads*** divides ***d_model***\n",
        "\n",
        "The annotation has seq_len and similar notations which is ***d_sample***\n",
        "\n",
        "***depth*** is calculated. It is number of words in each instance of Q, K, V for one head. Note that Q, K, V are concatenated over heads for efficient computation\n",
        "\n",
        "We suggest possibility of doing attention not across all d_sample inputs but rather separately in time and in location. This is implemented in \"Scaled Dot Product Attention\"\n",
        "\n",
        "We also allow d_Attention final size to be different from input d_model. Further we put correction of splitting into \"Scaled Dot Product Attention\" as it is naturally combined with other tensor reshape/transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9TpHjS8sHup",
        "colab_type": "text"
      },
      "source": [
        "### Multi-head Attention Discussion and Science version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fz5BMC8Kaoqo"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png\" width=\"500\" alt=\"multi-head attention\">\n",
        "\n",
        "\n",
        "Multi-head attention consists of four parts:\n",
        "*    Linear layers and split into heads.\n",
        "*    Scaled dot-product attention.\n",
        "*    Concatenation of heads.\n",
        "*    Final linear layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JPmbr6F1C-v_"
      },
      "source": [
        "Each multi-head attention block gets three inputs; Q (query), K (key), V (value). These are put through linear (Dense) layers and split up into multiple heads. \n",
        "\n",
        "The `scaled_dot_product_attention` defined above is applied to each head (broadcasted for efficiency). An appropriate mask must be used in the attention step.  The attention output for each head is then concatenated (using `tf.transpose`, and `tf.reshape`) and put through a final `Dense` layer.\n",
        "\n",
        "Instead of one single attention head, Q, K, and V are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. After the split each head has a reduced dimensionality, so the total computation cost is the same as a single head attention with full dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BSV3PPKsYecw",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  # Feed in d_model, num_heads. Nothing assumed. Other sizes implied by tensors\n",
        "  # seq_len = seq_len_q = seq_len_k= seq_len_v below is d_sample\n",
        "\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    assert self.d_model % self.num_heads == 0\n",
        "    \n",
        "    self.depth = d_model // self.num_heads\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    if d_model != d_Attention:\n",
        "      self.wq2 = tf.keras.layers.Dense(d_model)\n",
        "      self.wk2 = tf.keras.layers.Dense(d_model)\n",
        "      self.wv2 = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.finaldense = tf.keras.layers.Dense(d_Attention)\n",
        "        \n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    if tf.shape(q)[-1] == d_model:  \n",
        "      q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "      k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "      v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "    else:\n",
        "      q = self.wq2(q)  # (batch_size, seq_len, d_model)\n",
        "      k = self.wk2(k)  # (batch_size, seq_len, d_model)\n",
        "      v = self.wv2(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "    \n",
        "    # scaled_attention.shape == (batch_size,  seq_len_q, d_Attention)\n",
        "    concat_attention = scaled_dot_product_attention(q, k, v, mask)\n",
        "\n",
        "    output = self.finaldense(concat_attention)  # (batch_size, seq_len_q, d_Attention)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5prBlqE3qh0I",
        "colab_type": "text"
      },
      "source": [
        "### MultiHeadAttention Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0D8FJue5lDyZ"
      },
      "source": [
        "Create a `MultiHeadAttention` layer to try out. At each location in the sequence, `y`, the `MultiHeadAttention` runs all 8 attention heads across all other locations in the sequence, returning a new vector of the same length at each location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hu94p-_-2_BX",
        "colab": {}
      },
      "source": [
        "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
        "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
        "out = temp_mha(y, k=y, q=y, mask=None)\n",
        "out.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RdDqGayx67vv"
      },
      "source": [
        "## **Point wise feed forward network** (Original and Science)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag3IZpbu5aPe",
        "colab_type": "text"
      },
      "source": [
        "This is used in encoder (each) layer and the decoder.  The activation layer could be 'relu' or 'selu'.\n",
        "\n",
        "dff in code is our parameter ***d_ffn*** (size of first layer in feef forward network) and defaults to 4 * ***d_model***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gBqzJXGfHK3X"
      },
      "source": [
        "Point wise feed forward network consists of two fully-connected layers with a relu or selu activation in between."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ET7xLt0yCT6Z",
        "colab": {}
      },
      "source": [
        "def point_wise_feed_forward_network(d_EncoderLayer, d_ffn):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(d_ffn, activation=EncoderActivation),  # (batch_size, seq_len, d_ffn)\n",
        "      tf.keras.layers.Dense(d_EncoderLayer)  # (batch_size, seq_len, d_EncoderLayer)\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mytb1lPyOHLB",
        "colab": {}
      },
      "source": [
        "# Example of Point wise feed forward network\n",
        "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
        "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7e7hKcxn6-zd"
      },
      "source": [
        "## **Encoder and decoder**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDs43KCW-t9k",
        "colab_type": "text"
      },
      "source": [
        "Note the process starts with an ***Encoder*** and finishes with a ***Decoder***. These share components like multi-headed attention. We expect to look at different Decoders for science as we want floating point numbers and not as in NLP, members of a vocabulary We expect that decoder could be similar for science and NLP as it is looking for structure and that is a set of relationships which could be similar between science and NLP. ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yScbC0MUH8dS"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MfYJG-Kvgwy2"
      },
      "source": [
        "The transformer model follows the same general pattern as a standard [sequence to sequence with attention model](nmt_with_attention.ipynb). \n",
        "\n",
        "* The input sentence is passed through `N` encoder layers that generates an output for each word/token in the sequence.\n",
        "* The decoder attends on the encoder's output and its own input (self-attention) to predict the next word. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QFv-FNYUmvpn"
      },
      "source": [
        "### Encoder layer (Original and Science)\n",
        "\n",
        "Each encoder layer consists of sublayers:\n",
        "\n",
        "1.   Multi-head attention (with padding mask) \n",
        "2.    Point wise feed forward networks. \n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n",
        "\n",
        "The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_EncoderLayer` (last) axis. There are N = ***num_Encoderlayers*** encoder layers in the transformer.\n",
        "\n",
        "\n",
        "I am not clear why x and sublayer(x) (input and output, out1Â +Â ffn_output) are added. I would have concatenated. I had a similar comment on positional encoding which is added to rather than being appended to input. For science the numbers matter -- its not just patterns!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ncyS-Ms3i2x_",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention()\n",
        "    self.ffn = point_wise_feed_forward_network(d_EncoderLayer, d_ffn)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(EncoderDropout)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(EncoderDropout)\n",
        "    \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "# mha adjusts to shape[-1] of x being d_model or d_EncoderLayer\n",
        "    attn_output = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    if d_EncoderLayer == d_model:\n",
        "      addtogether = x + attn_output\n",
        "    else:\n",
        "      doublex = tf.concat([x,x], -1)\n",
        "      addtogether = doublex + attn_output \n",
        "    out1 = self.layernorm1(addtogether)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_EncoderLayer)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_EncoderLayer)\n",
        "    \n",
        "    return out2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AzZRXdO0mI48",
        "colab": {}
      },
      "source": [
        "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    tf.random.uniform((64, 43, 512)), False, None)\n",
        "\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6LO_48Owmx_o"
      },
      "source": [
        "### Decoder layer (Original)\n",
        "**Currently we do not expect to use this in science but later we may return**\n",
        "\n",
        "Each decoder layer consists of sublayers:\n",
        "\n",
        "1.   Masked multi-head attention (with look ahead mask and padding mask)\n",
        "2.   Multi-head attention (with padding mask). V (value) and K (key) receive the *encoder output* as inputs. Q (query) receives the *output from the masked multi-head attention sublayer.*\n",
        "3.   Point wise feed forward networks\n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n",
        "\n",
        "There are N decoder layers in the transformer.\n",
        "\n",
        "As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9SoX0-vd1hue",
        "colab": {}
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        " \n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "    \n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "    print(\"GCF6 \", np.shape(x), np.shape(out1), np.shape(out2), np.shape(out3))\n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ne2Bqx8k71l0",
        "colab": {}
      },
      "source": [
        "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
        "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
        "    False, None, None)\n",
        "\n",
        "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SE1H51Ajm0q1"
      },
      "source": [
        "### Encoder\n",
        "\n",
        "The `Encoder` consists of:\n",
        "1.   Input Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N encoder layers\n",
        "\n",
        "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-rBfJg5-YJx",
        "colab_type": "text"
      },
      "source": [
        "### Encoder (Original)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jpEox7gJ8FCI",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__():\n",
        "    super(Encoder, self).__init__()\n",
        "    \n",
        "   # self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.dense_1 = tf.keras.layers.Dense(d_model, activation=Encoderactivation)\n",
        "    if UseTransformerInputTemporalEncoding:\n",
        "      self.pos_encoding = positional_encoding(Transformermaximum_position_encoding, d_model)\n",
        "    \n",
        "    self.enc_layers = [EncoderLayer() for _ in range(num_Encoderlayers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(EncoderDropout)\n",
        "        \n",
        "  def call(self, x, training, mask):\n",
        "  \n",
        "  # adding embedding and position encoding.\n",
        "  # x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "  # x *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "    x = self.dense_1(x)\n",
        "\n",
        "    if UseTransformerInputTemporalEncoding:\n",
        "      seq_len = tf.shape(x)[1]\n",
        "      x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "    \n",
        "    for i in range(num_Encoderlayers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "    return x  # (batch_size, d_sample, d_EncoderLayer)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8QG9nueFQKXx",
        "colab": {}
      },
      "source": [
        "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
        "                         dff=2048, input_vocab_size=8500,\n",
        "                         maximum_position_encoding=10000)\n",
        "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
        "\n",
        "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_OZW9HM_43X",
        "colab_type": "text"
      },
      "source": [
        "### Encoder for Science"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XkLhZ1dAmXd",
        "colab_type": "text"
      },
      "source": [
        "The encoder for Science is very close to the NLP version\n",
        "Its output is TWO arrays\n",
        "* The result of self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model) before NLP position encoding applied\n",
        "* The same output of Encoder used in NLP\n",
        "\n",
        "Both are (***Transformerbatch_size***, ***d_sample***, ***d_model***)\n",
        "\n",
        "Note this is analogous to RESNET that adds input to output after several convolutional layers. We maybe incorrectly are concatenating not adding\n",
        "\n",
        "This interpreted as original embedded data which would have been fed into an LSTM in that model plus a second vector summarizing result of attention analysis -- a form of generalized history\n",
        "\n",
        "We will need to convert the ***d_sample*** index to two indices ***Tseq*** * size {[Num_Seq][Nloc]}\n",
        "\n",
        "We can run members of size {[Num_Seq][Nloc]} together in LSTM although this is not how it is done normally in pure LSTM. Alternatively we can run each sample member separately\n",
        "\n",
        "Note each member of sample has a separate encoder output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p-uO6ls8m2O5"
      },
      "source": [
        "### Decoder (Original)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZtT7PKzrXkNr"
      },
      "source": [
        " The `Decoder` consists of:\n",
        "1.   Output Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N decoder layers\n",
        "\n",
        "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d5_d5-PLQXwY",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "    \n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "    print(\"GCF4 \", np.shape(x))\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "    \n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    print(\"GCF5 \", np.shape(x))\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "      \n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a1jXoAMRZyvu",
        "colab": {}
      },
      "source": [
        "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
        "                         dff=2048, target_vocab_size=8000,\n",
        "                         maximum_position_encoding=5000)\n",
        "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "output, attn = sample_decoder(temp_input, \n",
        "                              enc_output=sample_encoder_output, \n",
        "                              training=False,\n",
        "                              look_ahead_mask=None, \n",
        "                              padding_mask=None )\n",
        "output.shape, attn['decoder_layer2_block2'].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk2MABcvCkW4",
        "colab_type": "text"
      },
      "source": [
        "### Decoder for Science\n",
        "This is not like the NLP Decoder. Rather it will use the same two layer LSTM we have already tested extensively in COVID.\n",
        "\n",
        "There are two important changes\n",
        "1. In COVID the equivalent of ***d_sample*** held just ***Tseq*** entries -- a single window for one location. Now we feed in a window of length Tseq as in COVID but the input data is muliple cases of size {[Num_Seq][Nloc]}. As we expect to start with one  sequence per network input this is just the number of locations.\n",
        "2. For each presented case, we intend to use not ust the output of encoder but rather the concatenation of two vectors of length ***d_model***\n",
        "\n",
        "* The result of self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model) before NLP position encoding applied\n",
        "* The same output of Encoder used in NLP containing concatenated attention head results\n",
        "\n",
        "There are two possibilities to consider\n",
        "1. That described above with a single input to decoder of length 2 * ***d_model*** * ***d_sample/Tseq***\n",
        "2. ***d_sample/Tseq*** separate runs (in parallel or one after the other) each containing one case. This is safest\" approach as closely mimics that used in COVID\n",
        "\n",
        "Note this LSTM subsystem ends with a small FCN and so we don't need an additional linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_caU47Rpt3HI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def EncodertoLSTMmerge(tf.keras.layers.Layer):\n",
        "  def __init__():\n",
        "    super(EncodertoLSTMmerge, self).__init__()\n",
        "    self.dense_merged = tf.keras.layers.Dense(d_merge, activation=Encoderactivation)\n",
        "\n",
        "def call(self, Originalinput, EncoderOutput):\n",
        "\n",
        "  Originalinput = tf.reshape(Originalinput, [Originalinput.shape[0], Nloc_sample, Tseq, NpropperseqTOT])\n",
        "  EncoderOutput = tf.reshape(EncoderOutput, [EncoderOutput.shape[0], Nloc_sample, Tseq, d_EncoderLayer])\n",
        "  Merged = tf.concat([Originalinput,EncoderOutput], -1)\n",
        "  Merged = self.dense_merged(Merged)\n",
        "\n",
        "  return Merged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWccxYzUqM7R",
        "colab_type": "text"
      },
      "source": [
        "# Transformer for Science"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AbcpEQBtFxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyScienceTransformermodel(tf.keras.Model):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(MyScienceTransformermodel, self).__init__(**kwargs)\n",
        "\n",
        "\n",
        "    self.Scienceencoder = Encoder()\n",
        "    self.Sciencemerge = EncodertoLSTMmerge()\n",
        "    self.fullLSTM = MyLSTMlayer() # Identical to that used in standalone LSTM\n",
        "\n",
        "  def call(self, inputs):  \n",
        "    # Here input is  flattened over Nloc_sample and Tseq although this is exposed and then flattened in scaled_dot_product_attention\n",
        "    Encoderoutput = self.Scienceencoder(inputs, training =settraining, mask = None)\n",
        "\n",
        "    # Here we expose separate dimensions Nloc_sample and Tseq\n",
        "    compositeinputs = self.Sciencemerge(inputs,Encoderoutput)\n",
        "    outputs = self.fullLSTM(compositeinputs)\n",
        "    return outputs\n",
        "\n",
        "def RunScienceTransformer():\n",
        "# Run the Science Transformer model defined by Model and Encoder/LSTM classes\n",
        "# Assumes X_predict, y_predict\n",
        "\n",
        "  X_train, y_train = shuffleDLinput(X_predict, y_predict)\n",
        "  settraining = True\n",
        "  LSTMInitialMLP = 0\n",
        "  myScienceTransformermodel = MyScienceTransformermodel(name ='myScienceTransformermodel')\n",
        "  if CustomLoss == 0:\n",
        "      myScienceTransformermodel.compile(loss='mse', optimizer= Transformeroptimizer)\n",
        "  if CustomLoss == 1:\n",
        "      myScienceTransformermodel.compile(loss= custom_lossGCF1, optimizer= Transformeroptimizer)\n",
        "  if CustomLoss == 4:    \n",
        "      myScienceTransformermodel.compile(loss= custom_lossGCF4, optimizer= Transformeroptimizer)\n",
        "\n",
        "  the_callbacks = [TqdmCallback(),]\n",
        "\n",
        "  if UseClassweights:   \n",
        "      cw = {}\n",
        "      for i in range(0,NpredperseqTOT):\n",
        "        cw[i] = Predictionwgt[i]     \n",
        "      modelresult = myScienceTransformermodel.fit(X_train, y_train,\n",
        "            epochs=Transformerepochs,\n",
        "            batch_size=Transformerbatch_size,\n",
        "            class_weight = cw,\n",
        "            verbose=Transformerverbose,\n",
        "            validation_split=Transformervalidationfrac,\n",
        "            callbacks=the_callbacks\n",
        "            )\n",
        "  else:\n",
        "      modelresult = myScienceTransformermodel.fit(X_train, y_train,\n",
        "            epochs=Transformerepochs,\n",
        "            batch_size=Transformerbatch_size,\n",
        "            verbose=Transformerverbose,\n",
        "            validation_split=Transformervalidationfrac,\n",
        "            callbacks=the_callbacks\n",
        "            ) \n",
        "  myScienceTransformermodel.summary()\n",
        "  settraining = False\n",
        "  finalizeDL(myScienceTransformermodel,modelresult)\n",
        "  return\n",
        "\n",
        "# Finally we can run the Science Transformer\n",
        "LaunchScienceTransformer = True\n",
        "if LaunchScienceTransformer:\n",
        "  RunScienceTransformer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y54xnJnuYgJ7"
      },
      "source": [
        "# Create the Original Transformer "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uERO1y54cOKq"
      },
      "source": [
        "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned.\n",
        "\n",
        "(Original Only. No further material used for Science Transformer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPnWIvpzo7Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sys.exit('Rest is Old')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PED3bIpOYkBu",
        "colab": {}
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, pe_input, rate)\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "  def call(self, inp, tar, training, enc_padding_mask, \n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "    print(\"GCF3 ENC OUT\", np.shape(enc_output), \" MASKS \", np.shape(look_ahead_mask),  np.shape(dec_padding_mask), \" DEC OUT \", np.shape(dec_output))\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "    \n",
        "    return final_output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tJ4fbQcIkHW1",
        "colab": {}
      },
      "source": [
        "sample_transformer = Transformer(\n",
        "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
        "    input_vocab_size=8500, target_vocab_size=8000, \n",
        "    pe_input=10000, pe_target=6000)\n",
        "\n",
        "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
        "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
        "                               enc_padding_mask=None, \n",
        "                               look_ahead_mask=None,\n",
        "                               dec_padding_mask=None)\n",
        "\n",
        "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "sample_transformer.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wsINyf1VEQLC"
      },
      "source": [
        "## Set hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zVjWCxFNcgbt"
      },
      "source": [
        "To keep this example small and relatively fast, the values for *num_layers, d_model, and dff* have been reduced. \n",
        "\n",
        "The values used in the base model of transformer were; *num_layers=6*, *d_model = 512*, *dff = 2048*. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer.\n",
        "\n",
        "Note: By changing the values below, you can get the model that achieved state of the art on many tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lnJn5SLA2ahP",
        "colab": {}
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
        "target_vocab_size = tokenizer_en.vocab_size + 2\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xYEGhEOtzn5W"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GOmWW--yP3zx"
      },
      "source": [
        "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n",
        "\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iYQdOO1axwEI",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7r4scdulztRx",
        "colab": {}
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f33ZCgvHpPdG",
        "colab": {}
      },
      "source": [
        "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
        "\n",
        "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YgkDE7hzo8r5"
      },
      "source": [
        "## Loss and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oxGJtoDuYIHL"
      },
      "source": [
        "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MlhsJMm0TW_B",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "67oqVHiT0Eiu",
        "colab": {}
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  \n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "phlyxMnm-Tpx",
        "colab": {}
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aeHumfr7zmMa"
      },
      "source": [
        "## Training and checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UiysUa--4tOU",
        "colab": {}
      },
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, \n",
        "                          pe_input=input_vocab_size, \n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZOJUSB1T8GjM",
        "colab": {}
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by \n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fzuf06YZp66w"
      },
      "source": [
        "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hNhuYfllndLZ",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print ('Latest checkpoint restored!!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0Di_Yaa1gf9r"
      },
      "source": [
        "The target is divided into tar_inp and tar_real. tar_inp is passed as an input to the decoder. `tar_real` is that same input shifted by 1: At each location in `tar_input`, `tar_real` contains the  next token that should be predicted.\n",
        "\n",
        "For example, `sentence` = \"SOS A lion in the jungle is sleeping EOS\"\n",
        "\n",
        "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
        "\n",
        "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
        "\n",
        "The transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next. \n",
        "\n",
        "During training this example uses teacher-forcing (like in the [text generation tutorial](./text_generation.ipynb)). Teacher forcing is passing the true output to the next time step regardless of what the model predicts at the current time step.\n",
        "\n",
        "As the transformer predicts each word, *self-attention* allows it to look at the previous words in the input sequence to better predict the next word.\n",
        "\n",
        "To prevent the model from peeking at the expected output the model uses a look-ahead mask."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LKpoA6q1sJFj",
        "colab": {}
      },
      "source": [
        "EPOCHS = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iJwmp9OE29oj",
        "colab": {}
      },
      "source": [
        "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
        "# execution. The function specializes to the precise shape of the argument\n",
        "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
        "# batch sizes (the last batch is smaller), use input_signature to specify\n",
        "# more generic shapes.\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "  \n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, tar_inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  \n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qM2PDWGDJ_8V"
      },
      "source": [
        "Portuguese is used as the input language and English is the target language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bbvmaKNiznHZ",
        "colab": {}
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  \n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  \n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "    train_step(inp, tar)\n",
        "    \n",
        "    if batch % 50 == 0:\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "      \n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "    \n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))\n",
        "\n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QfcsSWswSdGV"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y6APsFrgImLW"
      },
      "source": [
        "The following steps are used for evaluation:\n",
        "\n",
        "* Encode the input sentence using the Portuguese tokenizer (`tokenizer_pt`). Moreover, add the start and end token so the input is equivalent to what the model is trained with. This is the encoder input.\n",
        "* The decoder input is the `start token == tokenizer_en.vocab_size`.\n",
        "* Calculate the padding masks and the look ahead masks.\n",
        "* The `decoder` then outputs the predictions by looking at the `encoder output` and its own output (self-attention).\n",
        "* Select the last word and calculate the argmax of that.\n",
        "* Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
        "* In this approach, the decoder predicts the next word based on the previous words it predicted.\n",
        "\n",
        "Note: The model used here has less capacity to keep the example relatively faster so the predictions maybe less right. To reproduce the results in the paper, use the entire dataset and base transformer model or transformer XL, by changing the hyperparameters above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5buvMlnvyrFm",
        "colab": {}
      },
      "source": [
        "def evaluate(inp_sentence):\n",
        "  start_token = [tokenizer_pt.vocab_size]\n",
        "  end_token = [tokenizer_pt.vocab_size + 1]\n",
        "  \n",
        "  # inp sentence is portuguese, hence adding the start and end token\n",
        "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
        "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "  \n",
        "  # as the target is english, the first word to the transformer should be the\n",
        "  # english start token.\n",
        "  decoder_input = [tokenizer_en.vocab_size]\n",
        "  output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "  for i in range(MAX_LENGTH):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "  \n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input, \n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "    \n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    \n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == tokenizer_en.vocab_size+1:\n",
        "      return tf.squeeze(output, axis=0), attention_weights\n",
        "    \n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0), attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CN-BV43FMBej",
        "colab": {}
      },
      "source": [
        "def plot_attention_weights(attention, sentence, result, layer):\n",
        "  fig = plt.figure(figsize=(16, 8))\n",
        "  \n",
        "  sentence = tokenizer_pt.encode(sentence)\n",
        "  \n",
        "  attention = tf.squeeze(attention[layer], axis=0)\n",
        "  \n",
        "  for head in range(attention.shape[0]):\n",
        "    ax = fig.add_subplot(2, 4, head+1)\n",
        "    \n",
        "    # plot the attention weights\n",
        "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 10}\n",
        "    \n",
        "    ax.set_xticks(range(len(sentence)+2))\n",
        "    ax.set_yticks(range(len(result)))\n",
        "    \n",
        "    ax.set_ylim(len(result)-1.5, -0.5)\n",
        "        \n",
        "    ax.set_xticklabels(\n",
        "        ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
        "        fontdict=fontdict, rotation=90)\n",
        "    \n",
        "    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
        "                        if i < tokenizer_en.vocab_size], \n",
        "                       fontdict=fontdict)\n",
        "    \n",
        "    ax.set_xlabel('Head {}'.format(head+1))\n",
        "  \n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lU2_yG_vBGza",
        "colab": {}
      },
      "source": [
        "def translate(sentence, plot=''):\n",
        "  result, attention_weights = evaluate(sentence)\n",
        "  \n",
        "  predicted_sentence = tokenizer_en.decode([i for i in result \n",
        "                                            if i < tokenizer_en.vocab_size])  \n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Predicted translation: {}'.format(predicted_sentence))\n",
        "  \n",
        "  if plot:\n",
        "    plot_attention_weights(attention_weights, sentence, result, plot)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}